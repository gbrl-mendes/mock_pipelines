---
title: Sq_dez25 metabarcoding analysis
author:
- Hilário, OH
date: today
editor_options:
  chunk_output_type: console
format:
  html:
    code_download: true
    df-print: paged
    keep-md: true
    theme: flatly
    toc: true
    toc-depth: 5
    code-tools: true
  pdf: {}
---

<font size="0.5">**This pipeline integrates public tools available for eDNA metabarcoding analyses. To share or reproduce this content, please request authors' consent.**\
**Contact:** heronoh\@gmail.com</font>

# Short introduction

Welcome! We will guide you trough the analysis of environmental eDNA metabarcoding samples.

# Bioinformatics

## Set up

### Load R libs

```{r, eval=FALSE,echo=TRUE}
# 0 - load libraries and other programs ----
{
  library(tidyverse)
  library(phyloseq)
  library(Biostrings)
  library(ShortRead)
  library(dada2)
  library(DECIPHER)
  library(future)
  # library(ggh4x)
  library(vegan)
  library(ggtext)
  library(ggpubr)
}

# 1 - set path to cutadapt executable
cutadapt <- "/usr/local/bin/cutadapt"
```

<br>

### Set output and data paths

Here we will define a single project folder, and the pipeline will create the necessary subfolders for results organization. Only the this main project folder has to be edited on the code bellow.

```{r, eval=FALSE,echo=TRUE}
# 1 - create and set output and input paths ----

{
    
  #analysis name radical ----
  analysis_rad <-c("Sq_dez25")

  # the analysis folder ----
  # analysis_path <- "/home/noreh/prjcts/Sq_dez25/round2"
  analysis_path <- "~/prjcts/ecomol/analyses/2025/Sq_dez25"
  
  if(!dir.exists(analysis_path)){ 
    dir.create(analysis_path)
  }else{
      print(paste0("The folder ", analysis_path, " already exists"))
    }
  
  # create data_folder ----
  data_path <- paste0(analysis_path,"/data")
  if(!dir.exists(data_path)){ 
    dir.create(data_path)
  }else{
      print(paste0("The folder ", data_path, " already exists"))
    }
  
  #creat folders for the intermediate reads files ----
  ## create a folder for all processed reads ----
  pipe_libs <- paste0(data_path,"/reads")
  if(!dir.exists(pipe_libs)){ 
    dir.create(pipe_libs)
  }else{
      print(paste0("The folder ", pipe_libs, " already exists"))
    }
  
  ## create paired reads folder ----
  raw_libs <- paste0(pipe_libs,"/raw")
  if(!dir.exists(raw_libs)){ 
    dir.create(raw_libs)
  }else{
      print(paste0("The folder ", raw_libs, " already exists"))
    }
   
  ## create paired reads folder ----
  paired_libs <- paste0(pipe_libs,"/paired")
  if(!dir.exists(paired_libs)){ 
    dir.create(paired_libs)
  }else{
      print(paste0("The folder ", paired_libs, " already exists"))
    }
  
  ## create primer removed reads folder ----
  cutadapt_libs <- paste0(pipe_libs,"/cutadapt")
  if(!dir.exists(cutadapt_libs)){ 
    dir.create(cutadapt_libs)
  }else{
      print(paste0("The folder ", cutadapt_libs, " already exists"))
    }
  
  # create quality_folder ----
  qual_path <- paste0(analysis_path,"/quality")
  if(!dir.exists(qual_path)){ 
    dir.create(qual_path)
  }else{
      print(paste0("The folder ", qual_path, " already exists"))
    }
 
  # create results folder ----
  results_path <- paste0(analysis_path,"/results")
  if(!dir.exists(results_path)){ 
    dir.create(results_path)
  }else{
      print(paste0("The folder ", results_path, " already exists"))
    }
  
  ## create a folder  for blast results ----
  blast_path <- paste0(results_path,"/blast")
  if(!dir.exists(blast_path)){ 
    dir.create(blast_path)
  }else{
      print(paste0("The folder ", blast_path, " already exists"))
    }
  
  ##create a folder for swarm results ----
  swarm_path <- paste0(results_path,"/swarm")
  if(!dir.exists(swarm_path)){ 
    dir.create(swarm_path)
  }else{
      print(paste0("The folder ", swarm_path, " already exists"))
  }

  ## create a folder  for dmx results ----
  {
  dmx_path <- paste0(pipe_libs,"/dmx")
  if(!dir.exists(dmx_path)){ 
    dir.create(dmx_path)
  }else{
      print(paste0("The folder ", dmx_path, " already exists"))
    }
  ## folder for dmx files  
  if(!dir.exists(paste0(dmx_path,"/all_dmx"))){ 
    dir.create(paste0(dmx_path,"/all_dmx"))
  }else{
      print(paste0("The folder ", paste0(dmx_path,"/all_dmx"), " already exists"))
  }  
 ## folder for combined files per sample 
  if(!dir.exists(paste0(dmx_path,"/all_combined"))){ 
    dir.create(paste0(dmx_path,"/all_combined"))
    }else{
      print(paste0("The folder ", paste0(dmx_path,"/all_combined"), " already exists"))
    }
  }

}


list.files(analysis_path)
```

## Load Samples table

This is the most important input on the analysis, along with the raw data. The *Samples Table* holds the information of the samples file names, primers, controls, indexes, different projects. An example of this table can be found [here](https://docs.google.com/spreadsheets/d/1NoLrwmubmFdOFwA5LJ6DO08eUm-HwpjA5MgTw2mxS0M/edit?usp=sharing).

After filling in the table, save it as .csv an place it on the data folder, inside the project's main directory.

```{r, eval=FALSE,echo=TRUE}
# load primers indexes and samples table ----
primers_n_samples <- readr::read_csv(file = "~/prjcts/ecomol/analyses/2025/Sq_dez25/data/WayCarbon_EcoMol_Motiva--primers_n_samples.csv")


primers_n_samples %>% View()

# Check if file names are really unique ----
if (nrow(primers_n_samples) != length(unique(primers_n_samples$Unique_File_name))) {
  
  print("Your file names are not unique")
  print(paste0("The file names:"))
  print(paste0(primers_n_samples$Unique_File_name[duplicated(primers_n_samples$Unique_File_name)],collapse = "\n "))
  print(paste0("apear more than once"))
  
  } else if (nrow(primers_n_samples) != length(unique(primers_n_samples$Sample))) {
    
  print("Your Sample names are not unique")
  print(paste0("The sample names:"))
  cat(paste0(primers_n_samples$Sample[duplicated(primers_n_samples$Sample)],collapse = "\n "))
  print(paste0("apear more than once"))
  }else{
    
  print("All file names and sample names are unique!")
}


# defining all separate projects to analyze independently ----
{
  all_projects <- BiocGenerics::unique(primers_n_samples$Project) %>%
    stringr::str_split(pattern = ";",simplify = F) %>% 
    base::unlist() %>% 
    BiocGenerics::unique()
  
  
  paste0("This analysis will by split into separate projects for:", paste0(c("\t",all_projects) ,collapse = "\n\t")) %>% 
    cat() %>% 
    message()
  
  }
```

### Identify files names radicals and levels

```{r, eval=FALSE,echo=TRUE}
# if you need to print sample names and sort them yourself ----
primers_n_samples$Unique_File_name %>% paste0(collapse = '",\n"') %>% cat()

# organize sample names in the order they will be printed on plots and results tables ----
  # sample_levels <- c(primers_n_samples$Unique_File_name) %>% unique()
  sample_levels <- c(primers_n_samples$Sample) %>% unique()

  sample_levels
```

## Raw data aquisition

### Get reads from Base Sapce

This part is only required if your read files is on Basespace. If the read files are already downloaded and demultiplexed, place them on the *\$raw_libs* folder and proceed to the next section.

```{bash, eval=FALSE, echo=TRUE}
# 1 - create and navigate to run files folder ----
cd  ~/Sq_dez25/data/reads/;

# 2 - download run from BaseSpace ----
# 2a - autenticate to basespace (must have a basespace account and shared projects/runs)
bs auth;

# 2b - list your projects data ----
bs list projects -F Name -F DateModified;

# 2c - download demultiplexed read files

bs download project -n "EM195_Ovos_Larvas" -o fastq --extension=fastq.gz

# 3 - organize raw data ----
mv ~/Sq_dez25/data/reads/fastq/*gz ~/Sq_dez25/data/reads/raw; 

ls ~/Sq_dez25/data/reads/raw; 

```

## Demultiplexing

### Demultiplex with function

```{r, eval=FALSE,echo=TRUE}

source("~/prjcts/ecomol/R/dmx_metabar.R")

all_Libs <- primers_n_samples$Lib %>% BiocGenerics::unique()

for (LIB in all_Libs[1]) {
  

  primers_n_samples_lib <- primers_n_samples %>% 
    dplyr::filter(Lib %in% c(LIB))


raw_files <- primers_n_samples_lib$`Undemultiplexed path` %>% 
  BiocGenerics::unique() %>% 
  list.files(full.names = T) %>% 
  Sys.glob() %>%
  normalizePath()

out_path <- primers_n_samples_lib$`Raw data path` %>% 
  BiocGenerics::unique()

project <- primers_n_samples_lib$Project %>% 
  BiocGenerics::unique()


dmx_metabar(undmx_file_R1 = raw_files[1], #raw R1
            undmx_file_R2 = raw_files[2], #raw R2
            out_path = out_path, # pasta onde vai ser escrito todo output
            project = project, #nome do projeto, entre aspas tipo "eDNA_bromelias" sem acento nem espaço
            Unique_File_name = primers_n_samples_lib$Unique_File_name,  #coluna da tabela de configuração
            primers = primers_n_samples_lib$Primer,                     #coluna da tabela de configuração
            samples_names = primers_n_samples_lib$Sample,
            idxs_FWD_seqs = primers_n_samples_lib$`Index sequence FWD`, #coluna da tabela de configuração
            idxs_FWD_names = primers_n_samples_lib$`Index name FWD`,    #coluna da tabela de configuração
            idxs_REV_seqs = primers_n_samples_lib$`Index sequence REV`, #coluna da tabela de configuração
            idxs_REV_names = primers_n_samples_lib$`Index name REV`,    #coluna da tabela de configuração
            query_size = 12   #tamanho da sequencia a ser considerada do index + primer
            )
    
}
    
# 
# # 
# {
#   undmx_file_R1 = raw_files[1]
#   undmx_file_R2 = raw_files[2]
#   out_path = out_path
#   project = project
#   Unique_File_name = primers_n_samples_lib$Unique_File_name
#   samples_names = primers_n_samples_lib$Sample
#   primers = primers_n_samples_lib$Primer
#   idxs_FWD_seqs = primers_n_samples_lib$`Index sequence FWD`
#   idxs_FWD_names = primers_n_samples_lib$`Index name FWD`
#   idxs_REV_seqs = primers_n_samples_lib$`Index sequence REV`
#   idxs_REV_names = primers_n_samples_lib$`Index name REV`
#   query_size = 12
# }
    
```

### Quality control of sequencing data

```{r, eval=FALSE,echo=TRUE}
# check if the raw data paths you provided do have files ----
primers_n_samples$`Raw data path` %>% unique() %>% list.files()

# if from dmx data ----
read_files <- primers_n_samples %>%
  dplyr::select(Unique_File_name,`Raw data path`) %>%
  dplyr::mutate("Read file"  = paste0(`Raw data path`,"/", Unique_File_name,"*")) %>% 
  dplyr::pull("Read file") %>%
  Sys.glob() %>%
  normalizePath() %>%
  BiocGenerics::unique()

read_files


read_files %>%  Sys.glob() %>% file.exists() %>% sum()
read_files %>%  Sys.glob() %>% normalizePath() %>% unique()
read_files %>%  Sys.glob() %>% normalizePath()

# run fastqc and multiqc for all read files ----

for (PRJ in all_projects){

fastqc_path <- paste0(qual_path, "/", PRJ, "/fastqc") 
dir.create(path = fastqc_path, recursive = T) 
multiqc_path <- paste0(qual_path, "/", PRJ, "/multiqc") 
dir.create(path = multiqc_path, recursive = T) 

  raw_path <- primers_n_samples$`Raw data path`[primers_n_samples$Project == PRJ] %>%
    unique()
  # # 
  # raw_path <- "/data/data_raw/colab/Sq_dez25/raw"
  
  
# 1 - run FastQC for all read files ----
 
  # reads <- read_files[str_detect(string = read_files,pattern = raw_path)]
  # reads <- read_files[base::names(read_files) %in% c(PRJ)]
  reads <- read_files[stringr::str_detect(string = read_files,
                                 pattern = paste0(raw_path,
                                                  collapse = "|"))]
  
  for (sequence in reads) {
  
  system2(command = "find", args = c(
    paste0(sequence, " -name '*.gz' 2>/dev/null | parallel fastqc {1} -t 20 -o ", fastqc_path)))
  
}

# 2 - run MultiQC for all FastQC reports ----


  system2(command = "multiqc", args = c(
    paste0("--interactive ", fastqc_path, " --filename ", 
           multiqc_path, "/",
           PRJ,"--sequencing_quality-MultiQC_report.html"))
    )
}
```

### Primer detection and removal

### Identify files

To avoid merging reads that did no come from the same cluster (and create chimeras), we must check read pairing and remove unpaired (mandatory on DADA2 and cutadapt).

```{r, eval=FALSE,echo=TRUE}

read_files %>%   Sys.glob()

all_fnFs <- sort(list.files(dirname(read_files), 
                            pattern="_R1_001.fastq|_R1_001.fastq.gz|\\.1.fastq|\\.R1.fastq|\\R1.fq|\\R1.fastq|1.fq.gz|-R1.fastq.gz", full.names = TRUE)) %>% unique()

all_fnRs <- sort(list.files(dirname(read_files),  
                            pattern = "_R2_001.fastq|_R2_001.fastq.gz|\\.2.fastq|\\.R2.fastq|\\R2.fq|\\R2.fastq|2.fq.gz|-R2.fastq.gz", full.names = TRUE)) %>% unique()

length(all_fnFs)
length(all_fnRs)

all_fnFs
all_fnRs

#6- loading sample data (origin and indexes) ----
sample_idx_tbl_wide <- primers_n_samples %>% 
  dplyr::select(c("Unique_File_name", 
                  "Lib", 
                  "Run", 
                  "Project",
                  "Researcher",
                  "Sample",
                  "Primer",
                  "Type",
                  "Raw data path",
                  # starts_with("metadata"),
                  dplyr::ends_with("ontrol")))  %>%
  dplyr::mutate("FWD_R1" = "F-R1",
         "FWD_R2" = "F-R2")


for (sample in 1:nrow(sample_idx_tbl_wide)) {

  message("Workin on sample:")
  print(sample_idx_tbl_wide$Unique_File_name[sample])
  
    sample_idx_tbl_wide$FWD_R1[sample] <- all_fnFs[BiocGenerics::grep(pattern =  paste0(sample_idx_tbl_wide$`Raw data path`[sample],
                                                                          "/",sample_idx_tbl_wide$`Unique_File_name`[sample],"_"),
                                                                      x = all_fnFs)] %>% 
      BiocGenerics::unique()
    
    print(all_fnFs[BiocGenerics::grep(pattern =  paste0(sample_idx_tbl_wide$`Raw data path`[sample],
                                          "/",sample_idx_tbl_wide$`Unique_File_name`[sample],"_"),
                                      x = all_fnFs)])
    
    
    sample_idx_tbl_wide$FWD_R2[sample] <-  all_fnRs[BiocGenerics::grep(pattern =  paste0(sample_idx_tbl_wide$`Raw data path`[sample],
                                                                     "/",sample_idx_tbl_wide$`Unique_File_name`[sample],"_"),
                                                                     x = all_fnRs)] %>% 
      BiocGenerics::unique()
    
    print(all_fnRs[BiocGenerics::grep(pattern =  paste0(sample_idx_tbl_wide$`Raw data path`[sample],
                                          "/",sample_idx_tbl_wide$`Unique_File_name`[sample],"_"),
                                      x = all_fnRs)])
  
}


# 3 - Map sample names to reads files ----
sample_idx_tbl_wide %>% colnames()

sample_idx_tbl <- sample_idx_tbl_wide %>% 
  dplyr::mutate("FWD_R1_paired" = paste0(paired_libs,"/",Unique_File_name,"--FWD_R1_paired.fastq.gz"),
         "FWD_R2_paired" = paste0(paired_libs,"/",Unique_File_name,"--FWD_R2_paired.fastq.gz")) %>% 
  tidyr::pivot_longer(cols = c(
    "FWD_R1", "FWD_R2", "FWD_R1_paired", "FWD_R2_paired"),
    names_to = "Stage",
    values_to = "Read file") %>%
  dplyr::mutate("Unique_File_name_Primer" = Unique_File_name)

sample_idx_tbl

sample_idx_tbl$`Read file` %>% unique() %>% sort()


```

### Identify primers sequences

```{r, eval=FALSE,echo=TRUE}
#1 - identify primers ----

sample_idx_tbl$Primer %>% unique() %>% 
  stringr::str_split(pattern = ";") %>% 
  base::unlist() %>% 
  BiocGenerics::unique()

#primers sequences used for each sample -----
#              inosine pairs with A, C, U
#                                 T, G, A = IUPAC code:  D
#              cutadapt  accepts IUPAC code !!!!!!!!
#        https://www.bioinformatics.org/sms/iupac.html

# Name primers: Sq_dez25X_FWD or XXXxx-XXXX_REV

##### function to convert IUPAC sequences to regex ###----
iupac2seq <- function(dna_seq){
# reference IUPAC codes for nucleotides
  iupac_code <- c("A" = "A",
                "C" = "C",
                "G" = "G",
                "T" = "T",
                "Y" = "[CT]",
                "R" = "[AG]",
                "H" = "[ACT]",
                "M" = "[AC]",
                "K" = "[GT]",
                "S" = "[GC]",
                "W" = "[AT]",
                "B" = "[CGT]",
                "D" = "[AGT]",
                "V" = "[ACG]",
                "N" = "[ACGT]")
iupac_tbl <- tibble("Code" = names(iupac_code),
                    "Meaning" = iupac_code)

# Convert each character in the sequence
  regex_seq <- str_replace_all(dna_seq, iupac_code)

  return(regex_seq)  
}
#########################################################


{
all_primers <- c(
  #COI_R1 ----
  # COI_R1__FWD = "TCHACHAAYCAYAARGAYATYGG", #MG2-LCO1490_F
  # COI_R1__REV = "ACYATRAARAARATYATDAYRAADGCRTG",    #MG2-univ-R1
  # COI_R1__REV = "ARAARATYATDAYRAADGCRTG",    #MG2-univ-R1
  # 
  # #COIr2 ----
  # COIr2__FWD = "TCHACHAAYCAYAARGAYATYGG", #MG2-LCO1490_F
  # COIr2__REV = "ARTCARTTWCCRAAHCCHCC",    #fwhR1_R2
  # COIr2b__REV = "AYNARTCARTTHCCRAAHCC",   #CO1-CFMR-dege_R3
  
  # TM primers ----
  # #p16S ----
  # p16S__FWD = "CCTAYBBBRBGCASCAG",
  # p16S__REV = "GGACTACNNGGGTATCTAAT",
  # 
  #BF1BR2 ----
  # https://github.com/VascoElbrecht/JAMP/blob/master/JAMP/inst/primers.csv
  # BF1BR2__FWD = "ACWGGWTGRACWGTNTAYCC",
  # BF1BR2__REV = "TCDGGRTGNCCRAARAAYCA",

  #COI_FWh - fwhF2/fwhR2n ----
  ##  https://doi.org/10.3897/mbmg.1.14625      macroinvertebrates
  # COI_FWh__FWD = "GGDACWGGWTGAACWGTWTAYCCHCC",
  # COI_FWh__REV = "GTRATWGCHCCDGCTARWACWGG",


  # # #pITS ----
  # pITS__FWD = "CTTGGTCATTTAGAGGAAGTAA",
  # pITS__REV = "GCTGCGTTCTTCATCGATGC",s
  
  # # #NeoFish ----
  # neo__FWD = "CGCCGTCGCAAGCTTACCCT",
  # neo__REV = "AGTGACGGGCGGTGTGTGC",
  # 
  #12S-MiBird ----
#                                 MiBird__FWD = "GGGTTGGTAAATCTTGTGCCAGC",
                                # MiBird__FWD = "GGGTTGGTAAATYTYGTGCCAGC", # primer com os indexes multiplexados 2025
#                                 MiBird__REV = "CATAGTGGGGTATCTAATCCCAGTTTG",
                                # MiBird__REV = "CATAGTGGGGTATCTAATCCCAGTT", # primer com os indexes multiplexados 2025
  # # 
  # # #16S-Taylor/16SMam1 ----
  # p16SMam1__FWD = "TGCATCGGTTGGGGTGACCTCGGA",
  #                                 p16SMam1__FWD =        "CGGTTGGGGTGACCTCGGA",
  # p16SMam1__REV = "TGCATGCTGTTATCCCTAGGGTAACT",
  # p16SMam1__REV =               "TCCCTAGGGTAACT",
  #                                 p16SMam1__REV =       "GCTGTTATCCCTAGGGTAACT",
  
  # #fwh2 (COI) ----
  # fwh2__FWD = "GGDACWGGWTGAACWGT",
  # fwh2__REV = "GTRATWGCHCCDGCTARWACWGG",
  
  #MiFish ----
  # for i in `ls EM149*`; do zcat ${i} | grep -c "GTCGGTAAAACTCGTGCCAGC"; done
  # for i in `ls EM149*`; do zcat ${i} | grep -c "TGCATCATAGTGGGGTATCTAATCCCAGTTG"; done
  # for i in `ls EM149*`; do zcat ${i} | grep -c "CATAGTGGGGTATCTAATCCCAGTTTG"; done
  # for i in `ls EM197*`; do zcat ${i} | grep -c "CATAGTGGGGTATCTAATCCCAGTTTC"; done
  
  # MiFish2__FWD =            "GCCGGTAAAACTCGTGCCAGC",
  # MiFish2__FWD =         "GTCGGTAAAACTCGTCCAGC",
   # MiFishEM__FWD =          "GTCGGTAAAACTCGTGCCAGC", #2025 versão Ecomol Paranaíba e MiFish RJ & SP e Juliana q tem um G a mais no meio   ????
   # MiFishEMs__FWD =         "GTCGGTAAAACTCGTGCCAGC",
     # MiFish__FWD =         "AAACTCGTGCCAGC", #2025 REDUZIDA
  # # MiFish__REV =    "TGCATCATAGTGGGGTATCTAATCCCAGTTG",
  #     MiFish2__REV =                      "CATAGTGGGGTATCTAATCCCAGTTTG", # versão Ecomol Paranaíba e MiFish RJ & SP e Juliana
  # MiFishEMs__REV =                        "CATAGTGGGGTATCTAATCCCAGTT", #2025 versão Ecomol R.Baggio
  # MiFishEM__REV =                         "CATAGTGGGGTATCTAATCCCAGTTTG", #2025 versão Ecomol R.Baggio
  # MiFish__REV =                        "TCTAATCCCAGTTTG", #2025 versão Ecomol R.Baggio
  # MiFish__REV =          "CATAGTGGGGTATCTAATCCCAGTTTC", # versão Sq_dez25
    # MiFish2__REV =        "CATAGTGGGGTATCTAATCCCAGTTG", #versão reduzida
    # # MiFishE ----
  # MiFishE__FWD <- "RGTTGGTAAATCTCGTGCCAGC",
  # MiFishE__REV <-     "GCATAGTGGGGTATCTAATCCTAGTTTG",
 
  #COI-1 ----
  # C1__FWD <- "GGWACWGGWTGAACWGTWTAYCCYCC",
  # # C1__REV <- "TAIACYTCIGGRTGICCRAARAAYCA",
  # C1__REV <-   "TADACYTCDGGRTGDCCRAARAAYCA",
  # 
  # #COI-3 ----
  # C3__FWD <- "ACYAAICAYAAAGAYATIGGCAC",
  # C3__FWD <-   "ACYAADCAYAAAGAYATDGGCAC",
  # # C3__REV <- "CTTATRTTRTTTATICGIGGRAAIGC",
  # C3__REV <-   "CTTATRTTRTTTATDCGDGGRAADGC",
  # 
  # #COI-Inseto ----
  # CI__FWD <- "GGTACATTCAACCAATCATAAAGATATTGG",
  # CI__REV <- "GGGTACCGTGGAAAWGCTATATCWGGTG",
  # 
  # #COI-Lep (quase igual COI-Inseto) ----
  # Clep__FWD <- "ATTCAACCAATCATAAAGATATTGG",
  # Clep__REV <- "CGTGGAAAWGCTATATCWGGTG",
  
  # MiMammal-U-12S ----
    #                  https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-11-434/tables/1
  # mmu__FWD <- "GGGTTGGTAAATTTCGTGCCAGC",
  # mmu__REV <- "CATAGTGGGGTATCTAATCCCAGTTTG",
  
  # #Elas02 ----
  # Elasm02__FWD <- "GTTGGTHAATCTCGTGCCAGC",
  # Elasm02__REV <- "CATAGTAGGGTATCTAATCCTAGTTTG",
  
  # Coquetel de COI para peixes - Coq_Fish ----
  #Fish1 ----
  # "Fish1__FWD" = "TCAACCAACCACAAAGACATTGGCAC",
  # "Fish1__REV" = "TAGACTTCTGGGTGGCCAAAGAATCA",
  #Fish2 ----
  # "Fish2__FWD" = "TCGACTAATCATAAAGATATCGGCAC",
  # "Fish2__REV" = "ACTTCAGGGTGACCGAAGAATCAGAA",
  #
  # #VF2_FR1d ----
  # "VF2_FR1d__FWD" = "CAACCAACCACAAAGACATTGGCAC",
  # "VF2_FR1d__REV" = "ACCTCAGGGTGTCCGAARAAYCARAA",
  
  # # 12S Vertebrados ----
  #   ################################### zgrep -c "TTAGATACCCCACTATGC" *V5*gz
                                  # p12SV5inv__FWD = "TAGAACAGGCTCCTCTAG", # usar sempre nas analises dual PCR
                                  # p12SV5inv__REV = "TTAGATACCCCACTATGC",

                                  p12SV5__FWD = "TTAGATACCCCACTATGC", # sempre conferir onde o FWD está sendo encontrado
                                  p12SV5__REV = "TAGAACAGGCTCCTCTAG",



  #     #https://academic.oup.com/nar/article/39/21/e145/1105558?login=true   ORIGINAL Riaz et al. 2011, tb está trocado FWD REV
      #https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13485    #neste o 12SV5 está trocado FWD REV
  
  # #trnL (UAA) - Plantas  ----
  # trnLg_F = "GGGCAATCCTGAGCCAA",
  # trnLh_R = "CCATTGAGTCTCTGCACCTATC",
  
  #Mini_SH_E  (Mistura do COI-3-fwd com o MiFish-rev) ----
  # Mini_SH_E_F = "ACYAAICAYAAAGAYATIGGCAC",
  # Mini_SH_E_F = "ACYAADCAYAAAGAYATDGGCAC",
  # Mini_SH_E_R = "CATAGTGGGGTATCTAATCCCAGTTG",
  # 
  # #16S MAV - Invertebrados  ----
  # p16SMAV_F = "CCAACATCGAGGTCRYAA",
  # p16SMAV_R = "ARTTACYNTAGGGATAACAG",
  # 
  # #COI_minibar ----
  # minibar_F1 = "TCCACTAATCACAARGATATTGGTAC",
  # minibar_R1 = "GAAAATCATAATGAAGGCATGAGC",
  # # 
  # # #COI-ZBJ-Art ----
  # # COIZBJart_F1c
  # COIZBJart__FWD = "AGATATTGGAACWTTATATTTTATTTTTGG",
  # # COIZBJart_R2c
  # COIZBJart__REV = "WACTAATCAATTWCCAAATCCTCC",
  # # 
  # # #Mini COI ----
  # miniCOI__FWD = "ATCACCACTATTGTTAATATAAAACCC",
  # miniCOI__REV = "TAAACCTCAGGATGTCCGAAGAATCA",
  
  # p12SBatra - 12S anuros
  #                                 p12SBatra__FWD = "ACACCGCCCGTCACCCT",
  #                                 p12SBatra__REV = "GTAYACTTACCATGTTACGACTT",
  # p12SBatra__REV    "GTAYACTTATGTTACTT",
  # Reptile ----
  #                                 Reptile__FWD =     "AGACNAGAAGACCCTGTG",
  #                                 Reptile__REV =     "CCTGATCCAACATCGAGG",
  # p16SV4  ----
                                  # p16SV4__FWD =     "GTGCCAGCMGCCGCGGTAA",
                                  # p16SV4__REV =     "GGACTACHVGGGTWTCTAAT",
  # p18sEuk ----
                                  # p18sEuk__FWD =     "GTACACACCGCCCGTC",
                                  # p18sEuk__REV =     "TGATCCTTCTGCAGGTTCACCTAC",
# 
#   VertU ----
#   https://doi.org/10.3389/fevo.2023.1164206
  # #######  (ERRADOS! primieira leva Ecomol GBB)---
  # #V12Su ----
   V12Su__FWD = "GTGCCAGCNRCCGCGGTYANAC",
   V12Su__REV = "ATATRGGGTATCTAATCCYAGT",
  #V16Su ---
   V16Su__FWD = "ACGAGAAGACCCYRYGRARCTT",
   V16Su__REV = "TCTHRRANAGGATTGCGCTGTTA",
  #VCOIu ---
   VCOIu__FWD = "CAYGCHTTTGTGNATRATYYTYTT",
   VCOIu__REV = "GGRGGRTADACDGTYCANCCNGT",

  # ### Originais ----
  # # # #V12Su  ()--- 
  #  V12Su__FWD = "GTGCCAGCNRCCGCGGTYANAC",
  #  V12Su__REV = "ATAGTRGGGTATCTAATCCYAGT",
  # #V16Su ---
  #  V16Su__FWD = "ACGAGAAGACCCYRYGRARCTT",
  #  V16Su__REV = "TCTHRRANAGGATTGCGCTGTTA",
  # #VCOIu ---
  #  VCOIu__FWD = "CAYGCHTTTGTNATRATYTTYTT",
  #  VCOIu__REV = "GGRGGRTADACDGTYCANCCNGT",










  " " = NA
  ) %>% 
  stats::na.omit()

 all_primers

 # creates a list of single row tibbles for each primer ----
primers_list <- tibble("Primer seq" = all_primers,
                  "Primer name" =  names(all_primers)) %>% 
  split(1:nrow(.)) 
}


primers_list




all_primers_tbl <- tibble::tibble("Primer" = names(all_primers),
                                  "IUPAC Sequence" = all_primers) %>% 
  dplyr::mutate("regex sequence" = iupac2seq(`IUPAC Sequence`))

all_primers_tbl

```

<br>

<br>

### Generate sequences for complement, reverse and reverse complement of each primer

The function *allOrients* is used to generate all possible orientations for primers FWD e REV.

```{r eval=FALSE,echo=TRUE}
# 1 - generate all possible primer orientations ----

#function to get all possible primer orientations ----

####################################FUNCTION####################################
allOrients <- function(primers_list) {
   # Create all orientations of the input sequence
    # Must be a tibble with cols = c(Primers,`Primer name`)
  
   require(Biostrings)
   dna <- Biostrings::DNAString(primers_list$`Primer seq`)  # The Biostrings works w/ DNAString objects rather than character vectors
   orients <- c(Forward = dna, 
                Complement = Biostrings::complement(dna), 
                Reverse = Biostrings::reverse(dna),
                RevComp = Biostrings::reverseComplement(dna))
   
   names(orients) <- paste0(names(orients))
   
   primer_tbl <- sapply(orients, toString)
   
   primer_tbl <- tibble::tibble(Sequence = primer_tbl,
                                `Primer orientation` = base::names(primer_tbl)) %>% 
     dplyr::mutate(`Primer` = primers_list$`Primer name`) %>%
     tidyr::unite(col=`Orientation name`, `Primer` ,`Primer orientation`,remove = FALSE) %>% 
     dplyr::mutate(`Primer pair` = str_remove_all(string = Primer,
                                                  pattern = "__.*.$")) %>% 
     dplyr::mutate("Parsed sequence" = iupac2seq(Sequence))
                   
                   base::names(primer_tbl$Sequence) <- primer_tbl$`Orientation name`
                   
                   return(primer_tbl)  # Convert back to character vector
}
################################################################################

# 2 - Apply function to generate table with all primers orientations possible
primers_all_orients <- purrr::map_dfr(primers_list, allOrients)

primers_all_orients <- primers_all_orients %>% mutate(`Primer pair` = str_remove_all(string = Primer,
                                                              pattern = "__.*.$"))

#check naming
primers_all_orients$Sequence
      base::names(primers_all_orients$Sequence)
```

<br>

### Count primer presence on reads

Before primer removal it is possible to count their presence on the reads. This procedures is carried on independently for each sample. By doing this, you make sure that you are looking for the correct primers sequences on your samples.

```{r eval=FALSE}
# 1 - prepare to count primer orientation hits ----

# 1a - Load required functions ----

####################################FUNCTION####################################
#function to count primer on each specific library
primerHits <- function(primer, file_name) {
   # Counts number of reads in which the primer is found
   nhits <- Biostrings::vcountPattern(primer, 
                                      ShortRead::sread(ShortRead::readFastq(file_name)), 
                                      fixed = FALSE,
                                      max.mismatch = 1)
   
   return(sum(nhits > 0))
}
################################################################################

####################################FUNCTION####################################
#function to call primerHits for multiple primers
multi_primerHits <- function(Read_file,primers){
  primer_counts <- purrr::map_df(primers,
                                 .f = primerHits, 
                                 file_name = Read_file)
  
  primer_counts <- primer_counts %>% 
    dplyr::mutate(`Read file` = Read_file)
  
  return(primer_counts)
}
################################################################################

sample_idx_tbl$Stage %>% unique()


# 2b - Create vector of read files to look on for primers ----
reads_seqs_tbl <- sample_idx_tbl %>% 
  filter(Stage %in% c("FWD_R1", "FWD_R2")) %>% 
  dplyr::select(`Read file`,Unique_File_name) 

# 2c - Create a named vector for reads files ----
reads_seqs <- reads_seqs_tbl$`Read file`

names(reads_seqs) <- reads_seqs_tbl$Unique_File_name

reads_seqs

reads_seqs %>% unique()
reads_seqs %>% lengths()

# 2d - named vector of primer sequences ----
# primers_seqs <- primers_all_orients %>% pull(Sequence,name = `Orientation name`)
primers_seqs <- primers_all_orients %>% pull(Sequence,name = `Orientation name`)

# 2e - Set up for parallel searching ----
cores_to_be_used <- future::availableCores() - 2 # Usar todos os cores -2 = 78

future::plan(future::multisession(workers = cores_to_be_used))

# 3 - Count primers on reads ----
primers_in_Nreads <- furrr::future_map_dfr(reads_seqs,
                                           .f = multi_primerHits, 
                                           primers = primers_seqs, 
                                           .options = furrr::furrr_options(seed = NULL))

# 4 - identify which primers were found on most reeads ----
dim(primers_in_Nreads)

colSums(primers_in_Nreads[,1:length(primers_seqs)]) %>% sort()


#get sample information into primers_in_Nreads table ----
primers_in_Nreads <- dplyr::left_join(primers_in_Nreads,sample_idx_tbl,
                               by = "Read file") %>% 
  dplyr::mutate(Read = if_else((str_detect(Stage,
                                    pattern = "R1")),
                        "R1",
                        "R2")) %>% 
  # mutate(Unique_File_name = factor(Unique_File_name,levels = sample_levels)) %>%
  tidyr::unite(col = "Unique_File_name_Read", sep = " ", remove = FALSE,
        Unique_File_name,Read) 

# count numbers of reads in original RAW files ----
primers_in_Nreads <- primers_in_Nreads %>% 
  dplyr::mutate(`Total reads` =  ShortRead::countFastq(dirPath = .$`Read file`)[,1])


for (PRJ in all_projects){

  primers_in_Nreads %>% 
    dplyr::filter(Project %in% c(PRJ)) %>% 
    write.csv(file = paste0(results_path,"/",
                            PRJ,"--primers_found_in_reads.csv"))
  }
# 6- Remove columns(primers) not found in any sample

#Identify empty counts
colnames(primers_in_Nreads) #choose only numeric columns (primer counts)
colnames(primers_in_Nreads[1:length(primers_seqs)]) #choose only numeric columns (primer counts)
colSums(primers_in_Nreads[1:length(primers_seqs)]) # dá pra excluir do plot se tiver zero counts
(colSums(primers_in_Nreads[1:length(primers_seqs)]) == 0)#transformando em um vetor logico
colnames(primers_in_Nreads)[(colSums(primers_in_Nreads[1:length(primers_seqs)]) != 0)]#transformando em um vetor logico

```

### Plot primers identified in each sample

```{r, echo=TRUE,eval=FALSE}
#8 - prepare primer counts for plots in ggplot----

primers_all_orients$`Orientation name`

primers_in_Nreads %>% colnames() %>%  paste0(collapse = '",\n') %>% cat()

#convert primer hits table to long format
primers_in_Nreads_long <- primers_in_Nreads %>% 
  dplyr::select(!dplyr::ends_with(c("_Complement",
                   "_Reverse"))) %>% 
  gather(key = Sequences, 
         value = Count, 
         ends_with("FWD_Forward"),
         ends_with("FWD_RevComp"),
         ends_with("REV_Forward"),
         ends_with("REV_RevComp")
                  ) %>% 
  dplyr::mutate(Sequences = as.factor(Sequences),
         Unique_File_name = factor(Unique_File_name,levels = sample_levels)) %>% 
  dplyr::select(-c("Read file","Stage")) %>% 
  dplyr::select(where(function(x) any(!is.na(x)))) %>% 
  dplyr::filter(Count != 0) 
  

# PLOT 1: primers counts in readstile plot - only primers FWD & REV, foward & revcomp ----

library(viridis)
library(ggh4x)

#create levels for Files display on plot ----
Unique_File_name_Read_levels <- primers_in_Nreads_long %>% 
  # mutate("Metadata 12" = as.numeric(`Metadata 12`)) %>% 
  # arrange(`Metadata 12`) %>% 
  pull(Unique_File_name_Read) %>% unique()



for (PRJ in all_projects) {

options(scipen=10000)

# PRJ <- "Rio das Velhas"

project_name <- PRJ %>% 
  str_replace_all(pattern = " ",
                  replacement = "_") %>% 
  str_replace_all(pattern = "_-_",
                  replacement = "--")

PRJ_primers <- primers_in_Nreads_long %>% 
  dplyr::filter(Project %in% c(PRJ)) %>% 
  dplyr::pull(Primer) %>% 
  BiocGenerics::unique() %>% 
  str_split(pattern = ";",simplify = F) %>% 
  base::unlist() %>% 
  BiocGenerics::unique()
  
N_samples <-   primers_in_Nreads_long %>%
  dplyr::filter(Project %in% c(PRJ)) %>% 
  pull(Unique_File_name_Read) %>% unique() %>% length()

primers_tile <- primers_in_Nreads_long %>%
  dplyr::filter(Project %in% c(PRJ)) %>% 
  # dplyr::filter(str_detect(string = Sequences, 
  #                          pattern = paste0(PRJ_primers,collapse = "|"))) %>% 
  # dplyr::mutate(Unique_File_name_Read = factor(Unique_File_name_Read, levels = Unique_File_name_Read_levels)) %>%
  dplyr::mutate(Sequences = stringr::str_replace_all(Sequences,pattern = "__|_",replacement = "\n")) %>% 
  dplyr::mutate(Primer = stringr::str_replace_all(Primer,pattern = ";",replacement = "\n")) %>% 
  # ggplot2::ggplot(aes(y = interaction(Unique_File_name,Read,sep = " - "),
  # ggplot2::ggplot(aes(y = interaction(Unique_File_name_Read,Sample,sep = " - "),
  ggplot2::ggplot(aes(y = Unique_File_name_Read,
  # ggplot2::ggplot(aes(y = Sample,
                      # x = Sequences,
                      fill = (Count/`Total reads`*100),
                      group =`Primer`,alpha = 0.05)) +
  geom_bar(aes(
    x = `Total reads`,
    col = `Primer`,
    group = Sequences), 
    stat = "identity",
    position = "dodge",
            linewidth = 0.05, 
            linetype = 2) +
  # geom_tile(aes(
  #   col = `Primer`), 
  #           linewidth = 0.05, 
  #           linetype = 2) +
  geom_text(aes(
    x = `Total reads`,
    label = Count), 
    hjust = 0,
            size=1) +
  scale_fill_gradientn(name = "Proportion of reads\n     with primer (%)",
                       colours = c("white","red","yellow","green","dark green"),
                       values = c(0,1),
                       na.value ="white") +
  # scale_colour_manual(values = c("#233fdb","#ff3455","#2c9400")) +
  # scale_colour_manual(values = viridis::turbo(n = length(unique(primers_in_Nreads_long$Sequences))/8)) +
  guides(color = guide_legend(override.aes = list(fill = "white", 
                                                  size = 10))) +
  theme_light(base_line_size = 0.025,
              base_size = 6) +
  theme(axis.text.x = element_text(angle = 45,hjust = 1)) + 
  # geom_vline(xintercept = c(4.5,8.5,12.5,16.5,20.5,24.5),color = "black") +
  geom_hline(yintercept = seq(0.5,300,2),color = "darkgrey") +
  xlab("Primers") +
  ylab("Amostra") +
  scale_y_discrete(limits=rev) +
  scale_x_log10(breaks = c(10,100,1000,10000,100000),
               expand = expansion(mult = c(0, 0.2))) +
  # ggtitle(label = paste0("Ecomol - ",analysis_rad, " - ", PRJ),
  # ggtitle(label = paste0("LGC - ", PRJ),
  # ggtitle(label = paste0("EcoMol - ", PRJ),
  ggtitle(label = paste0(PRJ),
              subtitle = "Presença de primers nas amostras:\n    intensidade de cor relativa à contagem do respectivo primer no conjunto de reads\n(max. mismatch = 1)") +
  theme(strip.text.y = element_text(size = 10),
        plot.title = element_text(size=10),
        plot.subtitle = element_text(size=6),
        axis.text.x = element_text(size=6),
        legend.text= element_text(size=5),
        legend.title = element_text(size=7))+ scale_alpha(guide = 'none') +
  # facet_grid(rows = vars(Researcher,Primer),
  facet_grid(rows = vars(Primer),
             cols = vars(Sequences),
             scales = "free",
             space = "free")

# primers_tile


# ggsave(file = paste0(results_path,"/",analysis_rad,"-primers_found_in_reads_1e.pdf"),
ggsave(file = paste0(results_path,"/",
                     PRJ,"-primers_found_in_reads_1e.pdf"),
     plot = primers_tile,
     device = "pdf",
     width = 10 + (length(PRJ_primers)*10),
     height = (N_samples*0.3)+3,
     units = "cm",limitsize = F,
     dpi = 300)

}



#once generated, it is necessary to check if the FWD and REV primers orientation is correct.
#   if not, change the script as in:    https://benjjneb.github.io/dada2/ITS_workflow.html

# When the amplicon is shorter than the reads is expected the FWD primer
#  to be found in the forward reads in its forward orientation,
#    and in some of the reverse reads in its reverse-complement orientation
#    (due to read-through when the ITS region is short).
# Similarly the REV primer is found with its expected orientations.
#
# Note: Orientation mixups are a common trip-up. If, for example,
#    the REV primer is matching the Reverse reads in its RevComp orientation,
#    then replace REV with its reverse-complement orientation
# (REV <- REV.orient[["RevComp"]]) before proceeding.
```

#### Show figure on html

```{r, eval=TRUE,echo=TRUE, results='asis'}
# Extract the PDF path from the R object

pdf_info <- 
  list.files(path = "~/Sq_dez25/results",
             pattern = "primers_found_in_reads",
             full.names = T)

  
# Generate the iframe HTML code
cat(paste0('<iframe src="', pdf_info, '" width="1200" height="800"></iframe>'))
```

### Count primers on reads if anything is missing

```{r eval=FALSE,echo=TRUE}


```

## ***DADA2***

### Repairing reads

We will now generate file paths for the reads that will be repaired with DADA2. This paths will be passed to a parallelized version of DADA2 function.

```{r, eval=FALSE,echo=TRUE}

primer_paired_files <- sample_idx_tbl %>% 
    filter(str_detect(string = Stage,
                      pattern = "FWD_R1|FWD_R2|FWD_R1_paired|FWD_R2_paired")) %>% 
    pivot_wider(id_cols = c("Unique_File_name","Primer","Lib"),
                names_from = "Stage",
                values_from = "Read file") 



primer_paired_files



primer_paired_files$FWD_R1 %>% BiocGenerics::basename()
primer_paired_files$FWD_R1_paired %>% basename()


# Repairing in parallell ----

##############Function to repair and filter reads after demultiplexing (from CDI or not)

####################################FUNCTION####################################
repairNfilt_with_DADA2 <- function(Unique_File_name,
                                   FWD_R1_in,
                                   FWD_R2_in,
                                   FWD_R1_out,
                                   FWD_R2_out){
  #FWD oriented amplicon
  all_filtered_out <- tibble()
  
    if(sum(file.exists(FWD_R1_in)) && sum(file.exists(FWD_R2_in))){
      
      print(paste0("      FWD orientation"))
      print(paste0("Working on file: ", Unique_File_name))
      
      sample_filtered_out <- tibble()
      
      sample_filtered_out <- dada2::filterAndTrim(
        fwd = FWD_R1_in,
        filt = FWD_R1_out,
        rev = FWD_R2_in,
        filt.rev = FWD_R2_out,
        maxN = c(0,0),
        maxEE = c(20,20),
        multithread = T,
        matchIDs = TRUE,
        rm.phix = TRUE,
        compress = TRUE,
        minLen = 30,
        verbose = TRUE)
      
      sample_filtered_out <- sample_filtered_out %>%
        as_tibble() %>%
        dplyr::mutate("Unique_File_name" = Unique_File_name
               # ,
               # "Orientation" = "FWD"
               )
      }else{
        print(paste0("The files ",FWD_R1_in," or ",FWD_R2_in,"do not exist!"))
        
        }

  all_filtered_out <- bind_rows(all_filtered_out,sample_filtered_out)
  
  return(all_filtered_out)
}

################################################################################

#using the function ----
# Versões paralelas
cores_to_be_used <- future::availableCores() - 2 # Usar todos os cores -2 = 78

future::plan(future::multisession(workers = cores_to_be_used))



tictoc::tic()
all_filtered_out_fun <- repairNfilt_with_DADA2(Unique_File_name = primer_paired_files$Unique_File_name,
                                              FWD_R1_in = primer_paired_files$FWD_R1,
                                              FWD_R2_in = primer_paired_files$FWD_R2,
                                              FWD_R1_out = primer_paired_files$FWD_R1_paired,
                                              FWD_R2_out = primer_paired_files$FWD_R2_paired)
tictoc::toc()


# generate a table counting the number of paired reads ----
all_filtered_out <- all_filtered_out_fun %>% 
  mutate(prop = round((reads.out/reads.in*100),digits = 2)) %>% 
  dplyr::rename("Raw reads (pairs)" = "reads.in",
         "Paired reads"  = "reads.out",
          "Proportion" = "prop")



all_filtered_out
```

## ***Cutadapt*** - Primer removal

The ***cutadapt*** software ([DOI:10.14806/ej.17.1.200](http://journal.embnet.org/index.php/embnetjournal/article/view/200)) is also used for primer removal from read sequences.

#### Create output file names for cutadapt

```{r eval=FALSE}
sample_idx_tbl$Stage %>% unique()

sample_idx_tbl$`Read file` %>% unique()

#10 - map sample names to cutadapt reads files ----
#name outputs
paired_files_per_primer <- sample_idx_tbl  %>% 
  dplyr::filter(Stage %in% c("FWD_R1_paired","FWD_R2_paired")) %>% # select paired files
  dplyr::filter(file.exists(`Read file`))
  
  
  
cut_files_per_primer <- paired_files_per_primer %>%  
  mutate(Stage = gsub(Stage, pattern = "_paired",replacement = "_cutadapt")) %>% 
  mutate("Read file" = str_replace_all(string = `Read file`,
                                       pattern = "paired",
                                       replacement ="cutadapt")) 


  
# apenas se for separar por primer ----  #####################################################
  cut_files_per_primer <- cut_files_per_primer %>% 
  separate_longer_delim(cols = "Primer",     
                        delim = ";") %>% 
  mutate("Read file" = case_when(Stage %in% c("FWD_R1_cutadapt","FWD_R2_cutadapt") ~
                                   str_replace_all(string = `Read file`,
                                                   pattern = paste0(cutadapt_libs,"/"),
                                                   replacement = paste0(cutadapt_libs,"/",.$Primer,"--")),
                                 TRUE ~ `Read file`))
  
  
  

  cut_files_per_primer <- bind_rows(cut_files_per_primer, 
                                    paired_files_per_primer)



#create cutadapt flags from identified primers
#all -----
  primers_all_orients$Primer %>% unique()
#remove primers and filter only the reads that contain the expected primer ----
#prepare cutadapt flags specific for each primer


```

#### Generate and execute primer-specific commands

```{r eval=FALSE}

primer_sets <- primers_all_orients$`Primer pair` %>% 
  BiocGenerics::unique()




for (PRIMER_SET in primer_sets) {
#   
#   PRIMER_SET <- "MiFish2"
#   
# }


# PRIMER_SET__ ----

# select the respective orientations found to create cutadapt flags
 PRIMER_SET__FWD.orients <-  primers_all_orients$Sequence[primers_all_orients$`Orientation name` %>%
                                                    grep(pattern = paste0(PRIMER_SET,"__FWD_Forward"))]

 PRIMER_SET__FWD.RC <-  primers_all_orients$Sequence[primers_all_orients$`Orientation name` %>%
                                                grep(pattern = paste0(PRIMER_SET,"__FWD_RevComp"))]

 PRIMER_SET__REV.orients <-  primers_all_orients$Sequence[primers_all_orients$`Orientation name` %>%
                                                    grep(pattern = paste0(PRIMER_SET,"__REV_Forward"))]

 PRIMER_SET__REV.RC <-  primers_all_orients$Sequence[primers_all_orients$`Orientation name` %>%
                                               grep(pattern = paste0(PRIMER_SET,"__REV_RevComp"))]

# creat flags
 # Trim FWD and the reverse-complement of REV off of R1 (forward reads)
 PRIMER_SET__R1.flags <- paste0("-g ", PRIMER_SET__FWD.orients, " -a ", PRIMER_SET__REV.RC)
 # PRIMER_SET__R1.flags <- paste0('-g "', PRIMER_SET__FWD.orients, ';min_overlap=',nchar(PRIMER_SET__FWD.orients),'"',
 #                                
 #                                ' -a "', PRIMER_SET__REV.RC,';min_overlap=',nchar(PRIMER_SET__REV.RC),'"'
 #                                )

 # Trim REV and the reverse-complement of FWD off of R2 (reverse reads)
 PRIMER_SET__R2.flags <- paste0("-G ", PRIMER_SET__REV.orients, " -A ", PRIMER_SET__FWD.RC)
 # PRIMER_SET__R2.flags <- paste0('-G "', PRIMER_SET__REV.orients, ';min_overlap=',nchar(PRIMER_SET__REV.orients),'"',
 #                                
 #                                ' -A "', PRIMER_SET__FWD.RC,';min_overlap=',nchar(PRIMER_SET__FWD.RC),'"'
 #                                )

 PRIMER_SET__R1.flags
 PRIMER_SET__R2.flags

# reads files ----
  PRIMER_SET_cut_files <- cut_files_per_primer %>%
    filter(str_detect(string = Primer,pattern = PRIMER_SET)) %>%
    # pivot_wider(id_cols = c("Unique_File_name","Unique_File_name_Primer","Primer"),
    pivot_wider(id_cols = c("Unique_File_name","Unique_File_name_Primer"),
                names_from = "Stage",
                values_from = "Read file")

PRIMER_SET__fnFs.cut <- PRIMER_SET_cut_files$FWD_R1_cutadapt
names(PRIMER_SET__fnFs.cut) <- PRIMER_SET_cut_files$Unique_File_name
PRIMER_SET__fnRs.cut <- PRIMER_SET_cut_files$FWD_R2_cutadapt
names(PRIMER_SET__fnRs.cut) <- PRIMER_SET_cut_files$Unique_File_name
PRIMER_SET__fnFs.paired <- PRIMER_SET_cut_files$FWD_R1_paired
names(PRIMER_SET__fnFs.paired) <- PRIMER_SET_cut_files$Unique_File_name
PRIMER_SET__fnRs.paired <- PRIMER_SET_cut_files$FWD_R2_paired
names(PRIMER_SET__fnRs.paired) <- PRIMER_SET_cut_files$Unique_File_name


# PRIMER_SET__fnFs.cut <- PRIMER_SET__fnFs.cut[file.exists(PRIMER_SET__fnFs.cut)]
# PRIMER_SET__fnRs.cut <- PRIMER_SET__fnRs.cut[file.exists(PRIMER_SET__fnRs.cut)]
PRIMER_SET__fnFs.paired <- PRIMER_SET__fnFs.paired[file.exists(PRIMER_SET__fnFs.paired)]
PRIMER_SET__fnRs.paired <- PRIMER_SET__fnRs.paired[file.exists(PRIMER_SET__fnRs.paired)]







# PRIMER_SET__ ----
for(i in seq_along(PRIMER_SET__fnFs.cut)) {
  system2(cutadapt, args = c(PRIMER_SET__R1.flags,
                             PRIMER_SET__R2.flags,
                             "-e 0.1", #error tolerance of 10%
                             "-j 70",
                             "-n", 5, # -n 2 required to remove FWD and REV from reads !!!!!!!!3
                             "-o", PRIMER_SET__fnFs.cut[i], # output files
                             "-p", PRIMER_SET__fnRs.cut[i],
                             PRIMER_SET__fnFs.paired[i],  # input files
                             PRIMER_SET__fnRs.paired[i],
                             # "--pair-adapters",
                             "--minimum-length 30 --discard-untrimmed --match-read-wildcards --pair-filter=both"
                             )) # guarantee no zerolength reads
}



}


```

## Repairing after primer removal

To avoid merging reads that did no come from the same cluster, we must check read pairing and remove unpaired (mandatory on DADA2). Sometimes cutadapt will not output paired reads, so this check must be performer again.

```{r, eval=FALSE,echo=TRUE}

repair_files_per_primer <- cut_files_per_primer %>% 
  dplyr::filter(stringr::str_detect(string = Stage , pattern = "_cutadapt")) %>% 
  dplyr::filter(file.exists(`Read file`)) %>% 
  tidyr::pivot_wider(id_cols = c("Unique_File_name","Unique_File_name_Primer","Primer","Run"),
                names_from = "Stage",
                values_from = "Read file") %>% 
  dplyr::mutate("FWD_R1_repaired" = stringr::str_replace_all(string = FWD_R1_cutadapt, 
                                                             pattern = "cutadapt",
                                                             replacement = "repaired"),
                "FWD_R2_repaired" = stringr::str_replace_all(string = FWD_R2_cutadapt, 
                                                             pattern = "cutadapt",
                                                             replacement = "repaired")) %>% 
  tidyr::unite(col = "Unique_File_name_Primer",                   
                   sep = "--", 
                   remove = F,
                   Unique_File_name, Primer)



# Versões paralelas
cores_to_be_used <- future::availableCores() - 2 # Usar todos os cores -2 = 78
future::plan(future::multisession(workers = cores_to_be_used))


all_filtered_out 


repair_files_per_primer$FWD_R1_cutadapt %>% file.exists()
repair_files_per_primer$FWD_R2_cutadapt %>% file.exists()
repair_files_per_primer$FWD_R1_repaired %>% file.exists()
repair_files_per_primer$FWD_R2_repaired %>% file.exists()


tictoc::tic()
all_filtered_out_fun_repaired2 <- 
  repairNfilt_with_DADA2(Unique_File_name = repair_files_per_primer$Unique_File_name_Primer,
                         FWD_R1_in = repair_files_per_primer$FWD_R1_cutadapt,
                         FWD_R2_in = repair_files_per_primer$FWD_R2_cutadapt,
                         FWD_R1_out = repair_files_per_primer$FWD_R1_repaired,
                         FWD_R2_out = repair_files_per_primer$FWD_R2_repaired)

tictoc::toc()


# create table with number of repaired reads per file ----
all_repaired <- all_filtered_out_fun_repaired2 %>% 
  dplyr::rename("Unique_File_name_Primer" = "Unique_File_name",
                "Primer detected reads" = "reads.in",
                "Repaired reads"  = "reads.out") %>% 
  dplyr::mutate("Proportion" = round((`Repaired reads`/`Primer detected reads`*100),
                                     digits = 2)) %>% 
  BiocGenerics::unique()

all_repaired 

```

<br>

### Identify error rates intrinsic to sequencing

```{r, eval=FALSE}
# 13 - learn error rates ----
tictoc::toc()



primers_n_samples$Run %>% unique()



all_dadaFs <- c()
all_dadaRs <- c()
all_derep_forward <- c()
all_derep_reverse <- c()


for (seq in unique(primers_n_samples$Run)) {


# seq <- "NxtSq_01_jan25"


message(paste0("Inicializando o sequenciamento: ", seq))

                       
            #seq ----
            seq_fnFs.repaired <- repair_files_per_primer %>%
               filter(Run %in% seq) %>%
               filter(file.exists(FWD_R1_repaired)) %>%
               pull(FWD_R1_repaired)
            
             names(seq_fnFs.repaired) <- repair_files_per_primer %>%
               filter(Run %in% seq) %>%
                             filter(file.exists(FWD_R1_repaired)) %>%
                               pull(Unique_File_name_Primer)
                               # pull(Unique_File_name)
            
            
             seq_fnRs.repaired <- repair_files_per_primer %>%
               filter(Run %in% seq) %>%
                             filter(file.exists(FWD_R2_repaired)) %>%
                               pull(FWD_R2_repaired)
            
             names(seq_fnRs.repaired) <- repair_files_per_primer %>%
               filter(Run %in% seq) %>%
                             filter(file.exists(FWD_R2_repaired)) %>%
                               pull(Unique_File_name_Primer)
                               # pull(Unique_File_name)
            
            
             length(seq_fnFs.repaired)
             length(seq_fnRs.repaired)
            
            
            
             # errors in R1 reads ----
               seq_errF <- learnErrors(fls = seq_fnFs.repaired,
                                       multithread=TRUE,
                                       randomize = FALSE,
                                       verbose = TRUE,
                                       nbases = "1e16")
             # errors in R2 reads ----
               seq_errR <- learnErrors(fls = seq_fnRs.repaired,
                                       multithread=TRUE,
                                       randomize = FALSE,
                                       verbose = TRUE,
                                       nbases = "1e16")


# if multiple runs
# seq ----
        seq_derep_forward <- derepFastq(seq_fnFs.repaired, verbose=TRUE)

        seq_derep_reverse <- derepFastq(seq_fnRs.repaired, verbose=TRUE)

        # seq_derep_forward[13]
        # seq_derep_reverse[13]


        seq_dadaFs <- dada(seq_derep_forward, err=seq_errF, multithread=TRUE)
        seq_dadaRs <- dada(seq_derep_reverse, err=seq_errR, multithread=TRUE)
        
        
        all_dadaFs <- c(all_dadaFs, seq_dadaFs)
        all_dadaRs <- c(all_dadaRs, seq_dadaRs)
        all_derep_forward <- c(all_derep_forward, seq_derep_forward)
        all_derep_reverse <- c(all_derep_reverse, seq_derep_reverse)

        

}

all_dadaFs %>% names()
all_dadaRs %>% names()
all_derep_forward %>% names()
all_derep_reverse %>% names()
```

<br>

### Dereplication: grouping into ASVs

On this step each library is reduced to its unique composing sequences and their counts.

```{r, eval=FALSE}
```

<br>

### Merge read pairs

On this step the forward an reverse reads are merged, by overlap, in order to reconstruct the insert full sequence.

```{r, eval=FALSE}

length(all_dadaFs)
length(all_dadaRs)
length(all_derep_forward)
length(all_derep_reverse)







# 15 - merge read pairs ----
# #merging ----

all_mergers <- mergePairs(dadaF = all_dadaFs,
        derepF =  all_derep_forward,
        dadaR =  all_dadaRs,
        derepR =  all_derep_reverse,
        minOverlap = 10,
        maxMismatch = 0,
        # returnRejects = TRUE,
        # justConcatenate = TRUE,
        verbose=TRUE)





# #concatenating ----
        all_concat <- mergePairs(dadaF = all_dadaFs,
                                  derepF =  all_derep_forward,
                                  dadaR =  all_dadaRs,
                                  derepR =  all_derep_reverse,
                                  # minOverlap = 12,
                                  minOverlap = 10,
                                  maxMismatch = 1,
                                  # returnRejects = TRUE,
                                  justConcatenate = TRUE,
                                  verbose=TRUE)


#combine sequence tables of different merging steps, or with concat, R1, R2 ----
 
 #must use a customized function that is not on dada2 (by benjjneb)
 
 sumSequenceTables <- function(table1, table2, ..., orderBy = "abundance") {
  # Combine passed tables into a list
  tables <- list(table1, table2)
  tables <- c(tables, list(...))
  # Validate tables
  if(!(all(sapply(tables, dada2:::is.sequence.table)))) {
    stop("At least two valid sequence tables, and no invalid objects, are expected.")
  }
  sample.names <- rownames(tables[[1]])
  for(i in seq(2, length(tables))) {
    sample.names <- c(sample.names, rownames(tables[[i]]))
  }
  seqs <- unique(c(sapply(tables, colnames), recursive=TRUE))
  sams <- unique(sample.names)
  # Make merged table
  rval <- matrix(0L, nrow=length(sams), ncol=length(seqs))
  rownames(rval) <- sams
  colnames(rval) <- seqs
  for(tab in tables) {
    rval[rownames(tab), colnames(tab)] <- rval[rownames(tab), colnames(tab)] + tab
  }
  # Order columns
  if(!is.null(orderBy)) {
    if(orderBy == "abundance") {
      rval <- rval[,order(colSums(rval), decreasing=TRUE),drop=FALSE]
    } else if(orderBy == "nsamples") {
      rval <- rval[,order(colSums(rval>0), decreasing=TRUE),drop=FALSE]
    }
  }
  rval
 }


mergers_seqtab <- makeSequenceTable(samples = all_mergers)
concat_seqtab <- makeSequenceTable(samples = all_concat)


mergers_seqtab %>% colnames()
concat_seqtab %>% colnames()


dada2:::is.sequence.table(mergers_seqtab)
dada2:::is.sequence.table(concat_seqtab)

 colnames(mergers_seqtab)
 colnames(concat_seqtab)
 
dim(concat_seqtab)
dim(mergers_seqtab)


getN <- function(x) sum(getUniques(x))

sapply(all_mergers, getN)
sapply(all_dadaFs, getN) #only R1
sapply(all_dadaRs, getN) #only R2




# rm(mergers_seqtab)
# rm(mergers_seqtab.nochim)
rownames(mergers_seqtab) 
colnames(mergers_seqtab) %>% length()
colnames(mergers_seqtab) %>% unique() %>% length()

dim(mergers_seqtab)
str(mergers_seqtab)

# Inspect distribution of sequence lengths
table(nchar(getSequences(mergers_seqtab)))
table(nchar(getSequences(mergers_seqtab))) %>% plot() #size distribution of the ASVs

```

<br>

### Remove *chimeras*

*Chimeras* are artificial read pairs that might have been generated erroneously on sequencing. The **DADA2** package estimates the probability of a sequence to be chimeric given the abundancy of its parental sequnces. After chimeric sequences removal, the remaining ASVs length distribution is assessed. On further steps it will be used to restrict analisys to ASVs compatible with each primer amplicons' length interval, in order to keep of unexpected ASVs.

```{r, eval=FALSE}
# 16 - remove chimeras ----


# any(colnames(C1conc_seqtab) %in% colnames(mergers_seqtab))

mergers_seqtab.nochim <- removeBimeraDenovo(mergers_seqtab, method="consensus", multithread=TRUE, verbose=TRUE)  
concat_seqtab.nochim <- removeBimeraDenovo(concat_seqtab, method="consensus", multithread=TRUE, verbose=TRUE)


#minFoldParentOverAbundance??
dim(mergers_seqtab.nochim)
dim(concat_seqtab)
dim(concat_seqtab.nochim)
sum(mergers_seqtab.nochim)/sum(mergers_seqtab) # =  0.9567811 , perda de 4.4% na abundancia -> estes 4.4% são quimeras

#count proportion of ASVs of a given length
table(nchar(getSequences(mergers_seqtab.nochim)))
table(nchar(getSequences(mergers_seqtab.nochim))) %>% plot()


View(mergers_seqtab.nochim)
dim(mergers_seqtab.nochim)

```

<br> \## Count reads and remaining ASVs

```{r, eval=FALSE}
# 17 - count reads proportion throughout the pipeline ----

#preparing subtables with named rows to combine latter
#raw files
#paired files ----
all_filtered_out

#cutadapt files ----
# repaired ----
all_repaired
  

#denoised ----
tbl_Denoised_R1 <- (sapply(all_dadaFs, getN) %>% 
                      tibble::as_tibble(rownames = "Unique_File_name_Primer")) %>% 
  `colnames<-`(c("Unique_File_name_Primer",
                 "Denoised (R1)")) 

tbl_Denoised_R2 <- (sapply(all_dadaRs, getN) %>% 
                      tibble::as_tibble(rownames = "Unique_File_name_Primer")) %>% 
  `colnames<-`(c("Unique_File_name_Primer",
                 "Denoised (R2)")) 

#merged  ----
tbl_Merged <- (rowSums(mergers_seqtab) %>% 
                 tibble::as_tibble(rownames = "Unique_File_name_Primer")) %>%
  `colnames<-`(c("Unique_File_name_Primer", "Merged"))

#non-chimeric ----
tbl_Non_chimeric_merged <- (rowSums(mergers_seqtab.nochim) %>% 
                              tibble::as_tibble(rownames = "Unique_File_name_Primer")) %>% 
  `colnames<-`(c("Unique_File_name_Primer", "Non-chimeric Merged"))

# concat ----
    tbl_concat <- (rowSums(concat_seqtab) %>% 
                     tibble::as_tibble(rownames = "Unique_File_name_Primer")) %>%
  `colnames<-`(c("Unique_File_name_Primer", "Concatenated"))
    
#non-chimeric ----
    tbl_Non_chimeric_concat <- (rowSums(concat_seqtab.nochim) %>% 
                                  tibble::as_tibble(rownames = "Unique_File_name_Primer")) %>% 
  `colnames<-`(c("Unique_File_name_Primer", "Non-chimeric Concatenated"))



# combine all counts by sample to plot ----
all_repaired_tbl <- all_repaired %>%
      select(!starts_with(match = "Prop")) %>%
  tidyr::separate(col = Unique_File_name_Primer,
                  into = c("Unique_File_name", "Primer"),
                  sep = "--",remove = F) 


all_filtered_out_and_raw <- all_repaired_tbl %>%           # coloquei essa primeiro pois tme mais linhas
      dplyr::left_join(y = all_filtered_out,
                       by = "Unique_File_name") %>% 
  relocate("Unique_File_name",
           # "Unique_File_name_Primer",
           "Raw reads (pairs)" ,
           "Paired reads",
           "Primer detected reads",
           "Repaired reads") %>% 
  select(!starts_with(match = "Prop"))



all_track <- all_filtered_out_and_raw %>%
  dplyr::left_join(tbl_Denoised_R1,by = "Unique_File_name_Primer") %>%
  dplyr::left_join(tbl_Denoised_R2,by = "Unique_File_name_Primer") %>%
  dplyr::left_join(tbl_Merged,by = "Unique_File_name_Primer") %>%
  dplyr::left_join(tbl_Non_chimeric_merged,by = "Unique_File_name_Primer") %>%
      # dplyr::left_join(tbl_concat,by = "Unique_File_name_Primer") %>%
      # dplyr::left_join(tbl_Non_chimeric_concat,by = "Unique_File_name_Primer") %>%
  dplyr::left_join(unique(primers_n_samples[,c("Unique_File_name","Project","Researcher","Type","Sample",
                                               "Metadata 1",
                                               "Metadata 2",
                                               "Metadata 3",
                                               "Metadata 4",
                                               "Lib")]), #projects metadata
            by = "Unique_File_name") %>% 
  dplyr::relocate(c("Primer","Unique_File_name","Unique_File_name_Primer",
                                               "Lib"))


all_track <- all_track %>%                                                      # conferir essa parte quando tiver mais de um primer
  dplyr::group_by(Unique_File_name, Project, Researcher, Type, Sample,Lib,
                  Primer,
                  `Metadata 1`,
                  `Metadata 2`,
                  `Metadata 3`,
                  `Metadata 4`) %>%
  dplyr::summarise(
    "Raw reads (pairs)" = round(mean(`Raw reads (pairs)`),digits = 0),
    "Paired reads" = round(mean(`Paired reads`),digits = 0),
    "Primer detected reads" = round(mean(`Primer detected reads`),digits = 0),
    "Repaired reads" = round(mean(`Repaired reads`),digits = 0),
    "Denoised (R1)" = round(mean(`Denoised (R1)`),digits = 0),
    "Denoised (R2)" = round(mean(`Denoised (R2)`),digits = 0),
    "Merged" = round(mean(`Merged`),digits = 0),
    "Non-chimeric Merged" = round(mean(`Non-chimeric Merged`),digits = 0),
    # "Concatenated" = round(mean(`Concatenated`),digits = 0),
    # "Non-chimeric Concatenated" = round(mean(`Non-chimeric Concatenated`),digits = 0)
    ) %>% 
  dplyr::ungroup()

all_track %>% colnames() %>% paste0(collapse = '",\n"') %>% cat()


# save counts table ---


for (PRJ in all_projects){

writexl::write_xlsx(x = all_track,
                    path = paste0(results_path,"/",PRJ,"-reads_and_seqs_counts-",Sys.Date(),".xlsx"),
                    col_names = TRUE,format_headers = TRUE)

}

# transform tibble to long format, better for ggplot ----
  track_tbl <- all_track %>%
  tidyr::gather(key = "Stage", 
                value = "Read counts",
                "Raw reads (pairs)",
                "Paired reads", 
                "Primer detected reads",
                "Repaired reads", 
                "Denoised (R1)",
                "Denoised (R2)",
                "Merged",
                "Non-chimeric Merged"
                         # "Concatenated",
                         # "Non-chimeric Concatenated"
                ) %>%
    dplyr::mutate(Stage = factor(Stage, 
                                 levels = c("Raw reads (pairs)",
                                            "Paired reads", 
                                            "Primer detected reads",
                                            "Repaired reads", 
                                            "Denoised (R1)",
                                            "Denoised (R2)",
                                            "Merged",
                                            "Non-chimeric Merged"
                                                    # "Concatenated",
                                                    # "Non-chimeric Concatenated"
                                            ))) 
    
options(scipen = 22)
  
    
    
base::rev(viridis::turbo(n = 30)) %>%  paste0(collapse = '"\n"') %>% cat()



track_tbl$Stage %>% levels()

#set colors for reads ----
cores_reads <- c(
  "Raw reads (pairs)" = "#7A0403FF",
  "Raw reads (R1)" = "#B11901FF",
  "Raw reads (R2)" = "#B11901FF",
  "Paired reads" = "#F25F14FF",
  "Primer detected reads" = "#FE942AFF",
  "Primer detected reads (R1)" = "#F7C13AFF",
  "Primer detected reads (R2)" = "#F7C13AFF",
  "Repaired reads" = "#DAE336FF",
  "Denoised (R1)" = "#AFFA37FF",
  "Denoised (R2)" = "#AFFA37FF",
  "Merged" ="#76FE5BFF",
  "Non-chimeric Merged" ="#34F395FF",
  "Concatenated" = "#2DB6F1FF",
  "Non-chimeric Concatenated" = "#458AFCFF",
  "R1 + R2" = "#4145AAFF",
  "Non-chimeric R1 + R2" = "#3A2C78FF"
  )


#multiple plots ---
for (PRJ in all_projects) {
  options(scipen = 999)

project_name <- PRJ %>% 
  stringr::str_replace_all(pattern = " ",
                           replacement = "_") %>% 
  stringr::str_replace_all(pattern = "_-_",
                           replacement = "--")

  
N_samples <- track_tbl %>%
  dplyr::filter(Project %in% c(PRJ)) %>% 
  dplyr::pull(Unique_File_name) %>% 
  BiocGenerics::unique() %>% 
  base::length()


# Calculate equal limits for both axes ----
x_min <- min(track_tbl$`Read counts`,na.rm = T)
x_max <- max(track_tbl$`Read counts`,na.rm = T)



  track_plot <- track_tbl %>% 
    dplyr::filter(Project %in% c(PRJ)) %>% 
    dplyr::filter(!is.na(`Read counts`)) %>% 
    # mutate(Unique_File_name = factor(Unique_File_name, levels =  sample_levels)) %>%
    dplyr::arrange(Unique_File_name) %>%
    ggplot2::ggplot(aes(y = Stage,
                        x = `Read counts`, 
                        fill = Stage,
                        group = Unique_File_name,
                        label = `Read counts`)) +
    geom_bar(stat="identity") + 
    geom_text(size = 5/.pt,
              x = -15000) +
    scale_fill_manual(values = alpha(colour = cores_reads,
                                     alpha =  0.75)) +
    labs(title = paste0(PRJ),
         subtitle = paste0("Number of sequences per library and Data cleaning/processing stage"),
         x = "Number of sequences",
         y = "Data processing stage") +
      facet_wrap(~Primer + Unique_File_name, ncol = 8) +
    # coord_fixed(ratio = x_max/length(unique(track_tbl$Stage))) +      # Ensures 1 unit on the x-axis equals 1 unit on the y-axis
    # coord_fixed(ratio = x_max/length(unique(track_tbl$Stage))) +      # Ensures 1 unit on the x-axis equals 1 unit on the y-axis
  # scale_x_continuous(limits = c(x_min,x_max)) +  # Apply the same limits to the x-axis
    scale_y_discrete() +
    scale_x_continuous(
      expand = expansion(add = c(40000, 0))  # 1 unidade só à esquerda
      )+
    # coord_fixed(ratio = max(track_tbl$`Read counts`,na.rm = T)/length(unique(track_tbl$Stage))*0.75) +
    theme_bw(base_size = 8) +
    theme(
      
      axis.text.x = element_text(angle = 90,hjust = 0.0001,
                                 vjust = -0.00000000001,face = "bold"),
      legend.position = "bottom",
      axis.title = ggtext::element_markdown()
          ) 
  # +
  #   ggpubr::xscale("10", .format = TRUE)

# track_plot 

# save plot
ggsave(file = paste0(results_path,"/",PRJ,"--reads_counts_track.pdf",collapse = ""),
# ggsave(file = paste0(results_path,"/",
#                      unique(smp_abd_ID_Final$Project),"/",
#                      unique(smp_abd_ID_Final$Project),"-samples_track.pdf",collapse = ""),
plot = track_plot,
device = "pdf",
width = 14,
height = round(N_samples/4,digits = 0)+2,
units = "cm", 
scale = 3, 
limitsize = F,
dpi = 120)

# knitr::plot_crop(x = paste0(results_path,"/",project_name,"-samples_track.pdf",collapse = ""))

}


means_tbl <- track_tbl %>% 
  # dplyr::filter(!Unique_File_name %in% c("EM206_25A_MiBird")) %>% 
  dplyr::group_by(Project, Stage,Primer) %>% 
  dplyr::summarise("Mean" = median(`Read counts`,na.rm = T))  
  
  track_boxplot <- track_tbl %>% 
  # dplyr::filter(!Unique_File_name %in% c("EM206_25A_MiBird")) %>% 
  # dplyr::group_by(Project, Stage, Type) %>% 
  ggplot2::ggplot(aes(
    x = Stage,
    y = `Read counts`, 
    fill = Stage)) +
  geom_violin(alpha = 0.25, 
              col = NA)+
  geom_boxplot(width = 0.8,
    outlier.shape = NA, 
    col = "#555555",
    notch=TRUE,
    notchwidth = 0.8,
    alpha = 0.5) +
  geom_jitter(aes(col = Stage,
                  shape = Type),
              size = 1,
              alpha = 0.5) +
  geom_line(data = means_tbl, aes(x = Stage,
                                  y = Mean, 
                                  group = Project), col = "#333333") +
  scale_fill_manual(values = alpha(colour = cores_reads,
                                   alpha =  0.75)) +
  scale_colour_manual(values = alpha(colour = cores_reads,
                                   alpha =  0.75)) +
  scale_shape_manual(values = c(23,24,25,21)) +
  facet_grid(cols = vars(Lib,Primer),
             rows = vars(Project),
             axes = "all_y") +
    scale_y_continuous(breaks =
                         c(-10,
                           0,1,10,50,
                           100,500,1000,5000,
                           10000,25000,50000,
                           100000,150000,200000,250000,300000,350000),
                       limits = c(-10,350000),
                       trans = "log10",
                       expand = c(0.001,0.001)
                       
                       ) +
    theme_bw() +
    theme(axis.text.x = element_text(hjust = 1,
                                     vjust = 0.25,
                                     angle = 90)) +
    labs(title = paste0(PRJ),
         subtitle = paste0("Distribution of sequences per library and Data cleaning/processing stage"),
         y = "Number of sequences",
         x = "Data processing stage")
  
 track_boxplot %>% 
# save plot
ggsave(file = paste0(results_path,"/",analysis_rad,"--reads_counts_boxplot_per_project_log.pdf",collapse = ""),
device = "pdf",
width = 40,
height = 20,
units = "cm", 
limitsize = F,
dpi = 120)


 track_tbl$Stage %>% unique()
 
 
 track_boxplot_means <- track_tbl %>% 
   dplyr::mutate(Sample = stringr::str_replace_all(Sample, pattern = "_| ", replacement = "\n")) %>% 
   dplyr::mutate(Type = stringr::str_replace_all(Type, pattern = "_| ", replacement = "\n")) %>% 
  # dplyr::filter(Stage %in% c("Raw reads (pairs)")) %>% 
  dplyr::filter(Stage %in% c("Non-chimeric Merged")) %>%
  # dplyr::group_by(Project,Sample,Type,Stage) %>% 
  # dplyr::summarise("Mean" = mean(`Read counts`)) %>% 
   ggplot2::ggplot(aes(x = Lib,
                       y = `Read counts`,
                       fill = Lib,
                       group = Lib)) +
   # geom_bar(stat = "identity", position = "dodge") +
   geom_boxplot(aes(x = Lib),
                outlier.shape = NA,
                col = "#000000",
                width = 0.6, 
                position = position_dodge(width = 0.8)
                ) +
   geom_jitter(aes(group = Lib),
               size = 1, 
               col = "#444444",
               alpha = 0.5,
               position = position_dodge(width = 0.8)
               ) +
   scale_fill_manual(values = viridis::turbo(n=8)[c(2:8)]) +
   # scale_colour_manual(values = viridis::turbo(n=8)[c(2:8)]) +
    theme(axis.text.x = element_text(hjust = 1,
                                     vjust = 0.25,
                                     angle = 90),
          strip.text.x = element_text(size = 8),
          legend.position = "bottom"
          ) +
   facet_grid(cols = vars(Type,`Metadata 2`),
              rows = vars(Primer),
              space = "free_x",
              scales  = "free_x",
              drop = TRUE) +
   geom_hline(yintercept = 10, linewidth = 0.001) +
   # scale_y_log10(breaks = scales::trans_breaks("log10", function(x) 10^x),
   # labels = scales::trans_format("log10", scales::math_format(10^.x))) +
   labs(title = "Número de sequências brutas por ponto amostral e marcador") +
   guides(colour = guide_legend(nrow = 1),
          fill = guide_legend(nrow = 1)) +
  scale_fill_manual(values = alpha(colour = cores_reads,
                                   alpha =  0.75)) +
  scale_colour_manual(values = alpha(colour = cores_reads,
                                   alpha =  0.75)) +
  scale_shape_manual(values = c(23,24,25,21)) 
 
 
#salvando com escala logaritmica ----
( track_boxplot_means +  scale_y_log10(breaks = c(   1, 10,50,
                           100, 500,1000,5000,
                           10000,25000,50000,
                           100000,150000,
                           200000,
                           250000,300000,350000
                           )) )%>%
   # save plot
   ggsave(file = paste0(results_path,"/",analysis_rad,"--mean_Merged_reads_per_project_log10_boxplot.pdf",collapse = ""),
          device = "pdf",
          width = 60,
          height = 20,
          units = "cm", 
          limitsize = F,
          dpi = 120)


#salvando com escala normal ----
( track_boxplot_means + 
    scale_y_continuous(breaks =
                         c(0,5000,
                           10000,25000,50000,
                           100000,150000,
                           200000,250000,300000
                           ),
                       limits = c(-10,350000),
                       expand = c(0.001,0.001)) ) %>%
   # save plot
   ggsave(file = paste0(results_path,"/",analysis_rad,"--mean_Merged_reads_per_project_normal_boxplot.pdf",collapse = ""),
          device = "pdf",
          width = 60,
          height = 20,
          units = "cm", 
          limitsize = F,
          dpi = 120)



```

#### Show figure on html

```{r, eval=TRUE,echo=TRUE, results='asis'}
# Extract the PDF path from the R object

pdf_track <- 
  list.files(path = "~/ecomol/analyses/2024/Sq_dez25/results",
             pattern = "reads_counts_track",
             full.names = T)

  
# Generate the iframe HTML code
cat(paste0('<iframe src="', pdf_track, '" width="1200" height="800"></iframe>'))
```

<br><br>

Here the **DADA2** pipeline ends.

<br><br>

## Phyloseq

On this step the ASVs associated to taxonomic ranks by **DADA2** and their respective counts by library, are combined using the **Phyloseq** package.

<br>

### Generate sample metadata table

Here the experiment metadata is associated to each sample.

```{r, eval=FALSE}
# 22 - create sample table ----

primers_n_samples %>% colnames()

all_samdf <- primers_n_samples %>% 
  dplyr::select(c("Project",
                  "Sample",
                  "Researcher",
                  # "Analysis",
                  "Unique_File_name",
                  "Primer",
                  "Lib",
                  "Type",
                  dplyr::starts_with("Metadata"),
                  "obs",
                  "Extraction control",
                  "PCR control","Filtration control")) %>% 
  BiocGenerics::unique() %>%
  tidyr::separate_longer_delim(cols = c("Primer"),
                               delim = ";") %>%                      # separando por primer
  tidyr::unite(Unique_File_name,Primer,
               col = "Unique_File_name_Primer",
               sep = "--",
               remove = F) %>%
  as.data.frame()

samdf <- all_samdf

rownames(samdf) <- samdf$Unique_File_name_Primer
```

<br>

This sample metadata table was created with the information available for the samples analyzed on this first run. This table must be customized for each experiment.

<br><br>

### Convert DADA2 object to tibble

```{r, eval=FALSE}
#23 - interpret dada on phyloseq ----
rownames(samdf)
str(samdf)

dim(mergers_seqtab)
dim(mergers_seqtab.nochim)



mergers_ps <- phyloseq::phyloseq(phyloseq::otu_table(mergers_seqtab.nochim, taxa_are_rows = FALSE),
                                 phyloseq::sample_data(samdf)
                                 # ,                                            #only if using DADA2 tax
                                 # phyloseq::tax_table(mergers_taxa$tax)
                                 )

            concat_ps <- phyloseq::phyloseq(phyloseq::otu_table(concat_seqtab.nochim, taxa_are_rows = FALSE),
                                            phyloseq::sample_data(samdf)
                                            # ,                                            #only if using DADA2 tax
                                            # phyloseq::tax_table(concat_taxa$tax)
                                            )
```

<br>

### Merge and Flex Phyloseq results

Many different graphics can be generated, together or in isolation, for all primers/libraries and taxonomic ranks.

```{r, eval=FALSE}
#24 - merge ps analisys ----
# combine all pyloseq objects in one
# by doing so, all ASVs will be combined and some will have 0 abundance
mergers_ps_tbl <- phyloseq::psmelt(mergers_ps) %>% 
  tibble::as_tibble() %>% 
  dplyr::mutate(`Read origin` = "merged") %>% 
  dplyr::filter(Abundance >= 1) %>% 
  dplyr::mutate("ASV tip" = OTU) %>% 
  dplyr::rename("ASV" = "OTU") 


      concat_ps_tbl <- phyloseq::psmelt(concat_ps) %>%
        tibble::as_tibble() %>%
        dplyr::mutate(`Read origin` = "concat")   %>%
        dplyr::filter(Abundance >= 1) %>% 
        dplyr::mutate("ASV tip" =  stringr::str_replace_all(string = OTU,
                                                   pattern = "NNNNNNNNNN",
                                                   replacement = ";")) %>% 
        tidyr::separate_longer_delim(cols = "ASV tip",
                                     delim = ";") %>% 
        dplyr::rename("ASV" = "OTU") %>% 
        unique()


#combine ps tables from all ASVs inputs
all_ps_tbl <- bind_rows(
                        mergers_ps_tbl
                                 # concat_ps_tbl
                        ) %>% 
  dplyr::select(-c("Sample")) %>%  
  dplyr::rename("Sample" = "sample_Sample") %>%
  dplyr::mutate("ASV Size (pb)" = nchar(ASV)) 

```

## calculate sample abundances ----

```{r, eval=FALSE, echo=TRUE}
{
  all_ps_tbl <- all_ps_tbl %>%
  dplyr::mutate("Relative abundance to all samples" = 0,
         "Relative abundance on sample" = 0,
         "Sample total abundance" = 0)
  
  abd_total <- sum(all_ps_tbl$Abundance)
  
  all_ps_tbl <- all_ps_tbl %>%
    dplyr::group_by(Project,
                    Unique_File_name,
                    Primer,
                    `Read origin`) %>%   #now the abundance on sample is for merged/R1/R2 separetely
    dplyr::mutate("Sample total abundance" = sum(Abundance),
           "Relative abundance to all samples" = round((Abundance/abd_total),digits = 6),
           "Relative abundance on sample" =  round((Abundance/`Sample total abundance`),digits = 6)) %>%
    dplyr::relocate(`Sample total abundance`,`Relative abundance to all samples`,`Relative abundance on sample`) %>% 
    dplyr::ungroup()

}

```

### Check ASVs lenghts pre BLAST

```{r, eval=FALSE}
# Tamanho das ASVs por amostra e Read origin ---- 
scales::show_col(viridis::viridis(n=10))
scales::show_col(viridis::turbo(n=12))


ASV_legth_by_Sample <- all_ps_tbl %>%
  # mutate(Sample=factor(Sample,levels = sample_levels)) %>% 
  # ggplot(aes(y=Unique_File_name,
  ggplot(aes(y= interaction(`Read origin`,Unique_File_name),
             x=`ASV Size (pb)`,
             fill = `Read origin`,
             col = `Read origin`,
             # col = Primer,
             size =`Relative abundance on sample`,
             alpha = 0.25
             )) +
  geom_jitter(height = 0.3,
              width = 0.3) +
  scale_x_continuous(breaks = c(seq(20,
                                    max(all_ps_tbl$`ASV Size (pb)`),10)),
  # scale_x_continuous(breaks = c(seq(20,280,10)),
                     expand = c(0.02,0.02)) +
  scale_shape_manual(name = "Identification\n     satatus",
                                             values = c(21,4),
                                             labels=c("BLAST IDed","no ID")) +
  scale_fill_manual(values = c(viridis::turbo(n=12)[c(3,6,9,12)])) +
  scale_colour_manual(values = c(viridis::turbo(n=12)[c(3,6,9,12)])) +
  xlab("Tamanho da ASV (pb)") +
  ylab("Amostra") +
  ggtitle(label = paste0(analysis_rad),
          subtitle = "Distribution of ASVs size and Read originper Sample considering all identified ASVs") +
  theme_bw(base_size = 8) +
  theme(legend.position = "right")+
  geom_vline(xintercept = c(10,max(all_ps_tbl$`ASV Size (pb)`))) +
  theme(axis.text.x = element_text(angle = 45,hjust = 1)) +
# +
#   guides(alpha="none",
#          color="none") 
# +
  facet_grid(rows = vars(Project, Primer, Type),scales ='free_y', space ='free_y') +
  # facet_grid(rows = vars(Sample,`Read origin`),scales ='free_y', space ='free_y') +
  theme(strip.text.y = element_text(size = 10,angle = 0))
  
ASV_legth_by_Sample
dev.off()


ggsave(file = paste0(results_path,"/",analysis_rad,"-ASV_length_by_sample-ALL-ASVs.pdf",collapse = ""),
     plot = ASV_legth_by_Sample,
     device = "pdf",
     width = 90,
     height = 50,
     units = "cm",
     dpi = 600)

```

## BLASTn identification

### Select ASVs for identification

```{r, eval=FALSE}
### select ASVs for BLASTn search ----

all_ps_tbl$ASV %>% unique()
all_ps_tbl$`ASV tip` %>% unique()

asvs_blast_all <- all_ps_tbl %>%
  BiocGenerics::unique() %>% 
  dplyr::select(`ASV tip`) %>% 
  dplyr::arrange(nchar(`ASV tip`)) %>%
  dplyr::pull(`ASV tip`) %>% 
  BiocGenerics::unique() %>%
  rev() %>% 
  as.character() 

asvs_blast_all
asvs_blast_all[1]
asvs_blast_all[10000]
asvs_blast_all[18000]

 
which(asvs_blast_all %>%  str_detect(pattern = "NNNNNNN"))
```

### Run BLASTn with BLASTr

```{r, eval=FALSE}
# blastn ----
# detach("BLASTr") 
# devtools::install_github("heronoh/BLASTr", force = TRUE)
devtools::install_github("heronoh/BLASTr", force = TRUE)
library(BLASTr,verbose = T)
packageVersion("BLASTr") #0.1.4



asvs_blast_all %>% nchar() %>% table() %>% plot()

{
# BLASTn identification ----
tictoc::tic("BLASTn taxonomy assignment")
date()

blast_res_1 <- parallel_blast(
  db_path = "/data/databases/LGC12Sdb/mai25/LGC12Sdb_complete_noGaps-2025-05-21.fasta /data/databases/core_nt/core_nt",
  # asvs = asvs_blast_all[1000:1010],
  query_seqs = asvs_blast_all,
  # asvs = asvs_blast_all_new,
  out_file = paste0(blast_path,"/blast_out_res_1.csv"),
  out_RDS = paste0(blast_path,"/blast_out_res_1.RDS"),
  total_cores = 60,
  perc_id = 80,
  num_threads = 2,
  perc_qcov_hsp = 80,
  num_alignments = 3,
  blast_type = "blastn"
)

date()
tictoc::toc()# 


#Save env
base::save.image(paste0(analysis_path,"/env--",analysis_rad,"--pos_BLAST--",Sys.Date(),".RData"))
}

{
# BLASTn identification ----
tictoc::tic("BLASTn taxonomy assignment")
date()

blast_res_2 <- parallel_blast(
  # db_path = "/data/databases/nt_2024/nt",
  # db_path = "/data/databases/core_nt/core_nt",
  # db_path = "/data/databases/core_nt/core_nt /data/databases/LGC12Sdb/oct24/LGC12Sdb_complete_noGaps-2024-09-20.fasta",
  db_path = "/data/databases/core_nt/core_nt /data/databases/LGC12Sdb/mai25/LGC12Sdb_complete_noGaps-2025-05-21.fasta",
  asvs = asvs_blast_all[20001:40000],
  # asvs = asvs_blast_all_new,
  out_file = paste0(blast_path,"/blast_out_res_2.csv"),
  out_RDS = paste0(blast_path,"/blast_out_res_2.RDS"),
  total_cores = 60,
  perc_id = 80,
  num_threads = 2,
  perc_qcov_hsp = 80,
  num_alignments = 3,
  blast_type = "blastn"
)

date()
tictoc::toc()# 
#Save env
base::save.image(paste0(analysis_path,"/env--",analysis_rad,"--pos_BLAST--",Sys.Date(),".RData"))
}


{
# BLASTn identification ----
tictoc::tic("BLASTn taxonomy assignment")
date()

blast_res_3 <- parallel_blast(
  # db_path = "/data/databases/nt_2024/nt",
  # db_path = "/data/databases/core_nt/core_nt",
  # db_path = "/data/databases/core_nt/core_nt /data/databases/LGC12Sdb/oct24/LGC12Sdb_complete_noGaps-2024-09-20.fasta",
  db_path = "/data/databases/core_nt/core_nt /data/databases/LGC12Sdb/mai25/LGC12Sdb_complete_noGaps-2025-05-21.fasta",
  asvs = asvs_blast_all[40001:63523],
  # asvs = asvs_blast_all_new,
  out_file = paste0(blast_path,"/blast_out_res_3.csv"),
  out_RDS = paste0(blast_path,"/blast_out_res_3.RDS"),
  total_cores = 60,
  perc_id = 80,
  num_threads = 2,
  perc_qcov_hsp = 80,
  num_alignments = 3,
  blast_type = "blastn"
)

date()
tictoc::toc()# 
#Save env
base::save.image(paste0(analysis_path,"/env--",analysis_rad,"--pos_BLAST--",Sys.Date(),".RData"))
}


blast_res_full <- dplyr::bind_rows( 
  # blast_res_3,
  # blast_res_2,
  blast_res_1
  # blast_res_2,
  ) %>% 
  dplyr::filter(!is.na(`1_subject header`)) %>% 
  dplyr::rename("ASV tip" = "Sequence")



```

### Correct subjects (LGC12SDb only)

```{r, eval=FALSE}
blast_res_full$`1_staxid` %>% table()
blast_res_full$`1_staxid` %>% is.na() %>% sum()
# 
# 
#               # LGC 12 DB - correct missing taxIDs
#               # load taxIDs file
#               LGC12db_tax_IDs <- read.csv(file = "/data/databases/LGC12Sdb/oct24/LGC12Sdb_complete_noGaps-2024-09-20.txt",
#                                           sep = " ",
#                                           col.names = c("1_subject","1_staxid"),
#                                           check.names = F,
#                                           header = F) %>%
#                 as_tibble() %>%
#                 mutate(`1_staxid` = as.character(`1_staxid`)) %>%
#                 unique()
#               
#               
#               blast_res_full <- blast_res_full %>%
#                 mutate(`1_staxid` = case_when(`1_staxid` %in% c("N/A") ~ NA,
#                                               TRUE ~ `1_staxid`)) %>%
#                 left_join(y = LGC12db_tax_IDs,
#                           by = "1_subject",
#                           suffix = c("", "_B")) %>%                          # Join on the ID column
#                 mutate(`1_staxid` = coalesce(`1_staxid`, `1_staxid_B`)) %>%  # Use coalesce to fill missing values
#                 select(-c(`1_staxid_B`))
              
              
blast_res_full$`1_staxid` %>% table()
```

## Taxonomy retrieval

### Select best of three hits

```{r,echo=TRUE, eval=FALSE}
# XR_004027927.1 ================== homo sapiens!
blast_res_full %>% 
  filter(str_detect(pattern = "^XR",
                    string = `1_subject`)) %>% 
  View()


#overview the identifications ----
blast_res_full$`1_subject header` %>% unique() %>% sort()

#set hits with poor names to remove from results
bad_1res_IDs <- c(
  "Uncultured",
  "Uncultured organism clone",
  "Uncultured prokaryote",
  "Eukaryotic synthetic construct",
  "16S rRNA amplicon fragment",
  "Invertebrate environmental",
  "Uncultured Candidatus",
  "Uncultured bacterium",
  "Uncultured archaeon clone",
  "Complete Metagenome-Assembled",
  "PREDICTED: Nomascus"               # esse macaco é gente
  ) %>% 
  paste0(collapse = "|")


blast_res_full <- blast_res_full %>%
  mutate("blast ID" = "blast ID",
         "blast ID Origin" = "blast ID Origin",
         "query_taxID" = "query_taxID")


# pick BLASTn res IDs and mark result origin ----

for (asv in 1:nrow(blast_res_full)) {
  
  if (stringr::str_detect(string = blast_res_full$`1_subject header`[asv],pattern = bad_1res_IDs) & 
      !is.na(blast_res_full$`2_subject header`[asv])) {
    
    blast_res_full$`blast ID`[asv] <- substr(as.character(blast_res_full$`2_subject header`[asv]),1,40)
    blast_res_full$`blast ID Origin`[asv] <- "2_"
    blast_res_full$query_taxID[asv] <- blast_res_full$`2_staxid`[asv]
    
      if (stringr::str_detect(string = blast_res_full$`2_subject header`[asv],pattern = bad_1res_IDs) & 
      !is.na(blast_res_full$`3_subject header`[asv])) {
        
        blast_res_full$`blast ID`[asv] <- substr(as.character(blast_res_full$`3_subject header`[asv]),1,40)
        blast_res_full$`blast ID Origin`[asv] <- "3_"
        blast_res_full$query_taxID[asv] <- blast_res_full$`3_staxid`[asv]
      
            if (stringr::str_detect(string = blast_res_full$`3_subject header`[asv],pattern = bad_1res_IDs)) {
            
            blast_res_full$`blast ID`[asv] <- "Match_not_reliable"
            blast_res_full$`blast ID Origin`[asv] <- NA
            blast_res_full$query_taxID[asv] <- NA
          }
      } 
  } else {
    if (stringr::str_detect(string = blast_res_full$`1_subject header`[asv],pattern = bad_1res_IDs) & 
      is.na(blast_res_full$`2_subject header`[asv])) {
      
      blast_res_full$`blast ID`[asv] <- "Match_not_reliable"
      blast_res_full$`blast ID Origin`[asv] <- NA
      blast_res_full$query_taxID[asv] <- NA
      
      }else{
        blast_res_full$`blast ID`[asv] <- substr(as.character(blast_res_full$`1_subject header`[asv]),1,40)
        blast_res_full$`blast ID Origin`[asv] <- "1_"
        blast_res_full$query_taxID[asv] <- blast_res_full$`1_staxid`[asv]
      }
  }
}

# Set mat as not_reliable if contains uncultured organism ----
blast_res_full$`blast ID`[stringr::str_detect(string = blast_res_full$`blast ID`, 
                                              pattern =  "ncultur|nvironmental")] <- "Match_not_reliable"


blast_res_full$`1_subject header`[blast_res_full$`blast ID` == "Match_not_reliable"] %>% unique()


```

### Extract species name from hit

```{r,echo=TRUE, eval=FALSE}
blast_res_full$`blast ID` %>% unique() %>% sort()
blast_res_full$`blast ID Origin` %>% table() 

#View bad labels ----
blast_res_full$`blast ID`[blast_res_full$`blast ID` %>% 
 stringr::str_detect(pattern = ":|^  |^ |Uncultured |uncultured |Candidatus |MAG:|MAG TPA_asm: |TPA_asm: |^Cf.|\n|candidate division|PREDICTED")] %>% 
  sort() %>% 
  unique()

# remove spaces after : to handle labels ----
blast_res_full$`blast ID` <- blast_res_full$`blast ID` %>% 
  stringr::str_replace(pattern = ": ", replacement = ":") %>% 
  stringr::str_remove(pattern = "\n$") %>% 
  stringr::str_remove(pattern = "^  |^ |Uncultured |uncultured |Candidatus |MAG:|MAG TPA_asm:|TPA_asm:|^Cf. |candidate division ") %>% 
  stringr::str_remove(pattern = "^  |^ |Uncultured |uncultured |Candidatus |MAG:|MAG TPA_asm:|TPA_asm:|^Cf. |candidate division ") %>% 
  stringr::str_remove_all(pattern = "\\[|\\]") %>% 
  stringr::str_replace(pattern = "\\n ",replacement = " ") %>% 
  stringr::str_replace(pattern = "cf\\. ",replacement = "") %>% 
  stringr::str_replace(pattern = "nr\\. ",replacement = "") %>% 
  stringr::str_replace(pattern = "sp\\. ",replacement = "sp\\.") %>% 
  stringr::str_replace(pattern = "\\,",replacement = "") %>% 
  stringr::str_replace(pattern = "sp\\.",replacement = "sp\\. ")

#check names ----
blast_res_full$`blast ID` %>% unique() %>% sort()
blast_res_full$`blast ID` %>% unique() %>% sort(decreasing = T)


# selecting just the first 2 names of BLAST result ----
for (row in 1:nrow(blast_res_full)) {

  blast_res_full$`blast ID`[row] <- stringr::str_split_fixed(string = blast_res_full$`blast ID`[row], pattern = " ",n = 3)[1:2] %>% 
    paste0(collapse = " ")

}


# return with space after:
blast_res_full$`blast ID` <- blast_res_full$`blast ID` %>% 
  stringr::str_replace(pattern = ":", replacement = ": ")

#check names ----
blast_res_full$`blast ID` %>% unique() %>% sort()


# correct confusing labels to unify identities ----
blast_res_full$`blast ID`[blast_res_full$`blast ID` %in% c("Human DNA",
                                                           "Eukaryotic synthetic",
                                                           "Human chromosome")] <- "Homo sapiens"

  blast_res_full$`blast ID` %>% unique() %>% sort()
  
  
  blast_res_full %>% dplyr::filter(`blast ID` %in% c(" ",""))
```

### Retrieve complete taxonomy

```{r,echo=TRUE, eval=FALSE}
blast_res_full <- blast_res_full %>%
  relocate(`blast ID`,`blast ID Origin`,`query_taxID`)



# select NCBI taxIDs to searc----
taxIDs2search <- blast_res_full$query_taxID %>% 
  unique() %>% 
  na.omit() %>% 
  as.character()
 
 
devtools::load_all(path = "/home/noreh/prjcts/BLASTr/R")


 taxonomy_tbl1 <- parallel_get_tax(organisms_taxIDs = taxIDs2search,
                                   retry_times = 5,
                                   verbose = "full")
 
  taxIDs2search[!(taxIDs2search %in% c(unique(taxonomy_tbl1$query_taxID)))]
 
  
  
  
  
  
  blast_res_full[blast_res_full$query_taxID %in% c(  taxIDs2search[!(taxIDs2search %in% c(unique(taxonomy_tbl1$query_taxID)))]),] %>% View()
  blast_res_full$`blast ID`[blast_res_full$query_taxID %in% c(  taxIDs2search[!(taxIDs2search %in% c(unique(taxonomy_tbl1$query_taxID)))])] %>% BiocGenerics::unique()
  
  
  
  
 taxonomy_tbl2 <- parallel_get_tax(organisms_taxIDs =
  taxIDs2search[!(taxIDs2search %in% c(unique(taxonomy_tbl1$query_taxID)))],
                                  retry_times = 1,verbose = F)


 
taxonomy_tbl <- dplyr::bind_rows(taxonomy_tbl1
                                 # ,
                                 # taxonomy_tbl2
                                 ) %>% 
  BiocGenerics::unique()
 
 
taxIDs2search[!(taxIDs2search %in% c(unique(taxonomy_tbl1$query_taxID)))]
taxIDs2search[!(taxIDs2search %in% c(unique(taxonomy_tbl$query_taxID)))]

```

### Fill empty taxonomic ranks

```{r,echo=TRUE, eval=FALSE}
# solving LGC db problems ----
                  taxonomy_tbl %>% 
                    filter(`Class (NCBI)` %in% c("Actinopteri")) %>% 
                    View()
                  
                  taxonomy_tbl %>% 
                    filter(`Phylum (NCBI)` %in% c("Chordata")) %>% 
                    View()
                  

#see all genus detected ----
(taxonomy_tbl$Sci_name %>% 
    str_split_fixed(pattern = " ",n=2))[,1] %>% 
                    unique() %>% 
                    sort()
  
# Correct some NA genus (for LGC and other) ----
taxonomy_tbl <- taxonomy_tbl %>% 
                    dplyr::rowwise() %>% 
                    dplyr::mutate(`Genus (NCBI)` = dplyr::case_when((is.na(`Genus (NCBI)`) &
                                                                       `Class (NCBI)` %in% c("Actinopteri")) ~ stringr::str_remove_all(Sci_name,
                                                                                                                                       pattern = " .*.$"),
                                                                    TRUE ~ `Genus (NCBI)`
                                                                    )) %>% 
                    dplyr::mutate(`Genus (NCBI)` = dplyr::case_when(is.na(`Genus (NCBI)`) ~ stringr::str_remove_all(Sci_name,
                                                                                                                                       pattern = " .*.$"),
                                                                    TRUE ~ `Genus (NCBI)`))


taxonomy_tbl$`Superkingdom (NCBI)` %>% unique()
taxonomy_tbl$`Superkingdom (NCBI)` %>% table()
taxonomy_tbl$`Kingdom (NCBI)` %>% unique()
taxonomy_tbl$`Kingdom (NCBI)` %>% table()
taxonomy_tbl$`Genus (NCBI)` %>% table()


taxonomy_tbl %>% 
  dplyr::filter(is.na(`Superkingdom (NCBI)`)) %>% 
  dplyr::pull(`Phylum (NCBI)`) %>% 
  table() %>% 
  sort()


taxonomy_tbl$`Superkingdom (NCBI)`[taxonomy_tbl$`Kingdom (NCBI)` %in% c("Promethearchaeati", "Nanobdellati",
                                                                        "Methanobacteriati",
                                                                        "Thermoproteati") & 
                                     is.na(taxonomy_tbl$`Superkingdom (NCBI)`)] <- "Archaea"

taxonomy_tbl$`Superkingdom (NCBI)`[taxonomy_tbl$`Phylum (NCBI)` %in% c("Ciliophora", "Euglenozoa", "Oomycota",
                                                                       "Bacillariophyta", "Tubulinea", "Apicomplexa",
                                                                       "Cercozoa", "Endomyxa", "Haptophyta",
                                                                       "Hemimastigophora", "Preaxostyla", "Haptophyta",
                                                                       "Fornicata", "Rhodophyta", "Haptophyta",
                                                                       "Discosea", "Heterolobosea", "Nibbleridia",
                                                                       "Parabasalia", "Perkinsozoa", "Foraminifera",
                                                                       "Telonemia", "Nebulidia", 
                                                                       "Evosea") & 
                                     is.na(taxonomy_tbl$`Superkingdom (NCBI)`)] <- "Eukaryota"


taxonomy_tbl$`Superkingdom (NCBI)`[taxonomy_tbl$`Kingdom (NCBI)` %in% c("Viridiplantae", "Metazoa", "Fungi") & 
                                     is.na(taxonomy_tbl$`Superkingdom (NCBI)`)] <- "Eukaryota"

taxonomy_tbl$`Superkingdom (NCBI)`[taxonomy_tbl$`Kingdom (NCBI)` %in% c("Pseudomonadati", "Bacillati","Fusobacteriati",
                                                                        "Thermotogati"
                                                                        ) & 
                                     is.na(taxonomy_tbl$`Superkingdom (NCBI)`)] <- "Bacteria"

taxonomy_tbl$`Superkingdom (NCBI)`[stringr::str_detect(taxonomy_tbl$`Phylum (NCBI)`, pattern = "bacteriota$|bacterota$|bacteria$") & 
                                     is.na(taxonomy_tbl$`Superkingdom (NCBI)`)] <- "Bacteria"

taxonomy_tbl$`Superkingdom (NCBI)`[stringr::str_detect(taxonomy_tbl$`Phylum (NCBI)`, pattern = "Altimarinota$|Moduliflexota$|Microgenomatota$|Binatota$|CPR2$|CPR3$|Methylomirabilota$|Sumerlaeota$") & 
                                     is.na(taxonomy_tbl$`Superkingdom (NCBI)`)] <- "Bacteria"


taxonomy_tbl$`Superkingdom (NCBI)`[stringr::str_detect(taxonomy_tbl$`Phylum (NCBI)`, pattern = "WWE3$") & 
                                     is.na(taxonomy_tbl$`Superkingdom (NCBI)`)] <- "Viruses"

taxonomy_tbl$`Superkingdom (NCBI)`[taxonomy_tbl$`Kingdom (NCBI)` %in% c("Heunggongvirae") & is.na(taxonomy_tbl$`Superkingdom (NCBI)`)] <- "Viruses"


# fill NA tax with combination of max_tax and rank ----
for (line in 1:nrow(taxonomy_tbl)) {
  # if (taxonomy_tbl$genus[line] %in% c("NA",NA,"")) {
  if (taxonomy_tbl$`Superkingdom (NCBI)`[line] %in% c("NA",NA,"")) {
    taxonomy_tbl$`Superkingdom (NCBI)`[line] <- paste0("superkingdom of ", taxonomy_tbl$`Kingdom (NCBI)`[line]) }
  
  if (taxonomy_tbl$`Kingdom (NCBI)`[line] %in% c("NA",NA,"")) {
    taxonomy_tbl$`Kingdom (NCBI)`[line] <- paste0("kingdom of ", taxonomy_tbl$`Superkingdom (NCBI)`[line]) }
  
  if (taxonomy_tbl$`Phylum (NCBI)`[line] %in% c("NA",NA,"")) {
    taxonomy_tbl$`Phylum (NCBI)`[line] <- paste0("phylum of ", taxonomy_tbl$`Kingdom (NCBI)`[line]) }
  
  if (taxonomy_tbl$`Subphylum (NCBI)`[line] %in% c("NA",NA,"")) {
    taxonomy_tbl$`Subphylum (NCBI)`[line] <- paste0("subphylum of ", taxonomy_tbl$`Phylum (NCBI)`[line]) }
  
  if (taxonomy_tbl$`Class (NCBI)`[line] %in% c("NA",NA,"")) {
    taxonomy_tbl$`Class (NCBI)`[line] <- paste0("class of ", taxonomy_tbl$`Subphylum (NCBI)`[line]) }
  
  if (taxonomy_tbl$`Subclass (NCBI)`[line] %in% c("NA",NA,"")) {
    taxonomy_tbl$`Subclass (NCBI)`[line] <- paste0("subclass of ", taxonomy_tbl$`Class (NCBI)`[line]) }
  
  if (taxonomy_tbl$`Order (NCBI)`[line] %in% c("NA",NA,"")) {
    taxonomy_tbl$`Order (NCBI)`[line] <- paste0("order of ", taxonomy_tbl$`Subclass (NCBI)`[line]) }
  
  if (taxonomy_tbl$`Suborder (NCBI)`[line] %in% c("NA",NA,"")) {
    taxonomy_tbl$`Suborder (NCBI)`[line] <- paste0("suborder of ", taxonomy_tbl$`Order (NCBI)`[line]) }
  
  if (taxonomy_tbl$`Family (NCBI)`[line] %in% c("NA",NA,"")) {
    taxonomy_tbl$`Family (NCBI)`[line] <- paste0("family of ", taxonomy_tbl$`Suborder (NCBI)`[line]) }
  
  if (taxonomy_tbl$`Subfamily (NCBI)`[line] %in% c("NA",NA,"")) {
    taxonomy_tbl$`Subfamily (NCBI)`[line] <- paste0("subfamily of ", taxonomy_tbl$`Family (NCBI)`[line]) }
  
  if (is.na(taxonomy_tbl$`Genus (NCBI)`[line])) {
    taxonomy_tbl$`Genus (NCBI)`[line] <- paste0("genus of ", taxonomy_tbl$`Subfamily (NCBI)`[line]) }
  }

```

### Combine tax and BLAST hits ----

```{r, eval=FALSE, echo=TRUE}
# taxonomy_tbl_bckp2 <- taxonomy_tbl

blast_res_full
taxonomy_tbl


#10- bind tax rank cols to DB_tbl ----
blast_res_tax <- left_join(x = blast_res_full, 
                           y = taxonomy_tbl,
                           by = "query_taxID") 

blast_res_tax[is.na(blast_res_tax$`Superkingdom (NCBI)`),]%>% View()

all_ps_tbl %>% unique()


blast_res_tax %>% filter(`Genus (NCBI)` %in% c(NA)) %>% View()

blast_res_full %>% colnames()

#save complete taxoomy table ----
saveRDS(object = blast_res_tax,file = "~/prjcts/ecomol/analyses/2025/Sq_dez25/results/blast/blast_res_tax_285_seqs.rds")
blast_res_tax <- readRDS(file = "~/prjcts/ecomol/analyses/2025/Sq_dez25/results/blast/blast_res_tax_285_seqs.rds")

```

### Join BLASTn/tax to results ----

```{r, eval=FALSE, echo=TRUE}
all_ps_tbl$`ASV tip` %>% unique()
blast_res_tax$`ASV tip` %>% unique()


all_ps_tbl_blast <- dplyr::left_join(x = all_ps_tbl,
                                     y = blast_res_tax,
                                     by = "ASV tip") %>% 
  dplyr::rename("ASV (Sequence)" = "ASV") %>% 
  dplyr::filter(Abundance > 0)

colnames(all_ps_tbl_blast)
```

## BOLD identification (COI only)

```{r, eval=FALSE}

install.packages("bold")
library(bold)

# Identify ASVs using BOLD API ----

  asvs_bold <- asvs_blast_all[nchar(asvs_blast_all) >=80]
  asvs_bold_rev <- asvs_blast_all[nchar(asvs_blast_all) >=80] %>% 
    DNAStringSet() %>% 
    reverseComplement() %>% 
    as.character()


sessionInfo()

library(bold)
################################################################################
# function to run multiple bold searches and parse results
            ID_bold <- function(sequence,
                                db,
                                # response,
                                keepSeq,
                                Nhits){
  
# db <-  "COX1_SPECIES_PUBLIC"
# keepSeq <-  TRUE
# Nhits <-  3
# sequence <- c("AGCCCTCAGCCTCCTAATCCGAGCAGAGCTTAGTCAACCCGGGTCCCTTCTAGGTGACGACCAAATTTATAATGTTATCGTTACCGCACATGCTTTCGTAATAATCTTCTTCATAGTGATGCCGATCATAATTGGGGGCTTCGGAAACTGACTGGTCCCGCTAATGATTGGC")
    print ("ENTREI")
  
# Identify sequence via BOLD ----
  bold_res <- bold::bold_identify(sequences = c(sequence), 
                            db = db,
                            response = FALSE,
                            keepSeq = keepSeq)
  
  print("rodou bold id")
# recover taxonomy ----
  if (nrow(bold_res[[1]]) >= 1){
    
    
  print ("entrou no if")
# filter first 3 best hits by similarity ----
    bold_res_filt <- bold_res[[1]] %>% 
      head(Nhits) %>% 
      dplyr::arrange(tidytable::desc(similarity)) 
    
    bold_res_tax <- bold::bold_identify_taxonomy(bold_res_filt)
    
    bold_res_tax_filt <- bold_res_tax %>% select(c("ID",
                                                   "similarity",
                                                   "taxonomicidentification",
                                                   "genus_name",
                                                   "family_name",
                                                   "order_name",
                                                   "class_name",
                                                   "phylum_name",
                                                   # "sequencedescription",
                                                   "database",
                                                   # "citation",
                                                   # "specimen_url",
                                                   "specimen_country"
                                                   # ,
                                                   # "specimen_lat",
                                                   # "specimen_lon",
                                                   # "phylum_taxID",
                                                   # "class_taxID",
                                                   # "order_taxID",
                                                   # "family_taxID",
                                                   # "subfamily_taxID",
                                                   # "subfamily_name",
                                                   # "genus_taxID",
                                                   # "species_taxID",
                                                   # "species_name"
    )) %>% 
      dplyr::rename("ID (BOLD)" = "ID",
                    "Similarity (BOLD)" = "similarity",
                    "Species (BOLD)" = "taxonomicidentification",
                    "Genus (BOLD)" = "genus_name",
                    "Family (BOLD)" = "family_name",
                    "Order (BOLD)" = "order_name",
                    "Class (BOLD)" = "class_name",
                    "Phylum (BOLD)" = "phylum_name",
                    "Database (BOLD)" = "database",
                    "Sp. Country (BOLD)" = "specimen_country")
    
# organize results widewise ----
    bold_res_tax_filt <- tibble::rowid_to_column(
      bold_res_tax_filt,
      var = "res"
    )
    
    bold_res_tax_filt <- tidyr::pivot_wider(
      bold_res_tax_filt,
      names_from = "res",
      values_from = base::seq_len(
        base::ncol(bold_res_tax_filt)
      ),
      names_glue = "{res}_{.value}"
    )
    
    bold_res_tax_filt <- bold_res_tax_filt %>%
      dplyr::mutate(`Sequence` = sequence) %>%
      dplyr::relocate(tidyr::starts_with("6_")) %>%
      dplyr::relocate(tidyr::starts_with("5_")) %>%
      dplyr::relocate(tidyr::starts_with("4_")) %>%
      dplyr::relocate(tidyr::starts_with("3_")) %>%
      dplyr::relocate(tidyr::starts_with("2_")) %>%
      dplyr::relocate(tidyr::starts_with("1_")) %>%
      dplyr::relocate("Sequence") %>%
      dplyr::select(-tidyr::ends_with(c("_res", "_query")))
    
#return results ----
    return(bold_res_tax_filt)
    
  }
}

################################################################################





bold_res_tax %>% colnames() %>%  paste0(collapse = '",\n"') %>% cat()







# testando a função ----
teste <- ID_bold(sequence =  "AGCCCTCAGCCTCCTAATCCGAGCAGAGCTTAGTCAACCCGGGTCCCTTCTAGGTGACGACCAAATTTATAATGTTATCGTTACCGCACATGCTTTCGTAATAATCTTCTTCATAGTGATGCCGATCATAATTGGGGGCTTCGGAAACTGACTGGTCCCGCTAATGATTGGCGCACCCGATATGGCATTTCCACGAATAAATAACATAAGCTTCTGACTACTACCCCCATCTTTCCTCCTCCTTCTAGCATCTTCCGGAGTAGAGGCCGGGGCCG",
                       db = "COX1_SPECIES_PUBLIC",
                       # response = FALSE,
                       keepSeq = TRUE,
                       Nhits = 3)

#  
#  
# teste2 <- primers_all_orients <- purrr::map_dfr(.x = seqs,
#                                                 .f = ID_bold,
#                                                  db = "COX1_SPECIES_PUBLIC",
#                                                  keepSeq = TRUE,
#                                                  Nhits = 3)
#  

# which(asvs_bold %in% "TAGATTTAACTATTTTCTCCCTACATCTGGCAGGGGTATCATCCATTCTAGGAGCCATTAACTTTATTACAACCATCATCAACATGAAACCCCCCTCTATCTCACAATATCAAACACCATTATTTGTGTGATCAGTCCTAATTACGGCCGTACTTCTTCTACTATCTCTCCCCGTCTTAGCCGCAGGTATTACAATGTTGCTAACAGACCGAAACTTAAATACTACATTCTTTGACCCAGCAGGAGGAGGAGACCCAATCCTTTATCAACACCTA")
# 
# which(asvs_bold %in% "CCTTTACTTAGTATTCGGTGCCTGAGCTGGAATAGTAGGCACAGCTCTCAGCCTCCTAATCCGAGCAGAACTAAGTCAACCTGGCTCCCTGCTAGGTGATGATCAAATCTACAATGTTATCGTAACTGCACATGCATTTGTGATAATTTTCTTTATAGTAATACCAGTAATGATTGGGGGCTTCGGAAACTGACTTATTCCCCTAATGATCGGTG")
# 
# 
# 
# # bold_IDs_tax  <- ID_bold(sequence = asvs_bold,
# # bold_IDs_tax  <- ID_bold(sequence = asvs_bold[1096],
# bold_IDs_tax  <- ID_bold(sequence = "TAGATTTAACTATTTTCTCCCTACATCTGGCAGGGGTATCATCCATTCTAGGAGCCATTAACTTTATTACAACCATCATCAACATGAAACCCCCCTCTATCTCACAATATCAAACACCATTATTTGTGTGATCAGTCCTAATTACGGCCGTACTTCTTCTACTATCTCTCCCCGTCTTAGCCGCAGGTATTACAATGTTGCTAACAGACCGAAACTTAAATACTACATTCTTTGACCCAGCAGGAGGAGGAGACCCAATCCTTTATCAACACCTA",
# # bold_IDs_tax  <- ID_bold(sequence = "CCTTTACTTAGTATTCGGTGCCTGAGCTGGAATAGTAGGCACAGCTCTCAGCCTCCTAATCCGAGCAGAACTAAGTCAACCTGGCTCCCTGCTAGGTGATGATCAAATCTACAATGTTATCGTAACTGCACATGCATTTGTGATAATTTTCTTTATAGTAATACCAGTAATGATTGGGGGCTTCGGAAACTGACTTATTCCCCTAATGATCGGTG",
#                        # db = c("COX1", "COX1_SPECIES", "COX1_SPECIES_PUBLIC", "COX1_L640bp"),
#                        db = "COX1_SPECIES_PUBLIC",
#                        # response = FALSE,
#                        keepSeq = TRUE,
#                        Nhits = 3)








# running the function ----

cores_to_be_used <- future::availableCores() - 2 # Usar todos os cores -2 = 78
future::plan(future::multisession(workers = cores_to_be_used))


tictoc::tic("Parallel BOLD")

BOLD_ids_1 <- furrr::future_map_dfr(.x = asvs_bold[990:993],
                                  .f = ID_bold,
                                  db = "COX1_SPECIES_PUBLIC",
                                  keepSeq = TRUE,
                                  Nhits = 3,
                                  .options = furrr::furrr_options(seed = NULL))


tictoc::toc()


tictoc::tic("Parallel BOLD")

BOLD_ids_rev_1 <- furrr::future_map_dfr(.x = asvs_bold_rev,
                                  .f = ID_bold,
                                  db = "COX1_SPECIES_PUBLIC",
                                  keepSeq = TRUE,
                                  Nhits = 3,
                                  .options = furrr::furrr_options(seed = NULL))


tictoc::toc()

which(unique(all_ps_tbl_blast$ASV) %in% as.character(reverseComplement(DNAStringSet(unique(all_ps_tbl_blast$ASV)))))


which(asvs_bold %in% as.character(reverseComplement(DNAStringSet(unique(all_ps_tbl_blast$ASV)))))
which(asvs_bold %in% all_ps_tbl_blast$ASV)

# #Save env
   # base::save.image("~/prjcts/iSeq_27/env-iSeq_27_posBOLD-10jan24.RData")

   BOLD_ids_1 <- BOLD_ids_1 %>% 
     dplyr::rename("Sequence" = "ASV")
   
   
   
# Combine bold results ----
   
   BOLD_ids_1$ASV %in% unique(all_ps_tbl_blast$ASV) %>% sum()
   BOLD_ids_1$ASV %in% dada2::rc(unique(all_ps_tbl_blast$ASV)) %>% sum()
   BOLD_ids_1$ASV %in% unique(asvs_blast_all) %>% sum()
   

# reverse-complementing BOLD hits sequences results so can be joined to comple results table ---- 
   
   BOLD_ids_1$ASV <- dada2::rc(BOLD_ids_1$ASV)
   
   
   
   
   
   
   
   
   
   
   
   all_ps_tbl_blast <- all_ps_tbl_blast %>% 
     left_join(y = BOLD_ids_1,
               by = "Sequence")
   
   View(all_ps_tbl_blast)
   
   all_ps_tbl_blast %>% 
     filter(!is.na(`blast ID`)) %>% 
     View()

   all_ps_tbl_blast %>% 
     filter(`Read origin` %in% c("concat")) %>% 
     View()

```

## Set Final ID

```{r,echo=TRUE, eval=FALSE}
# BLASTn final identification ----
all_ps_tbl_blast <- all_ps_tbl_blast %>%
           mutate("Final ID (BLASTn)" = `blast ID`) 
# %>% 
#            mutate("Final ID (BOLD)" = `1_Species (BOLD)`)

all_ps_tbl_blast$`Final ID (BLASTn)` %>% unique() %>%  sort()
all_ps_tbl_blast$`Final ID (BOLD)` %>% unique() %>%  sort()



```

## ASVs seqs

### Create ASV headers

```{r,echo=TRUE, eval=FALSE}
#25 - recover all ASVs sequences to prepare fasta ----
# giving our seq headers more manageable names (ASV_1, ASV_2...) ----
all_asv_seqs <- tibble("ASV tip" = unique(all_ps_tbl_blast$`ASV tip`))

#how many digits to pass to sprintf----
sprt_dg <- all_asv_seqs %>%  nrow() %>% nchar()


all_asv_seqs <- all_asv_seqs %>%
  dplyr::mutate("ASV Size (pb)" = nchar(`ASV tip`)) %>%
  dplyr::arrange(dplyr::desc(`ASV Size (pb)`)) %>% 
  dplyr::mutate("ASV header" = paste0(sprintf(paste0(">ASV_%0",sprt_dg,"d"), row_number(.)),"-",.$`ASV Size (pb)`, "bp"))


#add ASV information to results tbl ----
all_ps_tbl_blast <- dplyr::left_join(x = all_ps_tbl_blast,
                                     y = all_asv_seqs[,c("ASV tip","ASV header"
                                                         # ,"ASV Size (pb)"
                                                         )],
                                     by = "ASV tip")


              
              
              log10(all_ps_tbl_blast$Abundance) %>% table()  %>%  plot()
              all_ps_tbl_blast$`Relative abundance on sample` %>% table()  %>%  plot()
              log10(all_ps_tbl_blast$`Relative abundance on sample`/100) %>% table()  %>%  plot()
              (all_ps_tbl_blast$`Relative abundance on sample`) %>% table()  %>%  plot()
              
              
              all_ps_tbl_blast %>% unique()
              all_ps_tbl_blast %>% duplicated()
              all_ps_tbl_blast[all_ps_tbl_blast %>% duplicated(),]
              all_ps_tbl[all_ps_tbl %>% duplicated(),]
              
              
              
              all_ps_tbl_blast$Abundance %>% table()  %>%  plot()
              all_ps_tbl_blast$`Relative abundance on sample` %>% table() %>%  plot()

```

### group ASVs into OTUs

```{r,echo=TRUE, eval=FALSE}

asvs_abd <- all_ps_tbl_blast %>%
  dplyr::filter(!str_detect(string = `ASV tip`,pattern = "N")) %>% 
  dplyr::select(c("ASV tip","ASV header","Abundance")) %>% 
  dplyr::group_by(`ASV tip`,`ASV header`) %>%
  dplyr::mutate("ASV total abundance" = sum(Abundance)) %>%
  dplyr::ungroup() %>% 
  dplyr::select(c(`ASV tip`,`ASV header`,`ASV total abundance`)) %>%
  BiocGenerics::unique() %>%
  dplyr::mutate(`ASV header abd` = paste0(`ASV header`,"_",`ASV total abundance`))

#write fasta file with ASVs and Taxonomy
all_asv_fasta_abd <- c(rbind(asvs_abd$`ASV header abd`, asvs_abd$`ASV tip`))

write(all_asv_fasta_abd, paste0(swarm_path,"/",analysis_rad,"-ASVs_abd.fasta"))

paste0(swarm_path,"/",analysis_rad,"-ASVs_abd.fasta")


```

### Run SWARM V2 on command line

```{r ,echo=TRUE, eval=FALSE}
# 1 - move to swarm folder on bash

# cd $PRJCT_DIR/results/swarm

# 2 - run SWARM

# swarm -t 50 ~/prjcts/iSeq_27/results/EM132_Ecomol_ovoselarvas-ASVs_abd.fasta -s EM132_Ecomol_ovoselarvas_abd-swarm.stats -o EM132_Ecomol_ovoselarvas_abd-swarm.out -w EM132_Ecomol_ovoselarvas_abd-representative_OTUs.fasta-i EM132_Ecomol_ovoselarvas_abd-swarm.structure -f


system2(command = "swarm", args = c(paste0(
  paste0(swarm_path,"/",analysis_rad,"-ASVs_abd.fasta "),
                                   " -t 50 "," -f ",
                                   " -s ", paste0(swarm_path,"/",analysis_rad,"-swarm.stats "),
                                   " -o ", paste0(swarm_path,"/",analysis_rad,"-swarm.out "),
                                   " -w ", paste0(swarm_path,"/",analysis_rad,"-swarm-representative_OTUs.fasta "),
                                   " -i ", paste0(swarm_path,"/",analysis_rad,"-swarm.structure ")
                                   )),) # guarantee no zerolength reads


```

### Associate ASVs to OTUs

```{r ,echo=TRUE, eval=FALSE}

#detect files generated by swarm and locate OTUs output
swarm_clust <- list.files(path = paste0(swarm_path),
                          pattern = "swarm.out",
                          full.names = TRUE ) %>% 
  readr::read_lines()

 swarm_clust
#################################  Function  ###################################
find_OTU <- function(ASV_header, clusters_swarm){
  
  ASV_OTU_tbl <- tibble::tibble(`ASV header abd` = stringr::str_remove_all(string = ASV_header,
  pattern  = ">"),
                                OTU = 0)
  
  ASV_OTU_tbl$OTU <- which(grepl(x = clusters_swarm,
                                     pattern = ASV_OTU_tbl$`ASV header abd`))
                                    
  return(ASV_OTU_tbl)
}
################################################################################


# prepare parallel OTU association ----
cores_to_be_used <- future::availableCores() - 2 # Usar todos os cores -2 = 78
future::plan(future::multisession(workers = cores_to_be_used))



# run find_OTU function on parallel ----
ASVs_and_OTUs <- furrr::future_map_dfr(.x = asvs_abd$`ASV header abd`,
                                       clusters_swarm = swarm_clust,
                                       .f = find_OTU,
                                       .options = furrr::furrr_options(seed = NULL))

# generate unique OTU names ----
#how many digits to pass to sprintf
sprt_dg <- ASVs_and_OTUs$OTU %>% 
  BiocGenerics::unique() %>% 
  length() %>% 
  nchar()

ASVs_and_OTUs <- ASVs_and_OTUs %>% 
  dplyr::mutate("OTU" = paste0(sprintf(paste0("OTU_%0",sprt_dg,"d"), OTU))) %>% 
  dplyr::mutate("ASV header abd" = str_replace(string = `ASV header abd`,
                                               pattern =  "^",
                                               replacement = ">" ))


ASVs_and_OTUs$OTU %>% unique() %>% length()
ASVs_and_OTUs$OTU %>% unique() 


asvs_abd <- left_join(asvs_abd,
                        ASVs_and_OTUs,
                      by = "ASV header abd")

asvs_abd

#add OTU names to results table ----
all_ps_tbl_blast <- left_join(x = all_ps_tbl_blast,
                              y = asvs_abd[,c("ASV tip","OTU")],
                              by = "ASV tip") 



colnames(all_ps_tbl_blast)

all_ps_tbl_blast %>% dplyr::select(`Final ID (BLASTn)`,OTU) %>% View() 
all_ps_tbl_blast %>% dplyr::select(`Final ID (BLASTn)`,OTU,`ASV Size (pb)`) %>% unique() %>% View() 
all_ps_tbl_blast %>% dplyr::select(`Final ID (BLASTn)`,OTU,`ASV Size (pb)`,`Read origin`) %>% unique() %>% View() 
all_ps_tbl_blast %>% dplyr::select(`ASV (Sequence)`,`Final ID (BLASTn)`,OTU,`ASV Size (pb)`,`Read origin`) %>% unique() %>% View() 



# all_ps_tbl_blast %>% dplyr::select(`Final ID (BLASTn)`,OTU) %>% dplyr::select(OTU) %>% unique() 
all_ps_tbl_blast %>% dplyr::select(`ASV (Sequence)`,`Final ID (BLASTn)`,OTU) %>% unique() 

```

### Write all ASVs with OTU and taxonomy

```{r,echo=TRUE, eval=FALSE}

all_asv_seqs_tax <- all_ps_tbl_blast %>% 
  dplyr::select(c("ASV (Sequence)", "Primer", "ASV header","OTU",
           "Class (NCBI)", "Family (NCBI)", "Genus (NCBI)", "blast ID","Project")) %>% 
  mutate(`ASV header` = str_remove_all(string = `ASV header`,pattern = ">")) %>% 
  unique() %>% 
  dplyr::group_by(`ASV (Sequence)`,`ASV header`,OTU) %>% 
  mutate(`Full ASV header` = paste0(">ENVIRONMENTAL: ",`ASV header`,"-",OTU,"-",`Primer`,"--", `Class (NCBI)`, ";", `Family (NCBI)`, ";", `Genus (NCBI)`, ";", `blast ID`)) %>%
  ungroup() %>% 
  unique() 



################ generate one fasta file per project #########
for (PRJ in all_projects) {
  project_name <- PRJ %>% 
    str_replace_all(pattern = " ",
                    replacement = "_") %>% 
    str_replace_all(pattern = "_-_",
                    replacement = "--")
  
  all_asv_seqs_tax_prj <- all_asv_seqs_tax %>%
    filter(Project %in% c(PRJ)) 
  
  #write fasta file with ASVs and Taxonomy
  all_asv_fasta <- c(rbind(all_asv_seqs_tax_prj$`Full ASV header`, all_asv_seqs_tax_prj$`ASV (Sequence)`))
  
  write(all_asv_fasta, paste0(results_path,"/",PRJ,"--all_ASVs.fasta"))

}



all_asv_seqs_tax %>% colnames()

all_asv_seqs_tax[,c(3,4,8)] %>% 
  print(n=100)




```

## Contamination control

### Identify ASVs present on the Blanks/Negative controls

```{r,echo=TRUE, eval=FALSE}

#corrigindo que na tabela os controles não foram importados

 all_ps_tbl_blast$Sample %>% unique()

all_ps_tbl_blast$Sample[all_ps_tbl_blast$Sample %>% grepl(pattern = c("Neg|NEG|Bco|Pos|Bra"),ignore.case = T)] %>% unique()
all_ps_tbl_blast$Unique_File_name[all_ps_tbl_blast$Unique_File_name %>% grepl(pattern = c("Neg|NEG|Bco|Pos|Bra"),ignore.case = T)] %>% unique()

all_ps_tbl_blast$PCR.control %>% unique() %>% str_split(pattern = ";",simplify = T) %>% c() %>%  unique() %>% sort()
all_ps_tbl_blast$Filtration.control %>% unique() %>% str_split(pattern = ";",simplify = T) %>% c() %>%  unique() %>% sort()
all_ps_tbl_blast$Extraction.control %>% unique() %>% str_split(pattern = ";",simplify = T) %>% c() %>%  unique() %>% sort()


# recorrigindo negativos e metadados ----

primers_n_samples_update <- primers_n_samples %>% 
  select( "Sample", "Unique_File_name", "Type", tidyr::starts_with("Metada"), "Researcher", "Project", "Lib", tidyr::ends_with("control") ) 


all_ps_tbl_blast <- all_ps_tbl_blast %>% 
  select(-c("Sample", "Type", tidyr::starts_with("Metada"), "Researcher", "Project", "Lib", tidyr::ends_with("control") )) %>% 
  left_join(y = primers_n_samples_update, by =  "Unique_File_name") 

all_ps_tbl_blast$Type %>% table()
all_ps_tbl_blast$Type %>% unique()

# mark control samples ----
ctrl_types <- c("Extraction control",
              "Extraction Control",
              "Ext. control",
              "Ext. Control",
              "Filt. Control",
              "PCR control",
              "PCR Control",
              "Filt. control",
              "Filtration control",
              "Filtration Control",
              "Negative control",
              "Negative Control",
              "Positive control",
              "Positive Control",
              "Control")

# Identify contamination based on respective controls----
all_ps_tbl_blast$Unique_File_name %>% unique() %>% sort()
all_ps_tbl_blast$`PCR control`%>% unique() %>% sort()
all_ps_tbl_blast$`Filtration control`%>% unique() %>% sort()


#create table with controls only 
all_contam_ASVs <- all_ps_tbl_blast %>%
  dplyr::filter(Abundance > 0) %>% 
  dplyr::filter(Type %in% ctrl_types) %>%
  dplyr::group_by(`ASV (Sequence)`, Unique_File_name) %>% 
  dplyr::mutate("Max. ASV abd. in control" = max(`Relative abundance on sample`)) %>%
  dplyr::ungroup() %>%
  dplyr::select("Unique_File_name",
                "ASV (Sequence)",
                "Max. ASV abd. in control",
                "Final ID (BLASTn)"
                # ,"Final ID (DADA2)"
                ) %>%
  BiocGenerics::unique()


all_contam_ASVs$Unique_File_name %>% unique()



# Is there any of the ASVs in control also in the Samples?
all_contam_ASVs$`ASV (Sequence)` %in% (all_ps_tbl_blast$`ASV (Sequence)` %>% unique())

#which IDs are present on the respective controles
all_ps_tbl_blast[((all_ps_tbl_blast$`ASV (Sequence)`) %in% all_contam_ASVs$`ASV (Sequence)`),] %>% View()



all_ps_tbl_blast$Type %>% unique()


```

### Calculate sample/control proportion

```{r,echo=TRUE, eval=FALSE}

# save new complete table to edit controls
all_ps_tbl_blast_controls <- all_ps_tbl_blast %>% 
  dplyr::mutate("Prop. to PCR control" = 0,
                "Prop. to Ext control" = 0,
                "Prop. to Filt control" = 0)



#confira os nomes dos controles!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
all_contam_ASVs$Unique_File_name

all_ps_tbl_blast_controls$Type %>% unique()
all_ps_tbl_blast_controls$`PCR control` %>% unique()
all_ps_tbl_blast_controls$`Filtration control` %>% unique()
all_ps_tbl_blast_controls$`Extraction control` %>% unique()


all_ps_tbl_blast_controls$Type %>% unique()
all_ps_tbl_blast_controls$Unique_File_name[all_ps_tbl_blast_controls$Type %in% c("PCR Control")] %>% unique()
all_ps_tbl_blast_controls$Unique_File_name[all_ps_tbl_blast_controls$Type %in% c("Filt. control","Filt. Control")] %>% unique()
all_ps_tbl_blast_controls$Unique_File_name[all_ps_tbl_blast_controls$Type %in% c("Ext. control", "Ext. Control")] %>% unique()





for (line in 1:nrow(all_ps_tbl_blast_controls)) {
  

  if(all_ps_tbl_blast_controls$`ASV (Sequence)`[line] %in% (all_contam_ASVs$`ASV (Sequence)`)){
  # tab_size <- nrow(all_ps_tbl_blast_controls) 
  # line <- 
  seq2search <- all_ps_tbl_blast_controls$`ASV (Sequence)`[line]
  file2search <- all_ps_tbl_blast_controls$Unique_File_name[line]
  
  
    PCRcontrols2search <- all_ps_tbl_blast_controls$`PCR control`[line] %>% str_split(pattern = ";") %>% unlist()

    FILTcontrols2search <- all_ps_tbl_blast_controls$`Filtration control`[line] %>% str_split(pattern = ";") %>% unlist()

    EXTcontrols2search <- all_ps_tbl_blast_controls$`Extraction control`[line] %>% str_split(pattern = ";") %>% unlist()
  
  
  PCR_control_tbl <- all_contam_ASVs %>% filter(Unique_File_name %in% PCRcontrols2search & `ASV (Sequence)` %in% seq2search)
  FILT_control_tbl <- all_contam_ASVs %>% filter(Unique_File_name %in% FILTcontrols2search & `ASV (Sequence)` %in% seq2search)
  EXT_control_tbl <- all_contam_ASVs %>% filter(Unique_File_name %in% EXTcontrols2search & `ASV (Sequence)` %in% seq2search)
  
  #proportion on PCR control
  all_ps_tbl_blast_controls$`Prop. to PCR control`[line] <- gtools::foldchange(denom = max(PCR_control_tbl$`Max. ASV abd. in control`),
                                                                         num = all_ps_tbl_blast_controls$`Relative abundance on sample`[line])
  
  #proportion on Filt control
  all_ps_tbl_blast_controls$`Prop. to Filt control`[line] <- gtools::foldchange(denom = max(FILT_control_tbl$`Max. ASV abd. in control`),
                                                                         num = all_ps_tbl_blast_controls$`Relative abundance on sample`[line])
  
  #proportion on Extraction control
  all_ps_tbl_blast_controls$`Prop. to Ext control`[line] <- gtools::foldchange(denom = max(EXT_control_tbl$`Max. ASV abd. in control`),
                                                                         num = all_ps_tbl_blast_controls$`Relative abundance on sample`[line])
  # }
  #denominador = abd in control
  #numerador = abd in sample
  # se +, amostra mais abundante que o controle
  
  # if (line*3==) {
  #   
  }
  print(line)
}


all_ps_tbl_blast_controls <- all_ps_tbl_blast_controls %>%
  dplyr::mutate("Possible contamination" = "True detection")


# Mark possible contaminations ----

  all_ps_tbl_blast_controls <- all_ps_tbl_blast_controls %>% 
    dplyr::mutate(`Contamination status` = dplyr::case_when(
      (all_ps_tbl_blast_controls$`Prop. to PCR control` != 0) ~ "Possible contamination",
      (all_ps_tbl_blast_controls$`Prop. to Filt control` != 0) ~ "Possible contamination",
      (all_ps_tbl_blast_controls$`Prop. to Ext control` != 0) ~ "Possible contamination",
      TRUE ~ "True detection"
      ))
  
  


all_ps_tbl_blast_controls$`Prop. to PCR control` %>% table() %>% plot()
all_ps_tbl_blast_controls$`Prop. to Filt control` %>% table() %>% plot()
all_ps_tbl_blast_controls$`Prop. to Ext control`%>% table() %>% plot()



all_ps_tbl_blast_controls %>% 
  filter(`Contamination status` %in% c("Possible contamination")) %>% View()
```

## Plot identified ASVs

```{r, eval=FALSE}


all_ps_tbl_blast_controls %>% 
  filter(str_detect(`1_subject header`,pattern = "ncult")) %>% 
  pull(`Superkingdom (NCBI)`) %>%
  unique()


all_ps_tbl_blast_controls$`Kingdom (NCBI)`[stringr::str_detect(string = all_ps_tbl_blast_controls$`1_subject header`,
                                              pattern =  "ncultur")] <- NA

all_ps_tbl_blast_controls$`Superkingdom (NCBI)` %>% unique()

all_ps_tbl_blast_controls$Project %>% unique()


library(plotly)

SHAPES <- c("Archaea" = 25,
            "Bacteria" = 24,
            "Eukaryota" = 21,
            "Viruses" = 23)


for (PRJ in all_projects) {

  message(paste0("ploting project: ", PRJ))

project_name <- PRJ %>% 
  str_replace_all(pattern = " ",
                  replacement = "_") %>% 
  str_replace_all(pattern = "_-_",
                  replacement = "--")

  
N_samples <-   all_ps_tbl_blast_controls %>%
  dplyr::filter(Project %in% c(PRJ)) %>% 
  dplyr::pull(Unique_File_name) %>% unique() %>% length()

max_ASV <- all_ps_tbl_blast_controls %>%
  dplyr::filter(Project %in% c(PRJ)) %>% 
  dplyr::pull(`ASV Size (pb)`)  %>% max()

min_ASV <- all_ps_tbl_blast_controls %>%
  dplyr::filter(Project %in% c(PRJ)) %>% 
  dplyr::pull(`ASV Size (pb)`)  %>% min()




ASV_legth_by_Sample_BLAST_plot <- all_ps_tbl_blast_controls  %>%
  dplyr::arrange(Primer) %>% 
  dplyr::filter(Project %in% c(PRJ)) %>% 
  # dplyr::filter(Type %in% c("Sample")) %>%
  dplyr::mutate("BLASTn pseudo-score" = ((`1_indentity`*(`1_qcovhsp`/10))/10)) %>%
  #correct uncultured detections
  dplyr::mutate("BLASTn pseudo-score" = dplyr::case_when(str_detect(`1_subject header`,
                                                                    pattern = "ncult") ~ NA,
                                                         TRUE ~ `BLASTn pseudo-score`)) %>% 
  dplyr::arrange(dplyr::desc(`BLASTn pseudo-score`)) %>% 
  dplyr::arrange(!is.na(`BLASTn pseudo-score`),`BLASTn pseudo-score`) %>% 
  ggplot(aes(
    # y = Sample,
    y = interaction(Sample, Unique_File_name, sep = " - "),
    x =`ASV Size (pb)`,
    fill = `BLASTn pseudo-score`,
    col = `BLASTn pseudo-score`,
    shape = `Superkingdom (NCBI)`,
    size =`Relative abundance on sample`,
    alpha = 0.2,
    group = `Final ID (BLASTn)`,
    text = paste0(
      "Final ID (BLASTn): ", `Final ID (BLASTn)`, "<br>",
      "Sample: ", Sample, "<br>",
      "ASV Size (pb): ", `ASV Size (pb)`, "<br>",
      "BLASTn pseudo-score: ", `BLASTn pseudo-score`, "<br>",
      "Superkingdom (NCBI): ", `Superkingdom (NCBI)`, "<br>",
      "Phylum (NCBI): ", `Phylum (NCBI)`, "<br>",
      "Class (NCBI): ", `Class (NCBI)`, "<br>",
      "Order (NCBI): ", `Order (NCBI)`, "<br>",
      "Relative abundance on sample: ", `Relative abundance on sample`
                                                   ))) +
  geom_jitter(height = 0.4,
              width = 0.25) +
  scale_fill_gradientn(name = "BLASTn\nidentification\n _pseudo-score_ (%)",
                     na.value = "grey95",
                     colours = c("#330000", "darkred", "red", "yellow", "green", "darkgreen"),
                     values = scales::rescale(c(60, 100), to = c(0, 1)),
                     breaks = c(60, 65, 70, 75, 80, 85, 90, 95, 100),
                     limits = c(60, 100)) +
  scale_color_gradientn(name = "BLASTn\nidentification\n _pseudo-score_ (%)",
                      na.value = "grey80",
                      colours = c("#330000", "darkred", "red", "yellow", "green", "darkgreen"),
                      values = scales::rescale(c(60, 100), to = c(0, 1)),
                      breaks = c(60, 65, 70, 75, 80, 85, 90, 95, 100),
                      limits = c(60, 100)) +
  scale_size_continuous(name = "Abundância\n     relativa\nna amostra (%)",
                        breaks = c(0,1,10,20,30,40,50,60,70,80,90,100),
                        ) +
  scale_x_continuous(breaks = c(seq(((floor((min_ASV / 10)) * 10)-10),(max_ASV + 10),10)),
                     expand = c(0.02,0.02),
                     sec.axis = dup_axis()) +
  scale_shape_manual(name = "Superkingdom (NCBI)",
                     values = SHAPES,
                     breaks = names(SHAPES),
                     na.value = 22
                     ) +
  xlab("Tamanho da ASV (pb)") +
  ylab("Amostra") +
  ggtitle(label = paste0("EcoMol - ",project_name),
          subtitle = "Status de identificação de todas ASVs encontradas na análise, após remoção das ASVs dos controles negativos") +
  theme_bw(base_size = 30) +
  theme(legend.title = element_markdown(),strip.text = element_text(size = 24),
        strip.text.y = element_text(angle = 0),
        axis.title = element_text(size = 24),
        axis.text.x = element_text(size = 24,angle = 0,hjust = 0.5),
        legend.position = "bottom",
        legend.key.width = unit(4, 'cm'),
        legend.key.height = unit(0.5, 'cm'),
        panel.grid.major.y = element_blank(),
        strip.placement = "outside") +
    geom_hline(yintercept = seq(1.5,N_samples,1), linetype = 1,linewidth=0.05,col="#dddddd") +
  facet_grid(rows = vars(`Read origin`, Primer),
             space = "free_y",
             scales = "free",
             axes = "all_x",
             axis.labels = "all_x",switch = "x") +
  guides(
  alpha = "none",
  color = "none",
  shape = guide_legend(override.aes = list(size = 6)),  # Increase shape size in legend
  size = guide_legend(override.aes = list(size = 5))    # Adjust size scale in legend
)


ggsave(file = paste0(results_path,"/",PRJ,"-ASV_length_by_sample--All_ASVs.pdf",collapse = ""),
     plot = ASV_legth_by_Sample_BLAST_plot,
     device = "pdf",
     width = 140,
     # height = ifelse(N_samples <= 10, 80, round(N_samples/0.5)), limitsize=FALSE,
     height = round((N_samples*2) + 15),
     limitsize=FALSE,
     units = "cm",
     dpi = 300)

ASV_legth_by_Sample_BLAST_plot <- ASV_legth_by_Sample_BLAST_plot +
  theme_bw(base_size = 10)

ASV_legth_by_Sample_BLAST_plotly <- ASV_legth_by_Sample_BLAST_plot %>% 
  plotly::ggplotly(
    , tooltip = "text",
    # tooltip = c("Final ID (BLASTn)",
  #                      "Sample",
  #                      "ASV Size (pb)",
  #                      "BLASTn pseudo-score",
  #                      "Superkingdom (NCBI)",
  #                      "Phylum (NCBI)",
  #                      "Class (NCBI)",
  #                      "Order (NCBI)",
  #                      "Relative abundance on sample"),
           # width = 2000,
           # height = 800,
           originalData = T)

  
htmlwidgets::saveWidget(widget = ASV_legth_by_Sample_BLAST_plotly,
                        selfcontained = TRUE,
                        file = paste0(results_path,"/",PRJ,"-ASV_length_by_sample--All_ASVs.html",collapse = ""))

}
```

#### Show figure on html

```{r, eval=TRUE,echo=TRUE, results='asis'}
# Extract the PDF path from the R object

pdf_info <- 
  list.files(path = "/home/noreh/ecomol/analyses/2024/Sq_dez25/results",
             pattern = "-ASV_length_by_sample--All_ASVs.pdf",
             full.names = T)

  
# Generate the iframe HTML code
cat(paste0('<iframe src="', pdf_info, '" width="800" height="800"></iframe>'))
```

## ASV expected length per primer

```{r, eval=FALSE, echo=TRUE}
# fill ranges column with expected primer insert ranges

all_ps_tbl_blast_controls$Primer %>% unique() 


all_ps_tbl_blast_controls %>% colnames()
 

all_ps_tbl_blast_controls <- all_ps_tbl_blast_controls %>% 
dplyr::mutate(`Expected length` = "FALSE")

all_ps_tbl_blast_controls$Primer %>% unique() %>% sort() %>% 
  paste0(collapse = '",\n"') %>% cat()


all_ps_tbl_blast_controls <- all_ps_tbl_blast_controls %>% 
  dplyr::mutate(`Expected length` = dplyr::case_when(
  ###### eDNA Vale
  (Primer %in%  c("MiBird") & `ASV Size (pb)` %in% c(155:250)) ~ "in range",
  (Primer %in%  c("p16SMam1") & `ASV Size (pb)` %in% c(69:162)) ~ "in range",
  (Primer %in%  c("p12SV5") & `ASV Size (pb)` %in% c(85:110)) ~ "in range",
  (Primer %in%  c("p12SV5inv") & `ASV Size (pb)` %in% c(85:110)) ~ "in range",
  (Primer %in%  c("MiFish") & `ASV Size (pb)` %in% c(115:260)) ~ "in range",
  (Primer %in%  c("p12SBatra") & `ASV Size (pb)` %in% c(49:140)) ~ "in range",
  (Primer %in%  c("Reptile") & `ASV Size (pb)` %in% c(140:280)) ~ "in range",
  (Primer %in%  c("COI_FWh") & `ASV Size (pb)` %in% c(170:250)) ~ "in range",
  (Primer %in%  c("Coq_Fish") & `ASV Size (pb)` %in% c(200:600)) ~ "in range",
  (Primer %in%  c("COI_R1") & `ASV Size (pb)` %in% c(120:150)) ~ "in range",
  (Primer %in%  c("p18sEuk") & `ASV Size (pb)` %in% c(100:420)) ~ "in range",
  (Primer %in%  c("p16SV4") & `ASV Size (pb)` %in% c(50:340)) ~ "in range",
  (Primer %in%  c("MiFish2") & `ASV Size (pb)` %in% c(140:200)) ~ "in range",
  (Primer %in%  c("MiFishEM") & `ASV Size (pb)` %in% c(115:280)) ~ "in range",
  (Primer %in%  c("MiFishEMs") & `ASV Size (pb)` %in% c(50:340)) ~ "in range",
  (Primer %in%  c("V12Su") & `ASV Size (pb)` %in% c(200:220)) ~ "in range",
  (Primer %in%  c("V16Su") & `ASV Size (pb)` %in% c(200:220)) ~ "in range",
  (Primer %in%  c("VCOIu") & `ASV Size (pb)` %in% c(120:180)) ~ "in range",
  # (Primer %in%  c("16Smim1") & `ASV Size (pb)` %in% c(85:97)) ~ "in range",
  # (Primer %in%  c("MiBird") & `ASV Size (pb)` %in% c(160:200)) ~ "in range",
  # # (Primer %in%  c("MiFishE") & `ASV Size (pb)` %in% c(160:300)) ~ "in range",
  # (Primer %in%  c("p12SV5") & `ASV Size (pb)` %in% c(80:150)) ~ "in range",
  # (Primer %in%  c("MiFish") & `ASV Size (pb)` %in% c(150:200)) ~ "in range",
  # (Primer %in%  c("p16SMam1") & `ASV Size (pb)` %in% c(80:120)) ~ "in range",
  TRUE ~ "out of range"
  )) 

all_ps_tbl_blast_controls$`Expected length` %>% table()

all_ps_tbl_blast_controls$`Expected length`[all_ps_tbl_blast_controls$`Expected length` == "FALSE"]

all_ps_tbl_blast_controls %>% colnames() %>% sort()

```

## Set Curated ID

The curated identification is obtained by manually (but programatically) correcting species based on biological scientific expertise, or species names that are incorrect.

```{r,echo=TRUE, eval=FALSE}

all_ps_tbl_blast_controls <- all_ps_tbl_blast_controls %>% 
  # mutate(`Final ID ` = unfactor(`Final ID `)) %>% 
  dplyr::mutate("Curated ID" = `Final ID (BLASTn)`)



# define most trustable taxonomic rank ----

all_ps_tbl_blast_controls <- all_ps_tbl_blast_controls %>% 
  # dplyr::mutate("BLASTn pseudo-score" = `1_indentity` *`1_qcovhsp` /100) %>% 
  dplyr::mutate("BLASTn pseudo-score" =  ((10 * `1_indentity`) + `1_qcovhsp`) / 11) %>%
  # dplyr::mutate("BLASTn pseudo-score" = ((`1_indentity`*(`1_qcovhsp`/10))/10)) %>% 
  dplyr::mutate("Identification" =  dplyr::case_when(
    `BLASTn pseudo-score` >= 98 ~ `Final ID (BLASTn)`, 
    `BLASTn pseudo-score` >= 95 & 
      `BLASTn pseudo-score` < 98 ~ `Genus (NCBI)`, 
    `BLASTn pseudo-score` >= 90 & 
      `BLASTn pseudo-score` < 95 ~ `Family (NCBI)`, 
    `BLASTn pseudo-score` >= 80 & 
      `BLASTn pseudo-score` < 90 ~ `Order (NCBI)`, 
    `BLASTn pseudo-score` >= 60 & 
      `BLASTn pseudo-score` < 80 ~ `Class (NCBI)`),
                "Identification Max. taxonomy" = dplyr::case_when(`BLASTn pseudo-score` >= 98 ~ "Species",
                                       `BLASTn pseudo-score` >= 95 & `BLASTn pseudo-score` < 98 ~ "Genus",
                                       `BLASTn pseudo-score` >= 90 & `BLASTn pseudo-score` < 95 ~ "Family",
                                       `BLASTn pseudo-score` >= 80 & `BLASTn pseudo-score` < 90 ~ "Order",
                                       `BLASTn pseudo-score` >= 60 & `BLASTn pseudo-score` < 80 ~ "Class")) %>% 
  dplyr::relocate("Identification","Identification Max. taxonomy","BLASTn pseudo-score")


```

## Mark Metazoans

```{r, eval=FALSE}
#
#
#zooplankton	perifiton	fitoplankton
#class ---
# phylum

bentos_phy <- c(
  "Annelida",
  "Arthropoda",
  "Mollusca") %>% 
  BiocGenerics::unique() %>% 
  sort()





zplnk_phy <- c("Amoebozoa",
               "Arthropoda",
               "Cercozoa",
               "Ciliophora",
               "Rotifera") %>% 
  BiocGenerics::unique() %>% 
  sort()

prftn_phy <- c("Bacillariophyta",
               "Charophyta",
               "Chlorophyta",
               "Cryptophyta",
               "Cyanobacteria",
               "Euglenophyta",
               "Rhodophyta") %>% 
  BiocGenerics::unique() %>% 
  sort()

ftplnk_phy <- c("Bacillariophyta",
                "Charophyta",
                "Chlorophyta",
                "Cryptophyta",
                "Cyanobacteria",
                "Dinophyta",
                "Euglenophyta",
                "Ochrophyta",
                #
                "Apicomplexa",
                "Bacillariophyta",
                "Cercozoa",
                "Ciliophora",
                "Discosea",
                "Endomyxa",
                "Euglenozoa",
                "Evosea",
                "Foraminifera",
                "Fornicata",
                "Haptophyta",
                "Hemimastigophora",
                "Heterolobosea",
                "Nebulidia",
                "Nibbleridia",
                "Oomycota",
                "Parabasalia",
                "Perkinsozoa",
                "phylum of kingdom of superkingdom of NA",
                "Preaxostyla",
                "Rhodophyta",
                "Tubulinea") %>% 
  BiocGenerics::unique() %>% 
  sort()

# class
bentos_cls <- c("Bivalvia",
                "Clitellata",
                "Gastropoda",
                "Insecta") %>% 
  BiocGenerics::unique() %>% 
  sort()

# class
zplnk_cls <- c("Branchiopoda",
                "Eurotatoria",
                "Filosia",
                "Hexanauplia",
                "Lobosa",
                "Oligohymenophorea") %>% 
  BiocGenerics::unique() %>% 
  sort()

prftn_cls <- c("Bacillariophyceae",
                "Chlorophyceae",
                "Chrysophyceae",
                "Coscinodiscophyceae",
                "Cryptophyceae",
                "Cyanophyceae",
                "Euglenophyceae",
                "Florideophyceae",
                "Mediophyceae",
                "Ulvophyceae",
                "Zygnematophyceae") %>% 
  BiocGenerics::unique() %>% 
  sort()

ftplnk_cls <- c("Bacillariophyceae",
                "Chlorophyceae",
                "Chrysophyceae",
                "Coscinodiscophyceae",
                "Cryptophyceae",
                "Cyanophyceae",
                "Dinophyceae",
                "Euglenophyceae",
                "Mediophyceae",
                "Trebouxiophyceae",
                "Ulvophyceae",
                "Zygnematophyceae",
                #
                "Actinophryidae",
                "Aphelidea",
                "Bigyra",
                "Bolidophyceae",
                "Breviatea",
                "Centroplasthelida",
                "Choanoflagellata",
                "Chrysophyceae",
                "Cryptophyceae",
                "Developea",
                "Dictyochophyceae",
                "Dinophyceae",
                "Eustigmatophyceae",
                "Filasterea",
                "Glaucocystophyceae",
                "Hyphochytriomycetes",
                "Ichthyosporea",
                "Olisthodiscophyceae",
                "Pelagophyceae",
                "Phaeophyceae",
                "Phaeothamniophyceae",
                "Raphidophyceae",
                "Synurophyceae",
                "Xanthophyceae") %>% 
  BiocGenerics::unique() %>% 
  sort()

#----



zplnk_phy
prftn_phy
ftplnk_phy
zplnk_cls
prftn_cls
ftplnk_cls




all_ps_tbl_blast_controls






all_ps_tbl_blast_controls$`Kingdom (NCBI)` %>% table()
all_ps_tbl_blast_controls$`Superkingdom (NCBI)` %>% table()

all_ps_tbl_blast_controls %>% 
  dplyr::filter(`Superkingdom (NCBI)` %in% c("superkingdom of NA")) %>% View()

all_ps_tbl_blast_controls %>% 
  dplyr::filter(`Superkingdom (NCBI)` %in% c("superkingdom of NA")) %>% 
  dplyr::pull("Class (NCBI)") %>% 
  BiocGenerics::unique() %>% 
  sort()

all_ps_tbl_blast_controls %>% 
  dplyr::filter(`Phylum (NCBI)` %in% c("Cyanobacteriota")) %>% View()

all_ps_tbl_blast_controls %>% 
  # dplyr::filter(`Superkingdom (NCBI)` %in% c("superkingdom of NA")) %>% 
  dplyr::pull("Class (NCBI)") %>% 
  BiocGenerics::unique() %>% 
  sort() %>% 
  paste0(collapse = '",\n"') %>% cat()









#mark Possible Metazoan IDs ----

all_ps_tbl_blast_controls <- all_ps_tbl_blast_controls %>% 
  dplyr::mutate("Possible Metazoa" = NA)

all_ps_tbl_blast_controls <- all_ps_tbl_blast_controls %>% 
  dplyr::mutate("Possible Metazoa" = dplyr::case_when(
     stringr::str_detect(string = `blast ID`, 
                        pattern = "Chordate environmental") ~ FALSE,
     stringr::str_detect(string = `blast ID`, 
                        pattern = "Match_not_reliable") ~ FALSE,
     stringr::str_detect(string = `Superkingdom (NCBI)`, 
                         pattern = "Bacteria|Archaea") ~ FALSE,
     stringr::str_detect(string = `Superkingdom (NCBI)`, 
                         pattern = "Eukaryota") ~ TRUE,
     is.na(`Kingdom (NCBI)`) ~ FALSE,
     stringr::str_detect(string = `Kingdom (NCBI)`, 
                         # pattern = "acter|Archaea|Virus|Fungi|ridiplantae") ~ FALSE,
                                                 pattern = "acter|Archaea|Virus|virae|Fungi") ~ FALSE,                               # só zoooplanc vale
    # stringr::str_detect(string = `Phylum (NCBI)`, 
                        # pattern = "Arthropoda|Cnidaria|Gastrotricha|Rotifera|Cercozoa") ~ TRUE,
                        `Class (NCBI)` %in% c(zplnk_cls, prftn_cls, ftplnk_cls,bentos_cls) ~ TRUE,# só zoooplanc vale
                        `Phylum (NCBI)` %in% c(zplnk_phy, prftn_phy, ftplnk_phy,bentos_phy) ~ TRUE,# só zoooplanc vale
   
    stringr::str_detect(string =`Kingdom (NCBI)`, 
                        # pattern = "Metazoa") ~ TRUE,
                        pattern = "Metazoa|Viridiplantae") ~ TRUE                            # só zoooplanc vale
    )) 



all_ps_tbl_blast_controls$`Possible Metazoa` %>% table()

# all_ps_tbl_blast_controls %>%
#   filter(is.na(`Possible Metazoa`)) %>% 
#   # filter(`Possible Metazoa` == FALSE) %>% 
#   select(`Phylum (NCBI)`) %>% 
#   table()



all_ps_tbl_blast_controls %>% 
  dplyr::filter(`Possible Metazoa` %in% c(FALSE)) %>% 
  # dplyr::filter(`Kingdom (NCBI)` %in% c("kingdom of Eukaryota",
  #                                            "kingdom of superkingdom of NA")) %>% 
  # View()
  # dplyr::pull("Class (NCBI)") %>%
  # dplyr::pull("Kingdom (NCBI)") %>%
  dplyr::pull("Phylum (NCBI)") %>%
  BiocGenerics::unique() %>% 
  sort() %>% 
  paste0(collapse = '",\n"') %>% cat()

all_ps_tbl_blast_controls %>% filter(`Possible Metazoa` %in% c(NA,"NA")) %>% View()
all_ps_tbl_blast_controls %>% filter(`Possible Metazoa` %in% c(FALSE)) %>% View()
all_ps_tbl_blast_controls %>% filter(`Possible Metazoa` %in% c(TRUE)) %>% View()

```

## Reorganize results table

```{r, eval=FALSE}

all_ps_tbl_blast_controls <-
  all_ps_tbl_blast_controls %>%
  dplyr::rename("PCR Control" = "PCR control",
                "Ext. Control"= "Extraction control",
                "Filt. Control" = "Filtration control") %>%
  # dplyr::rename("PCR Control" = "PCR.control",
  #               "Ext. Control"= "Extraction.control",
  #               "Filt. Control" = "Filtration.control") %>%
  dplyr::select(
    c(
      "Researcher",
      "Project",
      "Primer",
                 "Sample",   
                 "Unique_File_name",
                 "Read origin",
                 "Relative abundance to all samples",
                 "Relative abundance on sample",
                 "Sample total abundance",
                 "Abundance",
      starts_with(match = "Metadata"),
            "obs",
            "BLASTn pseudo-score",
                 "Identification",
                 "Identification Max. taxonomy",
                 "Curated ID",
                 "Final ID (BLASTn)",
                                       # "Final ID (BOLD)",         # if BOLD
                 "Expected length",
      "Possible Metazoa",
                 "blast ID",
            "blast ID Origin",
          #blast
          "Genus (NCBI)",
          "Subfamily (NCBI)",
          "Family (NCBI)",
          "Suborder (NCBI)",
          "Order (NCBI)",
          "Subclass (NCBI)",
          "Class (NCBI)",
          "Phylum (NCBI)",
          "Subphylum (NCBI)",
          "Kingdom (NCBI)",
          "Superkingdom (NCBI)",
                 "1_subject header",
                 "1_staxid",
                 "1_subject",
                 "1_indentity",
                 "1_qcovhsp",
                 "1_length",
                 "1_mismatches",
                 "1_gaps",
                 "1_query start",
                 "1_query end",
                 "1_subject start",
                 "1_subject end",
                 "1_e-value",
                 "1_bitscore",

                       "2_subject header",
                 "2_staxid",
                 "2_subject",
                 "2_indentity",
                 "2_qcovhsp",
                 "2_length",
                 "2_mismatches",
                 "2_gaps",
                 "2_query start",
                 "2_query end",
                 "2_subject start",
                 "2_subject end",
                 "2_e-value",
                 "2_bitscore",

                       "3_subject header",
                 "3_staxid",
                 "3_subject",
                 "3_indentity",
                 "3_qcovhsp",
                 "3_length",
                 "3_mismatches",
                 "3_gaps",
                 "3_query start",
                 "3_query end",
                 "3_subject start",
                 "3_subject end",
                 "3_e-value",
                 "3_bitscore",
      ends_with(match = "(BOLD)"),
                 "ASV Size (pb)",
                 "ASV header",
                 "ASV (Sequence)",
      "ASV tip",
                 "OTU",
                 "Ext. Control",
                 "PCR Control",
                 "Filt. Control",
                 "Prop. to PCR control", 
                 "Prop. to Ext control",
                 "Prop. to Filt control",
                 "Contamination status",
                 "Type"
                 ))

all_ps_tbl_blast_controls$`Curated ID` %>%  unique() %>% sort()

```

# Apenas W W F

## adicionar curadoria!

```{r,echo=TRUE, eval=FALSE}



#ler tabelas de curadoria ----
#Peixes
p12S_cur_px <- readxl::read_xlsx(path = "~/prjcts/ecomol/analyses/MCTI/final/data/curadoria/12S/curadoria-Peixes_Ecomol-MCTI_cnxMA-12S-ASVs_X_samples-IDs_para_curadoria-Peixes_GLB.xlsx",
                                 col_names = T,
                                 guess_max = 100000) %>%
  dplyr::select(c("DNA Sequence", "Final ID (BLASTn)",
            "Class (NCBI)", "Order (NCBI)", "Family (NCBI)",
           "CURADORIA: ID curada","CURADORIA: taxon rank",
           "CURADORIA: obs curador","CURADORIA: Iniciais curador"
           # ,"IUCN"
           )) %>% 
  S4Vectors::rename("DNA Sequence" = "ASV (Sequence)" ,
         "CURADORIA: ID curada" = "Curated ID",
         "CURADORIA: taxon rank" = "Cur. taxon rank",
         "CURADORIA: obs curador" = "Comentário Curador",
         "CURADORIA: Iniciais curador" = "Curador") %>% 
  unique()



#Anfibios e repteis
p12S_cur_anfRep <- readxl::read_xlsx(path = "~/prjcts/ecomol/analyses/MCTI/final/data/curadoria/12S/curadoria-Anfibios_e_repteis_Ecomol-MCTI_cnxMA-12S-ASVs_X_samples-IDs_para_curadoria-Anfibios_e_repteis.xlsx",
                                     col_names = T,guess_max = 100000) %>%
  dplyr::select(c("DNA Sequence", "Final ID (BLASTn)",
            "Class (NCBI)", "Order (NCBI)", "Family (NCBI)",
           "CURADORIA: ID curada","CURADORIA: taxon rank",
           "CURADORIA: obs curador","CURADORIA: Iniciais curador",
           "IUCN"
           )) %>% 
  S4Vectors::rename("DNA Sequence" = "ASV (Sequence)" ,
         "CURADORIA: ID curada" = "Curated ID",
         "CURADORIA: taxon rank" = "Cur. taxon rank",
         "CURADORIA: obs curador" = "Comentário Curador",
         "CURADORIA: Iniciais curador" = "Curador") %>% 
  unique()

#aves
p12S_cur_aves <- readxl::read_xlsx(path = "~/prjcts/ecomol/analyses/MCTI/final/data/curadoria/12S/curadoria-Aves-Ecomol-MCTI_cnxMA-12S-ASVs_X_samples-IDs.xlsx",
                                     col_names = T,guess_max = 100000) %>%
  dplyr::select(c("DNA Sequence", "Final ID (BLASTn)",
            "Class (NCBI)", "Order (NCBI)", "Family (NCBI)",
           "CURADORIA: ID curada","CURADORIA: taxon rank",
           "CURADORIA: obs curador","CURADORIA: Iniciais curador",
           "IUCN"
           )) %>% 
  S4Vectors::rename("DNA Sequence" = "ASV (Sequence)" ,
         "CURADORIA: ID curada" = "Curated ID",
         "CURADORIA: taxon rank" = "Cur. taxon rank",
         "CURADORIA: obs curador" = "Comentário Curador",
         "CURADORIA: Iniciais curador" = "Curador") %>% 
  unique()

#mamiferos
p12S_cur_mam <- readxl::read_xlsx(path = "~/prjcts/ecomol/analyses/MCTI/final/data/curadoria/12S/recover_Curadoria-Mamiferos_Ecomol-MCTI_cnxMA-12S-ASVs_X_samples-IDs.xlsx",
                                     col_names = T,guess_max = 100000) %>%
  dplyr::select(c("DNA Sequence", "Final ID (BLASTn)",
            "Class (NCBI)", "Order (NCBI)", "Family (NCBI)",
           "CURADORIA: ID curada","CURADORIA: taxon rank",
           "CURADORIA: obs curador","CURADORIA: Iniciais curador"
           # ,
           # "IUCN"
           )) %>% 
  S4Vectors::rename("DNA Sequence" = "ASV (Sequence)" ,
         "CURADORIA: ID curada" = "Curated ID",
         "CURADORIA: taxon rank" = "Cur. taxon rank",
         "CURADORIA: obs curador" = "Comentário Curador",
         "CURADORIA: Iniciais curador" =  "Curador") %>% 
  unique()


 p12S_cur_px %>% colnames()
p12S_cur_anfRep %>% colnames()
p12S_cur_aves %>% colnames()
p12S_cur_mam %>% colnames()



p12S_cur <- bind_rows(p12S_cur_px, p12S_cur_anfRep, 
                      p12S_cur_aves, p12S_cur_mam
                      )



p12S_cur %>% colnames()

# integrar tabelas de curadoria ----

p12S_cur <- p12S_cur %>%
  select(c("ASV (Sequence)","Curated ID", "Comentário Curador","Curador")) %>%
  dplyr::rename("Curadoria 12S" = "Curated ID") %>% 
  unique()

# 
all_ps_tbl_blast_controls %>% colnames()



unique(all_ps_tbl_blast_controls$`ASV (Sequence)`) %in% unique(p12S_cur$`ASV (Sequence)`) %>% sum()



all_ps_tbl_blast_controls <- all_ps_tbl_blast_controls %>% 
  left_join(y = p12S_cur,
            by = "ASV (Sequence)") %>% 
  mutate("Curated ID" = case_when(`Curadoria 12S` %in% c(NA,"NA","") ~ `Final ID (BLASTn)`,
                                  TRUE ~ `Curadoria 12S`)) %>%
  relocate("ASV (Sequence)","Curated ID", "Curadoria 12S","Final ID (BLASTn)","Comentário Curador","Curador") 
# %>% 
  # select(-c("Curadoria 12S")) %>% 
  # View()

# 
# mif_mib_12v5_TBL_FINAL_abd_cur <- mif_mib_12v5_TBL_FINAL_abd %>%
#   select(-c( "Curated ID")) %>% 
#   left_join(y = p12S_cur,
#             by = "ASV (Sequence)") %>% 
#   mutate("Curated ID" = case_when(`Curated ID` %in% c(NA,"NA","") ~ `Final ID (BLASTn)`,
#                                   TRUE ~ `Curated ID`)) %>% 
#   relocate("ASV (Sequence)","Curated ID", "Final ID (BLASTn)","Comentário Curador","Curador")
# 
# 
# 
# mif_mib_12v5_TBL_FINAL_abd_cur %>% 
#     dplyr::group_by(`Sampling Unit`,Primer) %>% 
#     summarize("SubSAm sum" = sum(`Relative abundance on sample`)/length(unique(Unique_File_name)),
#               "SubSAm clean sum" =       sum(`Clean relative abd. on sample`)/length(unique(Unique_File_name)),
#               "SUnit sum" = sum(`ASV rel. abd. in Sampling  Unit by marker`),
#               "SUnit clean sum" =       sum(`Clean relative abd. on Sampling Unit by marker` )) %>% 
    # View()


```

##curadoria programática

```{r,echo=TRUE, eval=FALSE}
{
all_ps_tbl_blast_controls$`Order (NCBI)`[all_ps_tbl_blast_controls$`Curated ID` %in% c("Chromis elerae")] <- "Perciformes"

all_ps_tbl_blast_controls$`Class (NCBI)`[all_ps_tbl_blast_controls$`Curated ID` %in% c("Paleosuchus trigonatus","Rhinoclemmys punctularia")] <- "Reptilia"

all_ps_tbl_blast_controls$`Class (NCBI)`[all_ps_tbl_blast_controls$`Curated ID` %in% c("Caiman latirostris")] <-  "Reptilia"
all_ps_tbl_blast_controls$`Class (NCBI)`[all_ps_tbl_blast_controls$`Curated ID` %in% c("Phrynops hilarii")] <-  "Reptilia"
all_ps_tbl_blast_controls$`Class (NCBI)`[all_ps_tbl_blast_controls$`Curated ID` %in% c("Cow 25kD")] <-  "Bos taurus"
}
```

## Recalculate clean abundances

```{r,echo=TRUE, eval=FALSE}
# Unir por amostra----

all_ps_tbl_blast_controls %>% 
  select(Unique_File_name,Sample) %>% View()



all_ps_tbl_blast_controls_clean <- all_ps_tbl_blast_controls %>%
    # mutate("ID status" = case_when(is.na(`Final ID (BLASTn)`) & is.na(`Final ID (DADA2)` ) ~ "not IDed",
    #                                !is.na(`Final ID (BLASTn)`) | !is.na(`Final ID (DADA2)`) ~ "IDed")) %>%
  dplyr::mutate("ID status" = dplyr::case_when(
    is.na(`Final ID (BLASTn)`) ~ "not IDed",
    !is.na(`Final ID (BLASTn)`) ~ "IDed")) %>%
    ################# filtrar especies ################################################################################
    # filter(!`Final ID (BLASTn)` %in% c("Homo sapiens","Sus scrofa","Bos taurus"))
  dplyr::mutate("ASV clean abs. abd."  = NA) %>%
  dplyr::mutate("ASV clean abs. abd." = dplyr::case_when(
    `ID status` %in% c("IDed") &
      `Expected length` %in% c("in range") & 
      # `Contamination status` %in% c("True detection") &
      `Possible Metazoa` == TRUE ~ `Abundance`,
    TRUE ~ 0
    )) %>% 
  dplyr::group_by(Sample,
                  Project,
                  Unique_File_name,
                  `Expected length`,
                  `ID status`,
                  `Possible Metazoa`,
                  `Read origin`,
                  # `Contamination status`,
                  Primer
                  ) %>%
  dplyr::mutate("Total clean sample abd." = sum(`ASV clean abs. abd.`)) %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate("Clean relative abd. on sample" =  `ASV clean abs. abd.`/`Total clean sample abd.`) %>% 
  dplyr::relocate("Unique_File_name","Sample","Primer","Expected length",
                  "ID status", "Possible Metazoa","Read origin","Contamination status",
                  "Clean relative abd. on sample","Total clean sample abd.","ASV clean abs. abd.")

#order by abundance
colnames(all_ps_tbl_blast_controls_clean)


all_ps_tbl_blast_controls_clean$`Curated ID` %>% unique()
all_ps_tbl_blast_controls_clean$Project %>% unique()
all_ps_tbl_blast_controls_clean$`Read origin` %>% unique()







for (PRJ in all_projects) {

project_name <- PRJ %>% 
  str_replace_all(pattern = " ",
                  replacement = "_") %>% 
  str_replace_all(pattern = "_-_",
                  replacement = "--")

  
N_samples <-   all_ps_tbl_blast_controls_clean %>%
  filter(Project %in% c(PRJ)) %>% 
  pull(Unique_File_name) %>% unique() %>% length()

N_primers <-   all_ps_tbl_blast_controls_clean %>%
  filter(Project %in% c(PRJ)) %>% 
  pull(Primer) %>% unique() %>% length()

num_IDs <- all_ps_tbl_blast_controls_clean %>%
  filter(!is.na(`Clean relative abd. on sample`)) %>% 
  filter(Project %in% c(PRJ)) %>% 
  pull(`Curated ID`) %>% 
  unique() %>% 
  length()

N_origin <- all_ps_tbl_blast_controls_clean %>%
  filter(Project %in% c(PRJ)) %>% 
  pull(`Read origin`) %>% unique() %>% length()


ASVs_in_controls_plot <- all_ps_tbl_blast_controls_clean %>% 
  dplyr::mutate(`Contamination status` = factor(`Contamination status`)) %>% 
  dplyr::arrange(`Contamination status`) %>% 
  dplyr::arrange(dplyr::desc(`Clean relative abd. on sample`)) %>% 
  dplyr::filter(Project %in% c(PRJ)) %>% 
  dplyr::filter(`Possible Metazoa` %in% c(TRUE)) %>% 
  dplyr::filter(!is.na(`Clean relative abd. on sample`)) %>% 
  tidyr::unite(col = "Sample_Primer",
               Sample,
               Primer,
               sep = " - ",
               remove = F) %>% 
  dplyr::select(c("Clean relative abd. on sample",
         "Sample",
         "Sample_Primer",
         "Unique_File_name",
         "Curated ID",
         "Contamination status",
         "Read origin",
         "Type",
         dplyr::starts_with("Metadata"),
         "Total clean sample abd.",
         "Primer")) %>%  
  ggplot(aes(x = `Clean relative abd. on sample`, 
             # y = Sample, 
             # y = Sample_Primer, 
             # y = Unique_File_name, 
             y = interaction(Unique_File_name, Sample, Primer, sep = " "),
             group = Primer,
             fill = `Curated ID`,
             col= `Contamination status`)) +
  geom_bar(stat = "identity",
          position = "stack",
           width = 0.75,
           linetype="dashed",
           linewidth = 0.25) + 
  geom_text(aes(x = -0.05, 
                # y = Sample,
                # y = Sample_Primer,
                # y = Unique_File_name,
                col = "black",
                label=`Total clean sample abd.`,size =18), 
            check_overlap = TRUE) +
  scale_fill_manual(values = viridis::turbo(n = num_IDs)) +
  scale_color_manual(values = c("Possible contamination" = "red",
                                "True detection" = "white")) +
  ggtitle(label = paste0("EcoMol - ",PRJ),
          subtitle = "ASVs encontradas e sua presença nos controles") +
  theme_gray(base_size = 20)+
  theme(legend.position = "bottom",
        strip.text.y = element_text(angle = 0))+
  guides(fill=guide_legend(ncol=8),
         size="none") +
  xlab(label = "Number of sequences   |   Clean relative abundance on sample") +
  # geom_hline(yintercept = seq(2.5,N_samples*N_primers,N_primers),
  #            linewidth = 0.3,col = "#666666") +
  # facet_grid(cols = vars(`Read origin`,Primer),
  facet_grid(cols = vars(`Read origin`),
             rows = vars(`Metadata 2`,`Metadata 4`),
             scales = "free_y",
             space = "free_y", 
             axes = "all_y",
             axis.labels = "all_y",
             drop = T)


  ggsave(plot = ASVs_in_controls_plot,
         filename = paste0(results_path, "/",PRJ,"--ASVs_abd_by_sample",".pdf"),
         device = "pdf",
         width = (N_origin * 60) + 30,
         height = (N_samples*1) + 15 + (num_IDs/7), 
         limitsize = F,
         units = "cm")

}
```

#### Show figure on html

```{r, eval=TRUE,echo=TRUE, results='asis'}
# Extract the PDF path from the R object

pdf_info <- 
  list.files(path = "/home/noreh/ecomol/analyses/2024/Sq_dez25/results",
             pattern = "--ASVs_abd_by_sample.pdf",
             full.names = T)

  
# Generate the iframe HTML code
cat(paste0('<iframe src="', pdf_info, '" width="800" height="800"></iframe>'))
```

## Save final tables

### Save complete results table

```{r,echo=TRUE, eval=FALSE}

smp_abd_ID <- all_ps_tbl_blast_controls_clean %>% 
  dplyr::filter(`Abundance` > 0) %>% 
  dplyr::mutate("ASV (Sequence)" = case_when(`ASV (Sequence)` == `ASV tip` ~ "-",
                                             TRUE ~ `ASV (Sequence)`)) %>% 
  dplyr::arrange(
    Unique_File_name,
    dplyr::desc(`Clean relative abd. on sample`),
    dplyr::desc(`Relative abundance on sample`),
    dplyr::desc(`Read origin`),
              ) %>%
  dplyr::rename(
    "Sequence (ASV tip)" = "ASV tip",
    "ASV absolute abundance" = "Abundance",
    "BLAST ID" = "blast ID",
    "Final ID (BLASTn)" = "Final ID (BLASTn)",
    "Primer expected length" = "Expected length",
    ) %>% 
  dplyr::relocate(c(
    "Researcher",
    "Project",
    "BLASTn pseudo-score",
    "Identification",
    "Identification Max. taxonomy",
    "Primer",
    "Sample",
    "Primer",
    "Unique_File_name",
    "Read origin",
    "Total clean sample abd.",
    "Clean relative abd. on sample",
    "Relative abundance to all samples",
    "Relative abundance on sample",
    "Sample total abundance",
    "ASV absolute abundance",
    dplyr::starts_with("Metadata"),
    "obs",
    "Primer expected length",
    "ASV Size (pb)",
    "Possible Metazoa",
    "Curated ID",
    "Final ID (BLASTn)",
    "blast ID Origin")) 

dim(smp_abd_ID)

colnames(smp_abd_ID) %>% paste0(collapse = '",\n"') %>% cat()

# smp_abd_ID %>% filter(`Relative abundance on sample` >= 0.05)
# 
# smp_abd_ID %>% 
#   filter(`Read origin` %in% "R2") %>% 
#   pull(`ASV (Sequence)`) %>% 
#   unique()

smp_abd_ID$Sample %>% unique()
smp_abd_ID$`Superkingdom (NCBI)` %>% unique()
smp_abd_ID$`Kingdom (NCBI)` %>% unique()
smp_abd_ID$`Class (NCBI)` %>% unique()



# assess results ----
smp_abd_ID %>% 
  dplyr::group_by(Project,Sample,Unique_File_name, `Read origin`,Primer) %>%
# smp_abd_ID %>% dplyr::group_by(Unique_File_name) %>%
  dplyr::summarize("sum RRA" = sum(`Clean relative abd. on sample`,na.rm = T),
            "Abd abs limpa" = sum(`ASV clean abs. abd.`),
            "Abd abs suja" = sum(`ASV absolute abundance`)) %>% View()



#save complete table with all results ----
# slecionar apenas os resultados pertinentes ----
smp_abd_ID_Final <- smp_abd_ID
# %>% 
#   dplyr::filter(`Read origin` %in% c("concat"))
  #         %>% 
  # # filter(Primer %in% c("COI_R1")) 








#save complete results table, per project ----


for (PRJ in all_projects) {

project_name <- PRJ %>%
  str_replace_all(pattern = " ",
                  replacement = "_") %>% 
  str_replace_all(pattern = "_-_",
                  replacement = "--")

smp_abd_ID_Final %>% 
  dplyr::filter(Project %in% c(PRJ)) %>% 
  dplyr::rowwise() %>% 
  dplyr::mutate("1_subject header" = substr(`1_subject header`,1,200)) %>% 
  dplyr::mutate("2_subject header" = substr(`2_subject header`,1,200)) %>% 
  dplyr::mutate("3_subject header" = substr(`3_subject header`,1,200)) %>% 
  
  
  # dplyr::filter(!is.na(`Curated ID`)) %>%
  # dplyr::filter(!is.na(`Curated ID`)) %>%
  writexl::write_xlsx(
    path = paste0(results_path,"/",PRJ,"--Complete_analysis_results-",Sys.Date(),".xlsx"),
    col_names = TRUE,
    format_headers = TRUE)

smp_abd_ID_Final %>% saveRDS(file = paste0(results_path,"/",PRJ,"--Complete_analysis_results-",Sys.Date(),".rds"))



# 
# problematic_rows <- smp_abd_ID_Final %>%
#   dplyr::filter(Project %in% c(PRJ)) %>%
#   dplyr::filter(!is.na(`Curated ID`)) %>%
#   rowwise() %>%
#   mutate(across(
#     .cols = everything(),
#     .fns = ~ if (!is.na(.x) && is.character(.x) && nchar(.x) > 32767) TRUE else FALSE,
#     .names = "too_long_{.col}"
#   )) %>%
#   ungroup() %>%
#   filter(if_any(starts_with("too_long_"), ~ .x))
# 
# View(problematic_rows)












}

```

### Save ASV Vs. Samples table

```{r,echo=TRUE, eval=FALSE}

# generate ASVs Vs. Samples table from complete table ----

#function to either sum or unique by column type ----
##################################################
sum_uniq <- function(vec=vec){
  
  if (is.character(vec)==TRUE) {
    suniq <- BiocGenerics::unique(vec)
  }
  if (is.numeric(vec)==TRUE) {
    suniq <- sum(vec)
  }
  return(suniq)
}
####################################################

colnames(smp_abd_ID) %>% paste0(collapse = '",\n"') %>% cat()

smp_abd_ID$`ASV (Sequence)` %>% unique()

# generate ASVs Vs. Samples table from complete table ----


for (PRJ in all_projects) {

project_name <- PRJ %>% 
  str_replace_all(pattern = " ",
                  replacement = "_") %>% 
  str_replace_all(pattern = "_-_",
                  replacement = "--")


# ASVtbl_smpls_levels <- smp_abd_ID_Final %>% 
#   dplyr::select(Primer, Sample,Unique_File_name) %>%  
#   BiocGenerics::unique() %>% 
#   dplyr::arrange(Sample, Primer) %>%
#   dplyr::pull(Unique_File_name) 


smp_abd_ID_eco <-
smp_abd_ID_Final %>% 
  dplyr::filter(Project %in% c(PRJ)) %>% 
  # dplyr::filter(Type %in% c("Sample")) %>%
  dplyr::filter(`Clean relative abd. on sample` != 0) %>% 
  dplyr::mutate(Identification = dplyr::if_else(Identification %in% c(NA,"NA"),"NA",Identification)) %>% 
  dplyr::arrange(Primer, Sample) %>% 
  dplyr::mutate(
    "Curated ID" = Identification,
    "Obs. Curadoria" = "") %>% 
  dplyr::select(-c("Relative abundance to all samples", 
            "Sample total abundance",
            "ASV absolute abundance",
            # "Metadata 1","Metadata 2","Metadata 3","Metadata 4","Metadata 5","obs",
            # "Curated ID",
            # "Final ID (BLASTn)",
            # "Final ID (DADA2)",
            "Ext. Control",
            "Filt. Control",
            "PCR Control",
            "Prop. to PCR control",
            "Prop. to Ext control",
            "Prop. to Filt control",
            "Contamination status",
            # "Primer expected length",
            "Type")) %>% 
  tidytable::pivot_wider(
    id_cols = c(
      "Identification",
      "Identification Max. taxonomy",
      "Curated ID",
      "Obs. Curadoria",
      "Final ID (BLASTn)",
      # "Final ID (DADA2)",
      "Primer","Primer","Read origin","Primer expected length",
                "Possible Metazoa", "Project",
      
                "Superkingdom (NCBI)",
                "Kingdom (NCBI)",
                "Phylum (NCBI)",
                "Subphylum (NCBI)",
                "Class (NCBI)",
                "Subclass (NCBI)",
                "Order (NCBI)",
                "Suborder (NCBI)",
                "Family (NCBI)",
                "Subfamily (NCBI)",
                "Genus (NCBI)",
      "BLASTn pseudo-score",
      "1_subject header", "1_staxid", "1_subject", "1_indentity", "1_qcovhsp",
      "1_length", "1_mismatches", "1_gaps", "1_query start", "1_query end", "1_subject start",
      "1_subject end","1_e-value","1_bitscore",
      "2_subject header", "2_staxid", "2_subject", "2_indentity", "2_qcovhsp",
      "2_length", "2_mismatches", "2_gaps", "2_query start", "2_query end", "2_subject start",
      "2_subject end", "2_e-value","2_bitscore",
      "3_subject header", "3_staxid", "3_subject", "3_indentity", "3_qcovhsp",
      "3_length", "3_mismatches", "3_gaps", "3_query start", "3_query end", "3_subject start",
      "3_subject end","3_e-value","3_bitscore",
      "ASV Size (pb)","ASV header","ASV (Sequence)",
      "Sequence (ASV tip)",
      "OTU"),
    # values_from ="Relative abundance on sample",
    values_from ="Clean relative abd. on sample",
    values_fn = sum_uniq,
    names_from = "Unique_File_name",
    # names_from = "Sample name",
    # names_from = "Sample",                           #only!!!!!!!!!
    names_sort = TRUE,
    names_prefix = "SAMPLE ") %>% 
  dplyr::relocate(c("Primer",
      # colnames(metadatas[,-2]),
             "Read origin",
             
              "Superkingdom (NCBI)",
              "Kingdom (NCBI)",
             "Phylum (NCBI)",
             "Subphylum (NCBI)",
             "Class (NCBI)",
             "Subclass (NCBI)",
             "Order (NCBI)",
             "Suborder (NCBI)",
             "Family (NCBI)",
             "Subfamily (NCBI)",
             "Genus (NCBI)",
      "Curated ID",
      "Obs. Curadoria",

      "Identification",
      "Identification Max. taxonomy",
             
             
             "Possible Metazoa", 
             "Final ID (BLASTn)",
             "BLASTn pseudo-score","Primer expected length","ASV Size (pb)",
             dplyr::starts_with("SAMPLE ")
             # paste0("SAMPLE ",ASVtbl_smpls_levels)
             )) %>%  
  dplyr::mutate_if(is.numeric, replace_na, replace = 0)







smp_abd_ID_eco %>% 
         writexl::write_xlsx(
                    path = paste0(results_path,"/",PRJ,"-ASVs_x_amostras-",Sys.Date(),".xlsx"),
                    col_names = TRUE,format_headers = TRUE)


}
dim(smp_abd_ID)
dim(smp_abd_ID_eco)

colnames(smp_abd_ID_eco) %>% paste0(collapse = '",\n"') %>% cat()

```

## Reload results table after curation

```{r,echo=TRUE, eval=FALSE}
curated_smp_abd_ID <- smp_abd_ID_Final  %>% 
  dplyr::mutate(`Class (NCBI)` = case_when(`Class (NCBI)` %in% c("class of Craniata","Lepidosauria","Reptilia") ~ "Crocodylia/\nTestudines/\nLepidosauria",
                                           TRUE ~`Class (NCBI)`)) 
# %>%
#   dplyr::mutate("Phylum (NCBI)" = case_when(`Phylum (NCBI)` %in% c("Mollusca","Nematoda","Nemertea","Platyhelminthes",
#                                                                    NA,"NA","Cnidaria","Ostracoda","Gastrotricha",
#                                                                    "Porifera","Tardigrada") ~ "Outros",
#                                             `Order (NCBI)` %in% c("Crustacea","Hexapoda","Nemertea","Platyhelminthes","Diplura",
#                                                                   NA,"NA","Cnidaria","Ostracoda","Gastrotricha") ~ "Outros",
#                                             `Class (NCBI)` %in% c("Branchiopoda","Chilopoda","Diplopoda",
#                                                                   "Pycnogonida","Ostracoda","Thecostraca",
#                                                                   "class of Crustacea", "Symphyla",
#                                                                   "Pauropoda","Phylactolaemata", "Hexanauplia") ~ "Outros",
#                                             TRUE ~ `Phylum (NCBI)`)) %>% 
#   dplyr::mutate("Class (NCBI)" = case_when(`Phylum (NCBI)` %in% c("Outros") ~ "Outros",
#                                            TRUE ~ `Class (NCBI)`)) 
```

## Heatmap of ASVs and samples experimental

```{r eval=FALSE,echo=TRUE}
scales::show_col(viridis::turbo(n=10))

options(scipen = 500,digits = 4)

library(ggh4x)


smp_abd_ID$Sample %>% unique()
smp_abd_ID$`Metadata 1` %>% unique()
smp_abd_ID$`Metadata 2` %>% unique()
smp_abd_ID$`Metadata 3` %>% unique()
smp_abd_ID$`Metadata 4` %>% unique()
smp_abd_ID$Project %>% unique()




curated_smp_abd_ID$`Class (NCBI)` %>% unique()


#factor metadata
curated_smp_abd_ID %>% dplyr::select(starts_with("Metada")) %>% unique()

curated_smp_abd_ID$Sample %>% unique() 
curated_smp_abd_ID$`Metadata 1` %>% unique() 
curated_smp_abd_ID$`Metadata 2` %>% unique() 
curated_smp_abd_ID$`Metadata 3` %>% unique() 
curated_smp_abd_ID$`Metadata 4` %>% unique() 
curated_smp_abd_ID$`Metadata 5` %>% unique() 
curated_smp_abd_ID$`Metadata 6` %>% unique() 
curated_smp_abd_ID$`Metadata 7` %>% unique() 
curated_smp_abd_ID$Project %>% unique() 


# 

# curated_smp_abd_ID <- curated_smp_abd_ID %>%
#   tidyr::unite(col = "Project" ,
#                Project,obs,
#                remove = F,
#                sep = "-")
# 


for (PRJ in all_projects) {
# for (PRJ in c("eDNA_Amz--mai25-ori", "eDNA_Amz--mai25-rsq")) {

project_name <- PRJ %>% 
  str_replace_all(pattern = " ",
                  replacement = "_") %>% 
  str_replace_all(pattern = "_-_",
                  replacement = "--")
  
N_samples <-   curated_smp_abd_ID %>%
  dplyr::filter(Project %in% c(PRJ)) %>% 
  dplyr::pull(Unique_File_name) %>% 
  BiocGenerics::unique() %>% 
  length()

N_IDs <- curated_smp_abd_ID %>%
  dplyr::filter(Project %in% c(PRJ)) %>% 
  dplyr::pull(`Final ID (BLASTn)`) %>% 
  BiocGenerics::unique() %>% 
  length()


  message(paste0("ploting heatmap for project: ", PRJ))

heat_tbl <- 
curated_smp_abd_ID %>% 
  dplyr::rowwise() %>% dplyr::mutate(Sample = stringr::str_replace_all(Sample, pattern = "_| ", replacement = "\n"),
                                     Type = stringr::str_replace_all(Type, pattern = "_| ", replacement = "\n")) %>% 
  # dplyr::mutate("Metadata 5" = stringr::str_replace_all(`Metadata 5`,pattern = " ",replacement = "\n")) %>% 
  dplyr::filter(Project %in% c(PRJ)) %>%
  dplyr::arrange(Unique_File_name) %>%
  # mutate("Unique_File_name" = factor(Unique_File_name, levels = sample_levels)) %>%
  # dplyr::filter(Type %in% c("Sample")) %>%
  dplyr::filter(`Clean relative abd. on sample` >= 0.005) %>%
  dplyr::filter(`Primer expected length` %in% c("in range")) %>%
  dplyr::filter(`BLASTn pseudo-score` >= 99) %>%
  # dplyr::filter(`Kingdom (NCBI)` %in% c("Metazoa")) %>%
  # dplyr::filter(`Read origin` %in% c("merged")) %>%
  # filter(`Class (NCBI)` %in% c("Actinopteri")) %>%
  dplyr::group_by(`Final ID (BLASTn)`,Unique_File_name,`Read origin`,Primer) %>%
  dplyr::mutate("Relative abundance on sample sum (%)" = round(sum(`Clean relative abd. on sample`)*100,digits = 3),
                "Num ASVs per ID" = length(unique(`ASV (Sequence)`))) %>% 
  dplyr::ungroup() %>% 
  dplyr::group_by(`Final ID (BLASTn)`,`Read origin`) %>%
  dplyr::mutate("Min BLASTn pseudo-score" = substr(as.character(sprintf("%.2f",round(min(`BLASTn pseudo-score`),digits = 2))), 1, 5)) %>%
  dplyr::mutate("Max BLASTn pseudo-score" = substr(as.character(sprintf("%.2f",round(max(`BLASTn pseudo-score`),digits = 2))), 1, 5)) %>%
  dplyr::ungroup() %>% 
  dplyr::select(c("Min BLASTn pseudo-score",
                  "Max BLASTn pseudo-score",
                  "Unique_File_name", 
                  "Sample", 
                  "Read origin",
                  "Primer",
                  "Type",
                  "Final ID (BLASTn)", 
                  "Metadata 1",
                  dplyr::starts_with("Metad"),
                  # "Metadata 5", 
                  "Relative abundance on sample sum (%)",
                  "Final ID (BLASTn)", 
                  "Family (NCBI)", "Order (NCBI)", "Class (NCBI)")) %>% 
  unique()  
  


   IDs_smpls_heat <- heat_tbl %>% 
    ggplot(aes( 
                                                      # x = interaction(Primer,Unique_File_name,sep = " "),
    # x = `Metadata 4`,
    x = Unique_File_name,
    # x = interaction(`Read origin`,Unique_File_name,sep = " "),
             y = interaction(`Final ID (BLASTn)`,`Min BLASTn pseudo-score`,`Max BLASTn pseudo-score`,sep = " || ",lex.order = T),
             fill =`Relative abundance on sample sum (%)`,
             group=`Final ID (BLASTn)`
             # linetype = `Contamination status`,
             # label = `Num ASVs per ID`
             )) +
  geom_tile(size=0.25,
            height = 0.75,
            width = 0.75) +
  geom_text(aes(label = round(`Relative abundance on sample sum (%)`,digits = 1),
                col = `Relative abundance on sample sum (%)`),
            size = 2.5
             ) +
  # stat_contour(aes(z=`Contamination status`),
  #              color = c("#ff000d",NA)) +
  scale_fill_gradientn(name = "Abundância relativa\nna amostra (%)",
                       colours = c("white", "yellow","green","darkgreen","blue"),
                       values = c(0,1),
                       breaks = c(0.001,0.01, 0.05, 0.25,1,2.5,5,10,25,50,100),
                       na.value ="white",
                       trans="log10")+
  scale_colour_gradientn(name = "Abundância relativa\nna amostra (%)",
                       # colours = rev(c("black","white", "yellow","green","darkgreen","blue")),
                       colours = c("black","blue", "yellow","green"),
                       values = c(0,1),
                       breaks = c(0.001,0.01, 0.05, 0.25,1,2.5,5,10,25,50,100),
                       na.value ="white",
                       trans="log10") +
  scale_linetype_manual(values=c("solid",NA)) +
  # guides(color = guide_legend(override.aes = list(fill = "white", 
  #                                                 size = 10))) +
  theme_grey(base_line_size = 0.025,base_size = 8) +
  # theme(axis.text.x = element_text(angle = 0,hjust = 1)) +
  xlab("Pontos de coleta") +
  # ylab("Espécies") +
  ylab("BLASTn Identification / Min BLASTn pseudo-score / Max BLASTn pseudo-score") +
  # ylab("Identificação DADA2 / Identificação BLASTn") +
    # scale_y_discrete(limits=rev) +
  ggtitle(label = paste0("LGC - ",PRJ, " - ",Sys.Date()),
              subtitle = "Abundância relativa de cada identificação obtida por BLASTn\nIDs com BLASTn pseudo-score >= 95% e RRA >= 0.5%") +      
    # facet_grid(rows = vars(`Class (NCBI)`,`Order (NCBI)`,`Family (NCBI)`),
    facet_grid(rows = vars(`Class (NCBI)`,`Order (NCBI)`,`Family (NCBI)`),
               # cols = vars(Unique_File_name),
               # cols = vars(Type,`Metadata 1`,`Metadata 5`),
               cols = vars(Type,Sample),
                                # labeller = labeller(`Metadata 3` = supp.labs),
               scale = 'free',space = 'free',
    labeller = labeller("Unique_File_name" = label_wrap_gen(width=8,multi_line = T))) +
  theme(legend.position = "bottom",
        strip.text.y = element_text(size = 10,angle = 0),
        strip.text.x = element_text(size = 10),
        plot.title = element_text(size = 12),
        plot.subtitle = element_text(size = 10),
        # axis.text.y = element_text(size = 8),
        axis.title.x = element_text(size = 14), 
        # axis.title.y = element_text(size = 14), 
        axis.text.x = element_text(size = 8,angle = 45, hjust = 1),
        legend.text = element_text(size = 8),
        legend.title = element_text(size = 10),
        legend.key.width = unit(4, 'cm'),
        legend.key.height = unit(0.5, 'cm'),
        panel.border = element_rect(colour = "#000000", fill = NA),
        panel.grid = element_line(colour = "#ffffff",linewidth = 0.01),
        
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        )  +
  # geom_vline(xintercept = c(seq(0.5, 220.5, 1)), linewidth = 0.1) +
  guides(colour="none") 

# IDs_smpls_heat
# pg <- ggplotGrob(IDs_smpls_heat)
# 
# 
# 
# for(i in which(grepl("strip-r", pg$layout$name))){
#   pg$grobs[[i]]$layout$clip <- "off"
# }
# grid::grid.draw(pg)


IDs_smpls_heat_build <- ggplot_build(IDs_smpls_heat)

y_by_panel <- lapply(IDs_smpls_heat_build$layout$panel_params, function(pp) pp$y$breaks)
y_by_panel
y_all <- unique(unlist(y_by_panel))
y_all



dev.off()



IDs_smpls_heat_primers <- heat_tbl %>% 
  ggplot(aes( 
    x = Primer,
    y = interaction(`Final ID (BLASTn)`,`Min BLASTn pseudo-score`,`Max BLASTn pseudo-score`,sep = " || ",lex.order = T),
             fill = Primer,
             group=`Final ID (BLASTn)`
             )) +
  geom_tile(size=0.25,
            height = 0.75,
            width = 0.75)+      
    # facet_grid(rows = vars(`Class (NCBI)`,`Order (NCBI)`,`Family (NCBI)`),
    facet_grid(rows = vars(`Class (NCBI)`,`Order (NCBI)`,`Family (NCBI)`),
               # cols = vars(Primer),
               # cols = vars(Unique_File_name),
               # cols = vars(Type,`Metadata 1`,`Metadata 5`),
               # cols = vars(Type,Sample),
                                # labeller = labeller(`Metadata 3` = supp.labs),
               scale = 'free',space = 'free',
    labeller = labeller("Unique_File_name" = label_wrap_gen(width=8,multi_line = T))) +
  theme(
    # remove textos dos strips (facetas)
    strip.text.x = element_blank(),
    strip.text.y = element_blank(),
    # remove fundo dos strips
    strip.background = element_blank(),
    # remove espaço reservado para os strips
    strip.placement = "outside",
    # remove títulos dos eixos
    # axis.title.x = element_blank(),
    # axis.title.y = element_blank(),
    # remove labels dos eixos (nomes)
    # axis.text.x = element_blank(),
    # axis.text.y = element_blank(),

    # remove ticks
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),

    # limpa grid
    panel.grid = element_blank()
  ) +
  ylab("BLASTn Identification / Min BLASTn pseudo-score / Max BLASTn pseudo-score") +
    guides(fill = "none") 



library(patchwork)


plot_final <-
  wrap_elements(full = ggplotGrob(IDs_smpls_heat_primers)) |
  wrap_elements(full = ggplotGrob(IDs_smpls_heat)) +
  plot_layout(widths = c(1, 12))


ggsave(file = paste0(results_path,"/",PRJ,
                     "--heatmap-Sps_BLASTn_Bps_90--", Sys.Date(),".pdf"),
                     # "--heatmap-Sps_BLASTn_Bps_90--Actinopterii", Sys.Date(),".pdf"),
     plot = plot_final,
     device = "pdf",
     width = ifelse(N_samples <= 10, 25, (N_samples)+25),
     # width = ((N_samples) + 15),
     # height = ifelse(N_IDs <= 20, 10, N_IDs/5+5),
     height = ((N_IDs/10)+5),
     units = "cm",
     limitsize = FALSE,
     dpi = 300)

}


smp_abd_ID_Final %>% 
  filter(`Kingdom (NCBI)` %in% c("Metazoa")) %>% 
  pull(`Phylum (NCBI)`) %>% table() %>% plot()


smp_abd_ID_eco %>% colnames()

```

#### Show figure on html

## Heatmap of ASVs and samples

```{r eval=FALSE,echo=TRUE}
scales::show_col(viridis::turbo(n=10))

options(scipen = 500,digits = 4)

library(ggh4x)


smp_abd_ID$Sample %>% unique()
smp_abd_ID$`Metadata 1` %>% unique()
smp_abd_ID$`Metadata 2` %>% unique()
smp_abd_ID$`Metadata 3` %>% unique()
smp_abd_ID$`Metadata 4` %>% unique()
smp_abd_ID$Project %>% unique()


curated_smp_abd_ID$Metadata 3 %>% unique()


curated_smp_abd_ID$`Class (NCBI)` %>% unique()


#factor metadata
curated_smp_abd_ID %>% dplyr::select(starts_with("Metada")) %>% unique()

curated_smp_abd_ID$Sample %>% unique() 
curated_smp_abd_ID$`Metadata 1` %>% unique() 
curated_smp_abd_ID$`Metadata 2` %>% unique() 
curated_smp_abd_ID$`Metadata 3` %>% unique() 
curated_smp_abd_ID$`Metadata 4` %>% unique() 
curated_smp_abd_ID$`Metadata 5` %>% unique() 
curated_smp_abd_ID$`Metadata 6` %>% unique() 
curated_smp_abd_ID$`Metadata 7` %>% unique() 
curated_smp_abd_ID$`Metadata 8` %>% unique() 
curated_smp_abd_ID$`Metadata 9` %>% unique() 
curated_smp_abd_ID$`Metadata 10` %>% unique() 
curated_smp_abd_ID$Project %>% unique() 
curated_smp_abd_ID$Primer %>% unique() 


# 

# curated_smp_abd_ID <- curated_smp_abd_ID %>%
#   tidyr::unite(col = "Project" ,
#                Project,obs,
#                remove = F,
#                sep = "-")
# 


for (PRJ in all_projects) {
# for (PRJ in c("eDNA_Amz--mai25-ori", "eDNA_Amz--mai25-rsq")) {

project_name <- PRJ %>% 
  str_replace_all(pattern = " ",
                  replacement = "_") %>% 
  str_replace_all(pattern = "_-_",
                  replacement = "--")
  
N_samples <-   curated_smp_abd_ID %>%
  dplyr::filter(Project %in% c(PRJ)) %>% 
  dplyr::pull(Unique_File_name) %>% 
  BiocGenerics::unique() %>% 
  length()

N_IDs <- curated_smp_abd_ID %>%
  dplyr::filter(Project %in% c(PRJ)) %>% 
  dplyr::pull(`Final ID (BLASTn)`) %>% 
  BiocGenerics::unique() %>% 
  length()


  message(paste0("ploting project: ", PRJ))

IDs_smpls_heat <- 
curated_smp_abd_ID %>% 
  dplyr::rowwise() %>% dplyr::mutate(Sample = stringr::str_replace_all(Sample, pattern = "_| ", replacement = "\n")) %>% 
  # dplyr::mutate("Metadata 5" = stringr::str_replace_all(`Metadata 5`,pattern = " ",replacement = "\n")) %>% 
  dplyr::filter(Project %in% c(PRJ)) %>%
  dplyr::arrange(Unique_File_name) %>%
  # mutate("Unique_File_name" = factor(Unique_File_name, levels = sample_levels)) %>%
                                dplyr::filter(Primer %in% c("p12SV5", "VCOIu")) %>%
                                dplyr::filter(Type %in% c("Sample")) %>%
                                dplyr::filter(`Phylum (NCBI)` %in% c("Chordata", "Arthropoda")) %>%
  # dplyr::filter(Type %in% c("Sample")) %>%
  dplyr::filter(`Clean relative abd. on sample` >= 0.005) %>%
  dplyr::filter(`Primer expected length` %in% c("in range")) %>%
  dplyr::filter(`BLASTn pseudo-score` >= 95) %>%
  # dplyr::filter(`Kingdom (NCBI)` %in% c("Metazoa")) %>%
  # dplyr::filter(`Read origin` %in% c("merged")) %>%
  # filter(`Class (NCBI)` %in% c("Actinopteri")) %>%
  dplyr::group_by(`Final ID (BLASTn)`,Unique_File_name,`Read origin`,Primer) %>%
  dplyr::mutate("Relative abundance on sample sum (%)" = round(sum(`Clean relative abd. on sample`)*100,digits = 3),
                "Num ASVs per ID" = length(unique(`ASV (Sequence)`))) %>% 
  dplyr::ungroup() %>% 
  dplyr::group_by(`Final ID (BLASTn)`,`Read origin`) %>%
  dplyr::mutate("Min BLASTn pseudo-score" = substr(as.character(sprintf("%.2f",round(min(`BLASTn pseudo-score`),digits = 2))), 1, 5)) %>%
  dplyr::mutate("Max BLASTn pseudo-score" = substr(as.character(sprintf("%.2f",round(max(`BLASTn pseudo-score`),digits = 2))), 1, 5)) %>%
  dplyr::ungroup() %>% 
  dplyr::select(c("Min BLASTn pseudo-score",
                  "Max BLASTn pseudo-score",
                  "Unique_File_name", 
                  "Sample", 
                  "Read origin",
                  "Primer",
                  "Type",
                  "Final ID (BLASTn)", 
                  "Metadata 1",
                  dplyr::starts_with("Metad"),
                  # "Metadata 5", 
                  "Relative abundance on sample sum (%)",
                  "Final ID (BLASTn)", 
                  "Family (NCBI)", "Order (NCBI)", "Class (NCBI)", "Phylum (NCBI)")) %>% 
  unique() %>% 
  # filter(`Relative abundance on sample sum (%)` > 0.05) %>%
  ggplot(aes( 
                                                      # x = interaction(Primer,Unique_File_name,sep = " "),
    x = Primer,
    # x = Unique_File_name,
    # x = interaction(`Read origin`,Unique_File_name,sep = " "),
             y = interaction(`Final ID (BLASTn)`,`Min BLASTn pseudo-score`,`Max BLASTn pseudo-score`,sep = " || ",lex.order = T),
             fill =`Relative abundance on sample sum (%)`,
             group=`Final ID (BLASTn)`
             # linetype = `Contamination status`,
             # label = `Num ASVs per ID`
             )) +
  geom_tile(size=0.25,
            height = 0.75,
            width = 0.75) +
  geom_text(aes(label = round(`Relative abundance on sample sum (%)`,digits = 1),
                col = `Relative abundance on sample sum (%)`),
            size = 2.5
             ) +
  # stat_contour(aes(z=`Contamination status`),
  #              color = c("#ff000d",NA)) +
  scale_fill_gradientn(name = "Abundância relativa\nna amostra (%)",
                       colours = c("white", "yellow","green","darkgreen","blue"),
                       values = c(0,1),
                       breaks = c(0.001,0.01, 0.05, 0.25,1,2.5,5,10,25,50,100),
                       na.value ="white",
                       trans="log10")+
  scale_colour_gradientn(name = "Abundância relativa\nna amostra (%)",
                       # colours = rev(c("black","white", "yellow","green","darkgreen","blue")),
                       colours = c("black","blue", "yellow","green"),
                       values = c(0,1),
                       breaks = c(0.001,0.01, 0.05, 0.25,1,2.5,5,10,25,50,100),
                       na.value ="white",
                       trans="log10") +
  scale_linetype_manual(values=c("solid",NA)) +
  # guides(color = guide_legend(override.aes = list(fill = "white", 
  #                                                 size = 10))) +
  theme_grey(base_line_size = 0.025,base_size = 8) +
  # theme(axis.text.x = element_text(angle = 0,hjust = 1)) +
  xlab("Pontos de coleta") +
  # ylab("Espécies") +
  ylab("BLASTn Identification / Min BLASTn pseudo-score / Max BLASTn pseudo-score") +
  # ylab("Identificação DADA2 / Identificação BLASTn") +
    # scale_y_discrete(limits=rev) +
  ggtitle(label = paste0("LGC - ",PRJ, " - ",Sys.Date()),
              subtitle = "Abundância relativa de cada identificação obtida por BLASTn\nIDs com BLASTn pseudo-score >= 95% e RRA >= 0.5%") +      
    # facet_grid(rows = vars(`Class (NCBI)`,`Order (NCBI)`,`Family (NCBI)`),
    facet_grid(rows = vars(`Phylum (NCBI)`,`Class (NCBI)`,`Order (NCBI)`,`Family (NCBI)`),
               # cols = vars(Unique_File_name),
               # cols = vars(Type,`Metadata 1`,`Metadata 5`),
               cols = vars(`Metadata 1`,`Metadata 5`),
                                # labeller = labeller(`Metadata 3` = supp.labs),
               scale = 'free',space = 'free',
    labeller = labeller("Unique_File_name" = label_wrap_gen(width=8,multi_line = T))) +
  theme(legend.position = "bottom",
        strip.text.y = element_text(size = 10,angle = 0),
        strip.text.x = element_text(size = 10),
        plot.title = element_text(size = 12),
        plot.subtitle = element_text(size = 10),
        axis.text.y = element_text(size = 8),
        axis.title.x = element_text(size = 14), 
        axis.title.y = element_text(size = 14), 
        axis.text.x = element_text(size = 8,angle = 45, hjust = 1),
        legend.text = element_text(size = 8),
        legend.title = element_text(size = 10),
        legend.key.width = unit(4, 'cm'),
        legend.key.height = unit(0.5, 'cm'),
        panel.border = element_rect(colour = "#000000", fill = NA),
        panel.grid = element_line(colour = "#ffffff",linewidth = 0.01)
        )  +
  # geom_vline(xintercept = c(seq(0.5, 220.5, 1)), linewidth = 0.1) +
  guides(colour="none") 

# IDs_smpls_heat
# pg <- ggplotGrob(IDs_smpls_heat)
# 
# 
# 
# for(i in which(grepl("strip-r", pg$layout$name))){
#   pg$grobs[[i]]$layout$clip <- "off"
# }
# grid::grid.draw(pg)


ggsave(file = paste0(results_path,"/",PRJ,
                     "--heatmap-Sps_BLASTn_Bps_95--", Sys.Date(),".pdf"),
                     # "--heatmap-Sps_BLASTn_Bps_90--Actinopterii", Sys.Date(),".pdf"),
     plot = IDs_smpls_heat,
     device = "pdf",
     # width = ifelse(N_samples <= 10, 15, (N_samples/3)+15),
     width = ((N_samples) + 15),
     # height = ifelse(N_IDs <= 20, 10, N_IDs/5+5),
     height = ((N_IDs/10)+65),
     units = "cm",
     limitsize = FALSE,
     dpi = 300)

}


smp_abd_ID_Final %>% 
  filter(`Kingdom (NCBI)` %in% c("Metazoa")) %>% 
  pull(`Phylum (NCBI)`) %>% table() %>% plot()


smp_abd_ID_eco %>% colnames()

```

```{r, eval=TRUE,echo=TRUE, results='asis'}
# Extract the PDF path from the R object

pdf_info <- 
  list.files(path = "/home/noreh/ecomol/analyses/2024/Sq_dez25/results",
             pattern = "--heatmap-Sps_BLASTn_Bps",
             full.names = T)
  
# Generate the iframe HTML code
cat(paste0('<iframe src="', pdf_info, '" width="800" height="800"></iframe>'))
```

## Preparar tabela ecológica

Here we are going to select only the identifications that are pertinent to ecological analyses.

```{r, eval=FALSE}

# Transformar planilha final de resultados numa planilha de IDs X amostras ----
# converter a planilha final de resultados modificando filtros ----
curated_smp_abd_ID$`Metadata 2` %>% unique()
curated_smp_abd_ID$`Metadata 3` %>% unique()


FINAL_TBL <- curated_smp_abd_ID %>% 
  dplyr::mutate("Sample name" = Unique_File_name) %>% 
                                                                              # dplyr::filter(Type %in% c("Sample")) %>% 
  ############# definir agrupador ################################################
  # tidyr::unite(col = "Metadata 5", `Metadata 2`, `Metadata 3`,sep = "-",remove = F) %>%
  # dplyr::mutate("agrupador" = `Metadata 2`) %>%
  # dplyr::mutate("agrupador" = `Metadata 5`) %>%
  # dplyr::mutate("agrupador" = `Metadata 3`) %>%
  dplyr::mutate("agrupador" = "") %>%
  ###________________________ filtros diversos de entrada_______________________
  dplyr::filter(`Clean relative abd. on sample` != 0) %>% 
  # dplyr::filter(`Clean relative abd. on sample` >= 0.0001) %>%
  dplyr::filter(!str_detect(string = `Curated ID`,
                     pattern = "Match_not_reliable")) %>%
  # filter(`1_indentity` >= 90) %>%
  # filter(`BLASTn pseudo-score` >= 90) %>% 
  # filter(`Contamination status` %in% c("True detection")) %>% 
  dplyr::filter(`Superkingdom (NCBI)` %in% c("Eukaryota","superkingdom of Metazoa")) %>% 
  dplyr::filter(`Kingdom (NCBI)` %in% c("Metazoa")) %>% 
  # dplyr::filter(`Class (NCBI)` %in% c(
  # # # # "Aves",
  # # # # "Mammalia",
  # # # # "Amphibia",
  # # # # "Crocodylia/\nTestudines/\nLepidosauria",
  # "Actinopteri"
  # )) %>%
  # dplyr::filter(Type %in% c("Sample")) %>% 
  # dplyr::filter(`Read origin` %in% c("merged")) %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate("Clean relative abd. on sample" = `ASV absolute abundance`/`Total clean sample abd.`) 


```

## salvar tabelas ecológicas por projeto

```{r,echo=TRUE, eval=FALSE}

######## Function to transform values into 1 and zeros
jaccarize <- function(x) {
  # Using ifelse to check each element of the vector x
  ifelse(x == 0, 0, 1)
}
###################


for (PRJ in all_projects) {

project_name <- PRJ %>% 
  str_replace_all(pattern = " ",
                  replacement = "_") %>% 
  str_replace_all(pattern = "_-_",
                  replacement = "--")


  
    FINAL_tbl_IDs <- FINAL_TBL %>%
      dplyr::filter(Project %in% c(PRJ)) %>% 
      # dplyr::filter(`Class (NCBI)` %in% c("Actinopteri")) %>% 
  ###_______________remover amostras que atrapalham a visualização_______________###
      dplyr::select(c("Project","Primer", 
                    "Sample",
                    "Sample name", "agrupador",
                    "Clean relative abd. on sample",
                    "Metadata 1","Metadata 2",
                    "Metadata 3", "Metadata 4",
                    "Metadata 5", "Metadata 6",
                    "Metadata 7","Metadata 8",
                    "Metadata 9", "Metadata 10",
                    "Metadata 11" ,"Metadata 12",
                    "Curated ID")) %>% 
      tidyr::pivot_wider(                                #pivotando as IDs de linhas pra colunas
        id_cols = c(
                "Sample",
                "Sample name",
                # "Unique_File_name",
                "Project",
                "Primer",
                "Metadata 1", 
                "Metadata 2", 
                "Metadata 3", 
                "Metadata 4", 
                "Metadata 5", 
                "Metadata 6",
                "Metadata 7",
                "Metadata 8",
                "Metadata 9",
                "Metadata 10",
                "Metadata 11",
                "Metadata 12"
                ),
    values_from ="Clean relative abd. on sample",            #utilizando abundancias Identificadas
    # values_from ="ASV rel. abd. in Sampling Unit by marker",
    values_fn = sum_uniq,
    # names_from = Identification,
    names_from = `Curated ID`,
    names_sort = TRUE,
    names_prefix = "ID_"
    ) %>% 
  dplyr::relocate(c("Sample",
                "Sample name",
                # "Unique_File_name",
                "Project",
                "Primer",
             dplyr::starts_with("Metadata"),
             dplyr::starts_with("ID_"),
             )) %>%  
    dplyr::mutate(dplyr::across(starts_with("ID_") , \(x) replace_na(x, replace = 0))) 



    
    
    
FINAL_tbl_IDs %>% 
  writexl::write_xlsx(path = paste0(results_path,"/",PRJ,
                                    "--tabela_comunidade--Braycurtis.xlsx"),
                      col_names = T)

FINAL_tbl_IDs %>%
  mutate(across(starts_with('ID_'), jaccarize)) %>% 
   writexl::write_xlsx(path = paste0(results_path,"/",PRJ,
                                    "--tabela_comunidade--Jaccard.xlsx"),
                      col_names = T)


}

```

# Sumário de amostras

```{r, eval=FALSE}


curated_smp_abd_ID %>% colnames()
curated_smp_abd_ID$`Class (NCBI)` %>% unique()
curated_smp_abd_ID$`Phylum (NCBI)` %>% unique()
curated_smp_abd_ID$`Kingdom (NCBI)` %>% unique()
curated_smp_abd_ID$`Possible Metazoa` %>% unique()

#Gráfico de ASVs, OTUs e IDs ----

ASVsOUTsIDs_tbl <- curated_smp_abd_ID %>%
  dplyr::filter(`Possible Metazoa` %in% c(TRUE)) %>% 
                                            # dplyr::filter(`Class (NCBI)` %in% c(
                                            #   "Mammalia",
                                            #   "Actinopteri",
                                            #   "Aves",
                                            #   "Crocodylia/\nTestudines/\nLepidosauria",
                                            #   "Amphibia"
                                            #   )) %>% 
  dplyr::group_by(Project,Sample,Unique_File_name,Researcher, Type,`Curated ID`) %>% 
  dplyr::summarise("Total ASVs" = length(BiocGenerics::unique(`ASV header`)),
              "Total OTUs" = length(BiocGenerics::unique(OTU)),
              "Total IDs" = length(BiocGenerics::unique(`Curated ID`))) %>% 
  dplyr::ungroup() %>% 
    tidyr::pivot_longer(cols = c("Total ASVs","Total OTUs","Total IDs"),
                        names_to = "Stage",
                        values_to = "Read counts") %>% 
    dplyr::mutate(Type = factor(Stage,
                                levels = c("Total ASVs","Total OTUs","Total IDs")))
  

bind_rows(track_tbl,ASVsOUTsIDs_tbl)



```

# Entidades ASVs, OTUs e IDs

```{r eval=FALSE, echo=TRUE}

library(ggrepel)
library(viridis)

#Gráfico de ASVs, OTUs e IDs  por grupo ----

entities_plot <- curated_smp_abd_ID %>%
  dplyr::filter(`BLASTn pseudo-score` >=95) %>% 
  # mutate("Primer" =  "All") %>% 
  # mutate("Metadata 4" =  "Both") %>% 
  # bind_rows(curated_smp_abd_ID) %>% 
  dplyr::filter(`Possible Metazoa` %in% c(TRUE)) %>% 
  dplyr::filter(Type %in% c("Sample")) %>% 
                          # dplyr::filter(`Class (NCBI)` %in% c(
                          #   "Mammalia",
                          #   "Actinopteri",
                          #   "Aves",
                          #   "Crocodylia/\nTestudines/\nLepidosauria",
                          #   "Amphibia"
                          # )) %>%
  # dplyr::group_by(Primer,Sample,`Class (NCBI)`) %>%
  # dplyr::group_by(`Metadata 4`, `Metadata 2`,`Class (NCBI)`) %>%
  dplyr::group_by(Sample, `Class (NCBI)`) %>%
  summarise("Total ASVs" = length(BiocGenerics::unique(`ASV header`)),
            "Total OTUs" = length(BiocGenerics::unique(OTU)),
            "Total IDs" = length(BiocGenerics::unique(`Curated ID`))) %>% 
  tidyr::pivot_longer(cols = c("Total ASVs","Total OTUs","Total IDs"),
                      names_to = "Tipo",
                      values_to = "Counts") %>% 
  dplyr::mutate(Tipo = factor(Tipo,
                                 levels = c("Total ASVs","Total OTUs","Total IDs"))) %>% 
  
  dplyr::arrange(Tipo,desc(Counts)) %>% 
  ggplot2::ggplot(aes(x = Counts,
                      label = Counts,
                      # y = Primer,
                      y = Tipo,
                      # y = `Metadata 4`,
                      group = Sample,
                      # group = Tipo,
                      fill = Sample)) +
    geom_col(position = position_dodge2(width = 0.9, preserve = "single"),
             width = 0.9) +
  geom_text(aes(x = Counts * 0.9,
                      y = Tipo,
                      group = Sample),
                 position = position_dodge2(width = 0.9, preserve = "single"),
            col = "#dddddd",
            size = 3
    # direction = "x",      # só ajusta no eixo Y
    # nudge_x = 0.2,        # “empurra” um pouco para cima/baixo
    # box.padding = 0.2,
    # point.padding = 0.1,
    # min.segment.length = 0,
    # max.overlaps = Inf,   # evita suprimir labels
    # seed = 1
    ) +
  scale_x_log10(breaks = c(0,1,2,3,4,5,10,25,50,75,100,150,200,250,300,350,400,500,600,700,800),
                expand = c(0,0.02)
                  ) +
  # facet_grid(rows = vars(`Class (NCBI)`)) +
  facet_grid(rows = vars(`Class (NCBI)`),
             axes = "all_x",
             axis.labels = "all_x",
             space = "free",
             switch = "x") +
  # scale_fill_manual(values = c("#1d2173FF","#307519FF","#ff6a00FF")) +
  scale_fill_manual(values = viridis::viridis(n=10)) +
  theme(strip.text.y = element_text(size = 10, angle = 0),
        axis.text.y = element_text(lineheight = 0.7)) +
  labs(fill = "Lib type",
       title = "ASVs, OTUs e IDs únicas por grupo taxonômico e técnica",
       subtitle = bquote("Considerando apenas IDs com "*italic("BLASTn pseudo-score"*" >= 95%")))
# +
#   geom_hline(yintercept = c(0.5,3.5,6.5,9.5),
#              col = "#777777")


entities_plot
# ggsave(file = paste0(results_path,"/",PRJ,"--BARPLOT-generos.pdf",collapse = ""),
ggsave(plot = entities_plot,
       # file = paste0("/home/noreh/prjcts","/",analysis_rad,"/Entidades_por_marcador_e_classe.pdf",collapse = ""),
       file = paste0(results_path,"/",analysis_rad,"--Entidades_por_marcador_e_classe-all.pdf",collapse = ""),
     device = "pdf",
     width = 14,
     height = 8,
     dpi = 600)


```

# Sps exclusivas de cada técnica

```{r eval=FALSE, echo=TRUE}

sps_per_lib_type <- curated_smp_abd_ID %>%
  dplyr::filter(`BLASTn pseudo-score` >=95) %>% 
  dplyr::filter(`Possible Metazoa` %in% c(TRUE)) %>%
  dplyr::filter(`Class (NCBI)` %in% c(
    "Mammalia",
    "Actinopteri",
    "Aves",
    "Crocodylia/\nTestudines/\nLepidosauria",
    "Amphibia"
  )) %>% 
    dplyr::group_by(Sample, `Metadata 4`,`Class (NCBI)`, `Curated ID`) %>% 
  dplyr::summarise()



dualPCR_sps <- sps_per_lib_type %>% 
  dplyr::filter(`Metadata 4` %in% c("Dual PCR")) %>% 
  dplyr::pull(`Curated ID`)
PCRfree_sps <- sps_per_lib_type %>% 
  dplyr::filter(`Metadata 4` %in% c("PCR Free")) %>% 
  dplyr::pull(`Curated ID`)


species_list <- list(
  "Dual PCR" = dualPCR_sps,
  "PCR Free" = PCRfree_sps
)


# Generate Venn Diagram ----
venn_plot <- ggvenn::ggvenn(species_list,
                    show_elements = TRUE,
                    # show_elements = FALSE,
                    label_sep = "\n",
                    text_size = 2,
                    auto_scale = T,
                    fill_color = c("#448EFEff", "#FEAA33ff")) +
  # labs(title = bquote("Proporção de "*italic("taxa")*" de "*.(TRGT)* " detectados por cada metodologia"))
  labs(title = bquote("IDs detectados por cada metodologia considerando "*italic("BLASTn pseudo-score"*" >= 95%")))



venn_plot %>%  
  ggsave(file = paste0(results_path, "/",analysis_rad,"--venn_plot", ".pdf"),
         device = "pdf",
         width = 20,
         height = 20,
         limitsize = FALSE,
         units = "cm",
         dpi = 300)





# tabela de especies por amostra e tecnica ----

sps_per_lib_type %>% 
  mutate("presente" = TRUE) %>%
  tidyr::pivot_wider(names_from = "Metadata 4",
                     values_from = "presente",
                     values_fill = FALSE
                     ) %>% 
  writexl::write_xlsx(path = paste0(results_path,"/",analysis_rad,
                                    "--IDs_detectadas_por_tecnica.xlsx"),
                      col_names = T)

# tabela de especies por amostra e tecnica ----
curated_smp_abd_ID %>%
  dplyr::filter(`BLASTn pseudo-score` >=95) %>% 
  dplyr::filter(`Possible Metazoa` %in% c(TRUE)) %>%
  dplyr::filter(`Class (NCBI)` %in% c(
    "Mammalia",
    "Actinopteri",
    "Aves",
    "Crocodylia/\nTestudines/\nLepidosauria",
    "Amphibia"
  )) %>% 
    dplyr::group_by(`Metadata 4`,`Class (NCBI)`, `Curated ID`) %>% 
  dplyr::summarise() %>% 
  # dplyr::summarise("Detectado em N amostras" = length(unique(Sample)),
  #                  "Detectado nas amostras" = paste0(unique(Sample),collapse = ";"),
  #                                                     ) %>% 
  # dplyr::group_by(`Metadata 4`,`Class (NCBI)`, `Curated ID`) %>% 
  dplyr::mutate("presente" = TRUE) %>%
  tidyr::pivot_wider(names_from = "Metadata 4",
                     values_from = "presente",
                     values_fill = FALSE
                     )  %>% 
  writexl::write_xlsx(path = paste0(results_path,"/",analysis_rad,
                                    "--IDs_detectadas_por_tecnica_geral.xlsx"),
                      col_names = T)

```

### Ploting richness

```{r, eval=FALSE}
#28- ASVs plots by sample and species ----


scales::show_col(scales::hue_pal(c = 200, h= c(0,360))(50))
    scales::show_col(viridis::viridis(n = 9))
    scales::show_col(viridis::turbo(n =15))
    
    viridis::turbo(n =15)[c(2,8,11)]


scales::show_col(c())
scales::show_col(c("#440154", "#440184","#FF4A00","#ba0202","#0009DD","#007004", "#24768e", "#26a784", "#79d051", "#ff2b77"))
# colors6 <- scales::show_col(c("#440154", "#0009DD","#007004","#ba0202","#FF4A00", "#03435e"))
colors6 <-c("#440154", "#0009DD","#007004","#ba0202","#FF4A00", "#03435e")

colors4 <-c("#007004","#fbff00","#FF4A00","#ba0202")
colors5 <- c("#007004","#fbff00","#FF4A00","#ba0202")

scales::show_col(colors6)

scales::show_col(colors4)




# alfa div per sample ----


for (PRJ in all_projects) {

project_name <- PRJ %>% 
  str_replace_all(pattern = " ",
                  replacement = "_") %>% 
  str_replace_all(pattern = "_-_",
                  replacement = "--")
  
# N_samples <-   FINAL_TBL %>%
#   dplyr::filter(Project %in% c(PRJ)) %>% 
#   dplyr::pull(Unique_File_name) %>% 
#   BiocGenerics::unique() %>% 
#   length()

PRJ_class <- FINAL_TBL %>%
  dplyr::filter(Project %in% c(PRJ)) %>%
  dplyr::pull(`Class (NCBI)`) %>%
  BiocGenerics::unique() %>% 
  paste0(collapse = " ")




riqueza_Sample_BLASTn_bar <- FINAL_TBL %>%
  dplyr::filter(Project %in% c(PRJ)) %>%
  # dplyr::group_by(Sample,Primer) %>% 
  # mutate(`Read origin`=factor(`Read origin`,levels = c("merged", "R1", "R2","concat"))) %>% %>% 
  tidyr::unite(col = "Sample_Primer",
               Sample,
               Primer,
               sep = " - ",
               remove = F) %>% 
  ggplot(aes(
    x = Sample_Primer,
    fill = `Genus (NCBI)`)) +
  # fill = Identification)) +
  geom_bar(stat = "count", 
           position = "stack",
           width=0.75) +
  scale_fill_manual(values = viridis::turbo(n = length(unique(FINAL_TBL$`Genus (NCBI)`)))) +
  # scale_fill_manual(values = viridis::turbo(n = length(unique(FINAL_TBL$Identification)))) + 
  xlab("Amostra") +
  ylab("Riqueza de espécies") +
  ggtitle(label = paste0(PRJ),
  # subtitle = "Riqueza de identificações únicas por amostra com abd >= 0.5%: apenas Actinopteri") +
  subtitle = paste0("Riqueza de gêneros únicos por amostra (apenas ",PRJ_class,")")) +
  theme_bw(base_size = 20) +
  theme(legend.position = "bottom",)+
  # geom_vline(xintercept = c(21.5,22.5,23.5,24.5,25.5),size = 0.2)+
  theme(axis.text.x = element_text(angle = 45,hjust = 1)) +
  # facet_grid(cols = vars(`Metadata 1`,`Metadata 3`),
  facet_grid(cols = vars(`Metadata 1`),
             space = "free",
             scales = "free") +
  # guides(fill = guide_legend(ncol = 10))
  guides(fill = "none")


# riqueza_Sample_BLASTn_bar


ggsave(file = paste0(results_path,"/",PRJ,"--BARPLOT-generos.pdf",collapse = ""),
# ggsave(file = paste0("/home/noreh/prjcts/ecomol","/",analysis_rad,"-BARPLOT-riqueza.pdf",collapse = ""),
     plot = riqueza_Sample_BLASTn_bar,
     device = "pdf",
     width = 24,
     height = 16,
     dpi = 600)
}

```

# Ecological analysis

## Definir cores, formas e níveis

```{r,echo=TRUE, eval=FALSE}


# Definir esquema de cores ----

FINAL_TBL$Sample %>% unique()
FINAL_TBL$`Metadata 1` %>% unique()
FINAL_TBL$`Metadata 2` %>% unique()
FINAL_TBL$`Metadata 3` %>% unique()
FINAL_TBL$`Metadata 4` %>% unique()
FINAL_TBL$`Metadata 5` %>% unique()
FINAL_TBL$`Metadata 6` %>% unique()
FINAL_TBL$`Metadata 7` %>% unique()
FINAL_TBL$`Metadata 8` %>% unique()
FINAL_TBL$`Metadata 9` %>% unique()
FINAL_TBL$`Metadata 10` %>% unique()
FINAL_TBL$`Metadata 11` %>% unique()
FINAL_TBL$`Metadata 12` %>% unique()

scales::show_col(viridis::rocket(n=10))
scales::show_col(viridis::viridis(n=10))
scales::show_col(viridis::turbo(n=16))
scales::show_col(viridis::turbo(n=16)[c(2,4,6,8,10,12,14,16)])
viridis::turbo(n=16)[c(2,4,6,8,10,12,14,16)]

  scales::show_col(RColorBrewer::brewer.pal(9,name = "Blues"))
  scales::show_col(RColorBrewer::brewer.pal(9,name = "Greens"))

  
RColorBrewer::brewer.pal(9,name = "Blues")[c(3,6,9)]
RColorBrewer::brewer.pal(9,name = "Greens")[c(3,6,9)]
 
 
 
 
 
 


cores <- c( 
  "PCR Free" = "#ff6a00FF",
  "Dual PCR" = "#307519FF",
  "Both" = "#1d2173FF",
  "LAG01" ="#4143A7FF",
  "URBJ4" ="#3E9BFEFF",
  "LAG03" ="#1AE4B6FF",
  "AGRJ4" ="#88FF4EFF",
  "LAG05" ="#E1DD37FF",
  "NATJ4" ="#FD8D27FF",
  "LAG07" ="#D63506FF",
  "AQAJ4" ="#7A0403FF" 
  )


formas <- c(21,23)
# 
# 
# formas <- c("Transição" = 25,
#             "Mar" = 23,
#             "Rio" = 21)





scales::show_col(cores)

FINAL_TBL$`Metadata 9` %>% unique()

```

## NMDSs

```{r,echo=TRUE, eval=FALSE}

# cores <- c(
#   #primers ----
#   "Ovos" = "#33123BFF",
#   "Larvas" = "#2255FFFF")

# formas <- c("Ovos" = 22,
#             "Larvas" = 23)

#NMDS ----

 source("/home/noreh/prjcts/ecobar/run_nmds_per_group.R")



meus_NMDS <- run_nmds_per_group(
    NMDS_data =  dplyr::filter(FINAL_TBL, Type %in% c("Sample")),
    NMDS_samples = "Unique_File_name",
    NMDS_taxa =  "Curated ID",
    NMDS_taxa_counts =  "Clean relative abd. on sample",

    NMDS_projects = "Project",
    NMDS_subprojects = "Project",
    NMDS_groups = c("Sample"),
    NMDS_colours = "Sample",
    NMDS_colours_vec = cores,
    NMDS_shapes = "Sample",
    NMDS_shapes_vec = formas,
    NMDS_distance = "jaccard",
    NMDS_sig_sps_cutoff = 0.005,
    NMDS_out_samples = c(),
    NMDS_output_path = results_path
    
    # NMDS_data =  FINAL_TBL
    # NMDS_samples = "Sample"
    # NMDS_taxa =  "Curated ID"
    # NMDS_taxa_counts =  "Clean relative abd. on sample"
    # 
    # NMDS_projects = "Project"
    # NMDS_subprojects = "Project"
    # NMDS_groups = c("Metadata 1")
    # NMDS_colours = "Metadata 1"
    # NMDS_colours_vec = cores
    # NMDS_shapes = "Metadata 1"
    # NMDS_shapes_vec = formas
    # NMDS_distance = "jaccard"
    # NMDS_sig_sps_cutoff = 0.005
    # NMDS_out_samples = c()
    # NMDS_output_path = results_path
    )

```

## alpha diversity - phyloseq

```{r eval=FALSE, echo=TRUE}
# phyloseq diversity indexes

# BiocManager::install("phyloseq",force=T)
library("phyloseq")

# BiocManager::install("microbiome",force=T)
library("microbiome")


FINAL_TBL %>% colnames()
{
#create tax table ----
#create new tax table from BLASTn identifications



#create new tax table from BLASTn identifications
blast_tax_table <-  curated_smp_abd_ID %>%
  
  # filter(Type %in% c("Sample")) %>% 
  # mutate("`Sample name`" = str_remove_all(`Sample name`,
  #                                       pattern = "")) %>%
   mutate("Sample name" = str_replace_all(string = `Sample name`,pattern = "^",replacement = "SAMPLE ")) %>%
   mutate("Sample name" = str_replace_all(string = `Sample name`,pattern = " |\\-",replacement = "_")) %>%
  mutate("agrupador" = `Rio`)  %>% 
  
  # filter(`ID status` %in% c("IDed")) %>% 
  select(c(
                        # "Genus (BLASTn)",
                        # "Subfamily (BLASTn)",
                        # "Family (BLASTn)",
                        # "Suborder (BLASTn)",
                        # "Order (BLASTn)",
                        # "Subclass (BLASTn)",
                        # "Class (BLASTn)",
                        # "Phylum (BLASTn)",
                        # "Subphylum (BLASTn)",
                        # "Kingdom (BLASTn)"
           # ,
           #              "ASV (Sequence)"
           )) %>% 
  unique() %>%
  as.data.frame() %>% 
  # `rownames<-`(.$`ASV (Sequence)`) %>% 
  `rownames<-`(.$`Curated ID`) %>% 
  select(-c("Curated ID")) %>% 
  as.matrix()


#creating "OTU" table ----



FINAL_ID_table <-
      curated_smp_abd_ID %>%
    dplyr::filter(!is.na(`Curated ID`)) %>%
    dplyr::mutate("agrupador" = GROUP)  %>% 
    dplyr::select(c("Sample",
                    "Clean relative abd. on sample",
                    # "ASV (Sequence)"                            # estamos usando essa
                    "Curated ID"                            # estamos usando essa
                    )) %>% 
    tidyr::pivot_wider(                                #pivotando as IDs de linhas pra colunas
      id_cols = c("Curated ID"),
      values_from ="Clean relative abd. on sample",            #utilizando abundancias Identificadas
      values_fn = sum_uniq,
      names_from = "Sample",
      names_prefix = "SAMPLE_",
      names_sort = TRUE,
      ) %>%
    dplyr::mutate(across(starts_with("SAMPLE") ,~replace_na(.,replace = 0))) %>% 
  # mutate_if(is.numeric,  ~ . * 100000) %>%
  # mutate_if(is.numeric, round) %>%
  dplyr::mutate_if(is.numeric, jaccarize) %>%
  as.data.frame() %>% 
  `rownames<-`(.$`Curated ID`) %>% 
  select(-c("Curated ID")) %>% 
  filter(rowSums(.) != 0) %>%                         ############# Remover linhas cuja soma é zero
  select(which(!colSums(., na.rm=TRUE) %in% 0))       ############# Remover colunas cuja soma é zero
 
    


dim(FINAL_ID_table)







FINAL_ID_table %>% rowSums() ==0





#creating sample metadata_table ----
# metadata_tbl <- FINAL_TBL %>% 
metadata_tbl <- curated_smp_abd_ID %>% 
  mutate("agrupador" = .[[GROUP]])  %>% 
  # select(c("Sample", "metadata_9",  "metadata_10", "metadata_11")) %>% 
  select(c("Sample", "agrupador")) %>% 
   mutate("Sample" = str_replace_all(string = Sample,pattern = "^",replacement = "SAMPLE ")) %>%
   mutate("Sample" = str_replace_all(string = Sample,pattern = " |\\-",replacement = "_")) %>%
  unique() %>% 
  as.data.frame() %>% 
  `rownames<-`(.$Sample)
  

help(richness)

names(FINAL_ID_table)
str(FINAL_ID_table)

## create phyloseq object ----
FINAL_PS <- phyloseq::phyloseq(otu_table(FINAL_ID_table,taxa_are_rows = T),
                               sample_data(metadata_tbl)
                               # ,
                               # tax_table(blast_tax_table)
                               )
# 
phyloseq::transform_sample_counts()
# phylo_rich_plot <- plot_richness(physeq = FINAL_PS, 
#                                  x="Metadata9",
#                                  shape = "Metadata9",
#                                  color = "Metadata9", 
# measures = c("Observed", "Chao1", "ACE", "Shannon", "Simpson", "InvSimpson")) +
#   geom_boxplot(aes(fill = `Metadata9`),
#                outlier.stroke = 0.25,
#                col = "#828282",
#                linewidth = 0.05,
#                alpha = 0.25,
#                position = position_dodge(width = 1)) +
#     geom_point(position = position_dodge(width = 1),
#               stroke = 0.25) +
#                                 
#                                 ))+
#   # scale_colour_manual(values = c("#6b0000","#fcca03","#02cc37"))+
#   # scale_shape_manual(values = c(24,21,22)) +
#   theme_bw() 
# 
# phylo_rich_plot
# 
# sessionInfo()
# 
# # ggsave(file = paste0(figs_path,"/",prjct_rad,"-",Sys.Date(),"-phyloseq_richness-",EnvMat,".pdf",collapse = ""),
# ggsave(file = paste0(figs_path,"/05mai23/",prjct_rad,"-",Sys.Date(),"-phyloseq_richness-","agua",".pdf",collapse = ""),
# # ggsave(file = paste0(figs_path,"/",prjct_rad,"-",Sys.Date(),"-phyloseq_richness-","Agua",".pdf",collapse = ""),
#      plot = phylo_rich_plot,
#      device = "pdf",
#      width = 40,units = "cm",
#      height = 25,
#      dpi = 300)


 # estimate_richness(FINAL_PS)
div_est_phylo <-  estimate_richness(FINAL_PS,
                                    split = T, 
                                    measures = c("Observed", "Chao1","Obs./Chao1", "se.chao1",
                         "ACE", "se.ACE", "Shannon", "Simpson", "InvSimpson")) %>% 
   # as_tibble(rownames = "Sample name") %>% 
   as_tibble(rownames = "Sample") %>% 
  mutate("Obs./Chao1" = Observed/Chao1) %>% 
   # relocate("EnvMat","Status","Estado") %>% 
   pivot_longer(cols = c("Observed", "Chao1","Obs./Chao1", "se.chao1",
                         "ACE", "se.ACE", "Shannon", "Simpson", "InvSimpson"),
                names_to = "Indice",
                values_to = "Values") %>% 
  mutate(Indice = factor(Indice, levels = c("Observed", "Chao1","Obs./Chao1", "se.chao1",
                                            "ACE", "se.ACE", "Shannon", "Simpson", "InvSimpson"))) %>% 
  left_join(y = metadata_tbl,
            by = "Sample")


  library(ggsignif)

div_est_phylo$agrupador %>% unique()

viridis::turbo(n=30) %>% scales::show_col()
viridis::viridis(n=30) %>% scales::show_col()




# Compare groups
GROUPS_stat <- combn(x = unique(div_est_phylo$agrupador), 
                     m=2) %>% 
  unlist() 

# Wrap each pair in a list (if not already wrapped)
list_result <- lapply(seq_len(ncol(GROUPS_stat)), function(i) as.character(GROUPS_stat[, i]))





 div_est_phylo_plot <- div_est_phylo %>% 
   filter(Indice %in% c(
     "Observed", 
     # "Chao1",
     # "Obs./Chao1",
                        "Shannon",
     "Simpson")) %>% 
   ggplot(aes(y=Values,
              # x=interaction(Status,Estado,sep = "-"),
              x=agrupador,
              # shape = agrupador,
              col = "#282828",
              fill = agrupador,alpha = 0.1)) +
   geom_boxplot(col = "#282828",
                outlier.shape = NA,
                alpha = 0.75,
                linewidth = 0.05) +
   geom_jitter(aes(col = agrupador),
              alpha = 0.75,
              height = 0,
              width = 0.25)+
   # geom_signif(
   #   comparisons = list(
   #   c("P6", "P1"),
   #   c("P6", "P2"),
   #   c("P6", "P3"),
   #   c("P6", "P4"),
   #   c("P6", "P5")
   #   ),
   #   map_signif_level = F,
   #   col="#111111",
   #   y_position = c(32,31,30,29,28),
   #   test = "wilcox.test",
     # ) +  
    geom_signif(
     comparisons = list_result,
     map_signif_level = F,
     col="#111111",
     # y_position = c(32,31,30,29,28),
     test = "wilcox.test",
   ) +
   facet_wrap(nrow = 1,
              ~Indice,
              scales = "free") +
  scale_colour_manual(values = cores, breaks = names(cores), name = "Sampling site")+
  scale_fill_manual(values =  cores, breaks = names(cores), name = "Sampling site")+
  # scale_colour_manual(values = c("#6b0000","#fcca03","#02cc37"))+
  # scale_shape_manual(values = c(21,22,23,24,25,13)) +
  theme_bw(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45,hjust = 1,vjust = 1),
        axis.title = element_text(size = 14),
        strip.text = element_text(size = 14))+
  # labs(subtitle = "Índices de diversidade estimados a partir das espécies encontradas")+
  # labs(subtitle = "Diversity indexes estimated from species identified at each sampling site")+
  xlab(label = "Sampling site") +
  ylab(label = "Value") + 
   guides(shape="none")
 
 
 
 
 
 div_est_phylo_plot
 
 
 ggsave(file = paste0(figs_path,"/","alpha_div-",
                      # "5grupos-",
                      prjct_rad,"-",Sys.Date(),".pdf",collapse = ""),
     plot = div_est_phylo_plot,
     device = "pdf",
     width = 40,units = "cm",
     height = 16,
     dpi = 300)
 
 
 

 # extraindo tabela por ponto amostral par ao manuscrito
div_est_phylo %>% 
  group_by(`Sample`,agrupador,Indice) %>%
  # group_by(agrupador,Indice) %>% 
  mutate("Média" = mean(Values),
         "SD" = sd(Values)) %>% 
  arrange(Indice,`Sample`) %>% 
  select(-c("Sample","Values")) %>% 
  unique() %>% 
  View()
 
 

 
```

# Reorganizar resultados por projeto

```{r, eval=FALSE}


dir.create(path = paste0(analysis_path,"/final_results"))

for (PRJ in all_projects) {

# project <- "Teles Pires"

project_name <- PRJ %>% 
  str_replace_all(pattern = " ",
                  replacement = "_") %>% 
  str_replace_all(pattern = "_-_",
                  replacement = "--")



PRJ_dir_final <- paste0(analysis_path,
                         "/final_results",
                         "/resultados--",
                         project_name)

dir.create(path = PRJ_dir_final)

files_prefix <- paste0(PRJ,"-")

PRJ_multi <- paste0(qual_path,"/",PRJ,"/multiqc")

files_to_move <- list.files(c(results_path, results_path,PRJ_multi),
                            pattern = files_prefix,
                            recursive = F,
                            full.names = TRUE) %>% 
  as_tibble() %>% 
  mutate("Is dir" = file.info(value)$isdir) %>% 
  dplyr::filter(`Is dir` == FALSE) %>% 
  dplyr::pull(value)


file.rename(files_to_move, file.path(PRJ_dir_final, basename(files_to_move)))


}

```

# Análises do relatório

# FIGURA 1

```{r eval=FALSE, echo=TRUE}


# FIGURA 1 - Número de taxa detectado por Classe em cada conjunto amostral ----

tx_per_class_tbl <- FINAL_TBL %>% 
  dplyr::group_by(`Phylum (NCBI)`, `Class (NCBI)`,agrupador) %>% 
  summarise("ASVs" =  length(unique(`ASV (Sequence)`)),
            "OTUs" = length(unique(OTU)),
            "IDs" =  length(unique(`Curated ID`)),
            "Área" = unique(agrupador),
            "Espécies detectadas" = paste0(sort(unique(`Curated ID`)),collapse = ", ")) %>% 
  ungroup()  
  
  
  tx_per_class_plot <- tx_per_class_tbl %>% 
    select(-c("Espécies detectadas")) %>% 
  pivot_longer(cols = c(`ASVs`,`OTUs`,`IDs`),
               names_to = "Tipo",
               values_to = "Counts") %>% 
  filter(Tipo %in% c("IDs")) %>%
  # filter(Tipo %in% c("OTUs")) %>% 
  arrange(`Área`) %>% 
  ggplot(aes(x = Counts,
             label = sum(Counts),
             fill= `Área`,
             # group = interaction(`Distância`,Tempo, sep = " - ")))+
             group = `Área`))+
  # geom_bar(aes(y = interaction(`Distância`,Tempo, sep = " - ")),
  geom_bar(aes(y = `Área`),
           stat = "identity",
           position = "stack",
           col="#8c8c8c",
           linewidth=0.1,
           alpha = 1,
           width=.5) +
  # geom_text(aes(y = interaction(`Distância`,Tempo,sep = " - "),
  geom_text(aes(y = `Área`,
                label=Counts,
                hjust=-1),
                size=6)+
                    
  scale_fill_manual(values = cores,
                    breaks = names(cores)) +
  facet_grid(rows = vars(`Class (NCBI)`),
             # cols = vars(`Distância`),
             scales = "free_x",
             space = "free_x",drop = TRUE
             ) +
  # ylab(label = "Disância de coleta & Tempo de conservação") +
  ylab(label = "Conjunto amostrais") +
  xlab(label = expression(paste("Número de ",italic("taxa")," detectado por Classe"))) +
  theme_bw(base_size = 12) +
  theme(
    axis.title.x = element_text(size = 18),
    axis.title.y = element_text(size = 18, vjust = 2),
    strip.text.x = element_text(size = 16, angle = 0),
    strip.text.y = element_text(size = 16, angle = 0),
    axis.text.x = element_text(size=16,angle=0),
    axis.text.y = element_text(size=16)
    ) + 
  theme(legend.position='bottom') +
  # scale_x_continuous(breaks = c(0,5,10,25,50,75,100,125,150,200,250,300,350,400,450,500,600,700),
  scale_x_continuous(breaks = seq(0,50,5),
                     # trans = "log2",expand = c(0.05,0.05))
                     expand = c(0.05,0.05))

tx_per_class_plot
dev.off()
ggsave(file = paste0(results_path,"/",
                     # "3grupos-",
                     "5grupos-",
                     analysis_rad,"-",Sys.Date(),"-num_taxa_per_class-id80.pdf",collapse = ""),
     plot = tx_per_class_plot,
     device = "pdf",
     width = 40,
     height = 22,
     units = "cm",
     dpi = 300)



#salvar tabela de espécies por amsotra e classe

tx_per_class_tbl %>% writexl::write_xlsx(path = paste0(results_path,
                                                       "/5grupos-",
                                                       # "/3grupos-",
                                                       "Tabela_de_IDs_por_amostra-",
                                                       analysis_rad,"-",Sys.Date(),"-num_taxa_per_class-id80.xlsx",
                                                       collapse = ""),
                                         col_names = T, 
                                         format_headers = T)




cores




```

# FIGURA 2

```{r eval=FALSE, echo=TRUE}
# FIGURA 2 - distribuição de número de IDs por Classe e Unidade amostral



# Riqueza de taxa por status de conservação e estado----



library(ggsignif)

area_tax_rich_tbl <-
  FINAL_TBL %>%
  dplyr::group_by(`Sample name`,
           agrupador, 
           `Class (NCBI)`
           # `Order (NCBI)`
           ) %>% 
  summarise("ASVs" =  length(unique(`ASV (Sequence)`)),
            "OTUs" = length(unique(OTU)),
            "IDs" =  length(unique(`Curated ID`)),
            "Status" = unique(agrupador)) %>%
  ungroup() %>% 
  pivot_longer(cols = c(`ASVs`,`OTUs`,`IDs`),
               names_to = "Tipo",
               values_to = "Counts") 
  

  area_tax_rich_tbl <- area_tax_rich_tbl %>% 
  bind_rows(area_tax_rich_tbl %>%
              mutate("Class (NCBI)" = "Todos"))
  
  
area_tax_rich_tbl$agrupador %>% levels()

area_tax_rich_plot <-
  area_tax_rich_tbl %>% 
  filter(Tipo %in% c("IDs")) %>% 
  filter(`Class (NCBI)` %in% c("Insecta","Actinopteri","Amphibia","Aves","Mammalia","Crocodylia/\nTestudines/\nLepidosauria","Todos")) %>% 
  ggplot(aes(x = Status,
             y = Counts,
             fill=Status,
             # alpha = 0.5,
             # group = interaction(Estado,Status,sep = " - ")
             group = Status
             )) +
   geom_signif(comparisons = list(
     c("PESMar","Antigo"),
     c("PESMar","Recente"),
     c("Antigo","Recente")
     # ,
     # c("PESMar","Antigo Distante"),
     # c("PESMar","Antigo Distante"),
     # c("PESMar","Recente Perto"),
     # c("PESMar","Recente Distante")
     ),
              map_signif_level=TRUE,
              col="#bfbfbf",
              y_position = c(13,13.75,14.5,15.25),
              test = "wilcox.test",
              ) +
  geom_boxplot(position = position_dodge(width = 0.8,preserve = "single"),
               outlier.alpha = NA,
               outlier.fill = NA,
               outlier.shape = NA) +
  geom_jitter(aes(
             col=Status),
             width = 0.3,
             size =0.5) +
  scale_fill_manual(values = cores,
                    breaks = names(cores)) +
  scale_colour_manual(values = cores,
                    breaks = names(cores)) +
  facet_grid(
    # rows = vars(`Env. Mat`),
             # cols = vars(`Class (NCBI)`,`Order (NCBI)`),
             cols = vars(`Class (NCBI)`)
             # scales = "free",
             # space = "free"
             ) +
  
 
  theme_bw() +
  theme(strip.text.y = element_text(size = 16,angle = 0),
        strip.text.x = element_text(size = 16),
        axis.text.x = element_text(size=10,angle = 45, hjust = 1),
        axis.text.y = element_text(size=10),
        axis.title.x = element_text(size=16),
        axis.title.y = element_text(size=16),
        legend.text = element_text(size=16),
        legend.title = element_text(size=20)) +
  xlab(label = "Unidade amostral") +
  ylab(label = expression(paste("Número de espécies por ",italic("taxa"), " detectadas em cada Localidade Amostral"))) + 
  theme(legend.position='bottom') +
   scale_y_continuous(breaks = seq(0,130,5))
# library(ggpubr)

area_tax_rich_plot
dev.off()

# ggsave(file = paste0(results_path,"/05mai23/",analysis_rad,"-",Sys.Date(),"-rich_taxa_per_SampUnit_area_class-90.pdf",collapse = ""),
ggsave(file = paste0(results_path,"/",analysis_rad,"-",
                     "3grupos-",
                     Sys.Date(),"-rich_taxa_per_SampUnit_area_class-id80.pdf",collapse = ""),
     plot = area_tax_rich_plot,
     device = "pdf",
     width = 30,units = "cm",
     height = 22,
     dpi = 300)



```

# FIGURA 3

```{r eval=FALSE, echo=TRUE}



```

# FIGURA X

```{r eval=FALSE, echo=TRUE}



```

# FIGURA X

```{r eval=FALSE, echo=TRUE}



```

# FIGURA X

```{r eval=FALSE, echo=TRUE}



```

# figura de OTus e ASVs por amostras

```{r eval=FALSE, echo=TRUE}


# ----
FINAL_TBL %>% 
  filter(!str_detect(string = `Curated ID`, pattern = "nvironmental")) %>% 
  filter(`BLASTn pseudo-score` >= 90) %>%
  pull(`Phylum (NCBI)`) %>% 
  table()



FINAL_TBL %>% 
  filter(!str_detect(string = `Curated ID`, pattern = "nvironmental")) %>% 
  filter(`BLASTn pseudo-score` >= 90) %>%
  pull(`Class (NCBI)`) %>% 
  table()


# Gráfico de identidades----
options(scipen = 10000000)

# All markers ----
marker_IDs <- FINAL_TBL %>% 
  filter(`Phylum (NCBI)` %in% c("Chordata")) %>%
  select(c("Sequence (ASV tip)","Class (NCBI)","Order (NCBI)","Family (NCBI)","Curated ID","1_indentity")) %>% 
  unique() %>% 
  mutate("ID% range" = floor(`1_indentity`)) %>%
  # mutate("ID% range" = cut(x = `1_indentity`,
  #                          include.lowest=TRUE,
  #                          breaks = c(seq(80,100,1)),
  #                          labels = as.character(c(seq(81,100,1))))) %>%  
  mutate("Max taxonomy" = case_when(   `ID% range` >= 98 ~ "Species",
                                       `ID% range` >= 95 & `ID% range` < 98 ~ "Genus",
                                       `ID% range` >= 90 & `ID% range` < 95 ~ "Family",
                                       `ID% range` >= 80 & `ID% range` < 90 ~ "Order",
                                       `ID% range` >= 60 & `ID% range` < 80 ~ "Class")) %>% 
  mutate("Max taxonomy"  = factor(`Max taxonomy`,
                                  levels = c("Order","Family","Genus","Species"))) %>% 
    
  # mutate("ID% range" = sprintf("%03d",`ID% range`)) %>%
  dplyr::group_by(`Order (NCBI)`, `Curated ID`) %>% 
  mutate(`ID% range` = factor(`ID% range`,levels = c(seq(80,100,1)) ))
  



fake_data <- data.frame(
  Category = factor(setdiff(levels(marker_IDs$`ID% range`), marker_IDs$`ID% range`)),
  Value = NA
)

scales::show_col(rev(viridis::turbo(n=32)))

percent_colours <- rev(viridis::turbo(n=32))
names(percent_colours) <- seq(80,100,1)

marker_IDs_plot <- marker_IDs %>%
  ggplot(aes(x = `ID% range`,
             fill = `ID% range`,lable = `Curated ID`)) +
  geom_bar(stat = "count", 
           position = "stack") +
  theme_light() +
  facet_grid(cols = vars(`Max taxonomy`),
             # rows = vars(`Order (NCBI)`),
             drop = T,
             scales = "free" ,
             space = "free"

             ) +
  scale_fill_manual(values = percent_colours )+
  xlab(label = "Percentual de identidade da identificação por BLASTn")+
  ylab(label = "Número de ASVs") +
  theme(strip.text.y = element_text(size = 10,angle = 0),
        strip.text.x = element_text(size = 10)) +
  guides(fill="none")  
  

marker_IDs_plot

 ggsave(file = paste0(results_path,"/",PRJ,"--",Sys.Date(),"-IDs_percent_by_taxa.pdf",collapse = ""),
     plot = marker_IDs_plot,
     device = "pdf",
     width = 18,units = "cm",
     height = 12,
     dpi = 300)


  plotly::ggplotly(marker_IDs_plot, tooltip = c("Class (NCBI)","Order (NCBI)","Family (NCBI)","Curated ID","1_indentity"))

# Gráfico de identidades----


FINAL_TBL %>% 
  ggplot(aes(y = `1_indentity`,
             x = ,`1_qcovhsp`,
             shape = `Metadata 10`,
             col = `Phylum (NCBI)`,
             alpha=0.05),
         size =1)+
  geom_jitter(width = 0.5 ,
              height = 0.5 )+
  scale_color_manual(values = rev(viridis::viridis(n = length(unique(FINAL_TBL$`Phylum (NCBI)`)))))


vegan::diversity(x = all_IDs_NMDS_df[,15:ncol(all_IDs_NMDS_df)])
vegan::diversity(x = all_IDs_NMDS_df[,15:ncol(all_IDs_NMDS_df)],
                 groups = all_IDs_NMDS_df$Status )

FINAL_TBL %>% 
  filter(`Class (NCBI)` %in% c("Aves")) %>% 
  pull(`Curated ID`) %>% 
  table() %>% length()
           


FINAL_TBL %>% 
  filter(`Class (NCBI)` %in% c("Insecta")) %>% 
  # filter(`ASV rel. abd. in Sampling Unit by marker` >= 0.005) %>%
  # filter(`1_indentity` >= 85) %>% 
  pull(`Curated ID`) %>% 
  table() %>% length()
           


FINAL_TBL %>% 
  filter(`Class (NCBI)` %in% c("Hexanauplia")) %>% 
  pull(`Curated ID`) %>% 
  table() 
           


FINAL_TBL$agrupador %>% unique()





FINAL_TBL %>% 
  select("Unique ID","Sampling Unit total abundance") %>% 
  unique() %>% 
  pull(`Sampling Unit total abundance`) %>% 
  sum()





FINAL_TBL %>% 
  select("Unique ID","Sampling Unit total abundance") %>% 
  unique() %>% 
  pull(`Sampling Unit total abundance`) %>% 
  sum()





#----
```

#Beta Disper

```{r eval=FALSE, echo=TRUE}

#Boxplot distance to centroids ----


dist <- vegdist(all_IDs_NMDS_df[,16:ncol(all_IDs_NMDS_df)],method = "jaccard")

all_IDs_betadis <- betadisper(dist,all_IDs_NMDS_df$agrupador)

boxplot(all_IDs_betadis)

all_IDs_betadis$vectors
all_IDs_betadis$distances

btdspr_tbl <- tibble("distances" = all_IDs_betadis$distances,
       "group" = all_IDs_betadis$group)


library(ggpubr)

btdspr_plot <- btdspr_tbl %>% mutate(group = factor(group,
                                                    levels = c("PESMar",
                                                               "Antigo",
                                                               "Recente"))) %>%
                                                    # levels = c("PESMar",
                                                    #            "Antigo Perto",
                                                    #            "Antigo Distante",
                                                    #            "Recente Perto",
                                                    #            "Recente Distante"))) %>%
  ggplot(aes(x=group, 
             fill=group, 
             col=group, 
             y=distances)) + 
  geom_boxplot(alpha=0.75) +
  geom_jitter(height = 0,
              width = 0.3) +
  
   geom_signif(comparisons = list(
     c("PESMar","Antigo"),
     c("PESMar","Recente"),
     c("Antigo","Recente")

          # c("PESMar","Antigo Perto"),
     # c("PESMar","Antigo Distante"),
     # c("PESMar","Recente Perto"),
     # c("PESMar","Recente Distante")
     ),
              map_signif_level=TRUE,
              col="#bfbfbf",
              y_position = c(0.725,0.75,0.775,0.8,0.825),
              # test = "wilcox.test",
              ) +
  
  theme_bw() +
  scale_fill_manual(values = cores,
                    breaks = names(cores))+
  scale_colour_manual(values = cores,
                      breaks = names(cores)) +
  ylab(label = "Distância dos centroides") +
  xlab(label = "Status de conservação") +
  theme(legend.position = "bottom") +
  guides(color=guide_legend("Status de conservação"),
         fill=guide_legend("Status de conservação"))
  
  
  

btdspr_plot

ggsave(file = paste0(results_path,"/05mai23/",
                     "3grupos-",
                     "dist_centroids-all_markers-Solo-all_CleanAbd-90-",estado,"-",EnvMat,"-",analysis_rad,"-",Sys.Date(),".pdf",collapse = ""),
     plot = btdspr_plot,
     device = "pdf",
     width = 20,units = "cm",
     height = 14,
     dpi = 300)









#Betapart


#aqnalises brejao
library(betapart)


unique(all_IDs_NMDS_df$agrupador)

# all_IDs_NMDS_df_presence <- all_IDs_NMDS_df[,15:ncol(all_IDs_NMDS_df)]
all_IDs_NMDS_df_presence <- 1*(all_IDs_NMDS_df[,16:ncol(all_IDs_NMDS_df)] > 0)


View(all_IDs_NMDS_df_presence)

dim()




# 3 grupos ----
all_NMDS_pres_PESMAr <- all_IDs_NMDS_df_presence[all_IDs_NMDS_df$agrupador == "PESMar",] 
all_NMDS_pres_12 <- all_IDs_NMDS_df_presence[all_IDs_NMDS_df$agrupador == "Antigo",] 
all_NMDS_pres_22 <- all_IDs_NMDS_df_presence[all_IDs_NMDS_df$agrupador == "Recente",] 




beta.meta_PESMAr <- beta.sample(all_NMDS_pres_PESMAr, index.family="sor",sites=10,samples=100)
beta.meta_12 <- beta.sample(all_NMDS_pres_12, index.family="sor",sites=10,samples=100)
beta.meta_22 <- beta.samp le(all_NMDS_pres_22, index.family="sor",sites=10,samples=100)



boxplot((beta.meta_PESMAr$sampled.values$beta.SIM ), 
        (beta.meta_12$sampled.values$beta.SIM ), 
        (beta.meta_22$sampled.values$beta.SIM ),
        
        (beta.meta_PESMAr$sampled.values$beta.SOR ), 
        (beta.meta_12$sampled.values$beta.SOR ), 
        (beta.meta_22$sampled.values$beta.SOR ),
        
        (beta.meta_PESMAr$sampled.values$beta.SNE ), 
        (beta.meta_12$sampled.values$beta.SNE ), 
        (beta.meta_22$sampled.values$beta.SNE ), 
        ylim=c(0,1), names =c("PESMar SIM",
                              "Antigo SIM",
                              "Recente SIM",
                              "PESMar SOR",
                              "Antigo SOR",
                              "Recente SOR",
                              "PESMar SNE",
                              "Antigo SNE",
                              "Recente SNE"))





tbl_PESMAr <- tibble("SIM" = beta.meta_PESMAr$sampled.values$beta.SIM,
                 "SOR" = beta.meta_PESMAr$sampled.values$beta.SOR,
                 "SNE" = beta.meta_PESMAr$sampled.values$beta.SNE,
                 "Status" = "PESMar")




tbl_12 <- tibble("SIM" = beta.meta_12$sampled.values$beta.SIM,
                 "SOR" = beta.meta_12$sampled.values$beta.SOR,
                 "SNE" = beta.meta_12$sampled.values$beta.SNE,
                 "Status" = "Antigo")


tbl_22 <- tibble("SIM" = beta.meta_22$sampled.values$beta.SIM,
                 "SOR" = beta.meta_22$sampled.values$beta.SOR,
                 "SNE" = beta.meta_22$sampled.values$beta.SNE,
                 "Status" = "Recente")



beta_res_all <- bind_rows(tbl_PESMAr, 
                          tbl_12, 
                          tbl_22)


# 5 grupos ----
all_NMDS_pres_PESMAr <- all_IDs_NMDS_df_presence[all_IDs_NMDS_df$agrupador == "PESMar",] 
all_NMDS_pres_12per <- all_IDs_NMDS_df_presence[all_IDs_NMDS_df$agrupador == "Antigo Perto",] 
all_NMDS_pres_12lon <- all_IDs_NMDS_df_presence[all_IDs_NMDS_df$agrupador == "Antigo Distante",] 
all_NMDS_pres_22per <- all_IDs_NMDS_df_presence[all_IDs_NMDS_df$agrupador == "Recente Perto",] 
all_NMDS_pres_22lon <- all_IDs_NMDS_df_presence[all_IDs_NMDS_df$agrupador == "Recente Distante",] 




beta.meta_PESMAr <- beta.sample(all_NMDS_pres_PESMAr, index.family="sor",sites=10,samples=100)
beta.meta_12per <- beta.sample(all_NMDS_pres_12per, index.family="sor",sites=10,samples=100)
beta.meta_12lon <- beta.sample(all_NMDS_pres_12lon, index.family="sor",sites=10,samples=100)
beta.meta_22per <- beta.sample(all_NMDS_pres_22per, index.family="sor",sites=10,samples=100)
beta.meta_22lon <- beta.sample(all_NMDS_pres_22lon, index.family="sor",sites=10,samples=100)



boxplot((beta.meta_PESMAr$sampled.values$beta.SIM ), 
        (beta.meta_12per$sampled.values$beta.SIM), 
        (beta.meta_12lon$sampled.values$beta.SIM ), 
        (beta.meta_22per$sampled.values$beta.SIM ), 
        (beta.meta_22lon$sampled.values$beta.SIM ),
        
        (beta.meta_PESMAr$sampled.values$beta.SOR ), 
        (beta.meta_12per$sampled.values$beta.SOR),
        (beta.meta_12lon$sampled.values$beta.SOR ), 
        (beta.meta_22per$sampled.values$beta.SOR ), 
        (beta.meta_22lon$sampled.values$beta.SOR ),
        
        (beta.meta_PESMAr$sampled.values$beta.SNE ), 
        (beta.meta_12per$sampled.values$beta.SNE), 
        (beta.meta_12lon$sampled.values$beta.SNE ), 
        (beta.meta_22per$sampled.values$beta.SNE ), 
        (beta.meta_22lon$sampled.values$beta.SNE ), 
        ylim=c(0,1), names =c("PESMar SIM",
                              "Antigo Perto SIM",
                              "Antigo Distante SIM",
                              "Recente Perto SIM",
                              "Recente Distante SIM",
                              "PESMar SOR",
                              "Antigo Perto SOR",
                              "Antigo Distante SOR",
                              "Recente Perto SOR",
                              "Recente Distante SOR",
                              "PESMar SNE",
                              "Antigo Perto SNE",
                              "Antigo Distante SNE",
                              "Recente Perto SNE",
                              "Recente Distante SNE"))





tbl_PESMAr <- tibble("SIM" = beta.meta_PESMAr$sampled.values$beta.SIM,
                 "SOR" = beta.meta_PESMAr$sampled.values$beta.SOR,
                 "SNE" = beta.meta_PESMAr$sampled.values$beta.SNE,
                 "Status" = "PESMar")



tbl_12per <- tibble("SIM" = beta.meta_12per$sampled.values$beta.SIM,
                 "SOR" = beta.meta_12per$sampled.values$beta.SOR,
                 "SNE" = beta.meta_12per$sampled.values$beta.SNE,
                 "Status" = "Antigo Perto")



tbl_12lon <- tibble("SIM" = beta.meta_12lon$sampled.values$beta.SIM,
                 "SOR" = beta.meta_12lon$sampled.values$beta.SOR,
                 "SNE" = beta.meta_12lon$sampled.values$beta.SNE,
                 "Status" = "Antigo Distante")


tbl_22per <- tibble("SIM" = beta.meta_22per$sampled.values$beta.SIM,
                 "SOR" = beta.meta_22per$sampled.values$beta.SOR,
                 "SNE" = beta.meta_22per$sampled.values$beta.SNE,
                 "Status" = "Recente Perto")


tbl_22lon <- tibble("SIM" = beta.meta_22lon$sampled.values$beta.SIM,
                 "SOR" = beta.meta_22lon$sampled.values$beta.SOR,
                 "SNE" = beta.meta_22lon$sampled.values$beta.SNE,
                 "Status" = "Recente Distante")



beta_res_all <- bind_rows(tbl_PESMAr, 
                          tbl_12per, 
                          tbl_12lon, 
                          tbl_22per, 
                          tbl_22lon)


# gráfico ----

beta_res_all$Status %>% unique()

beta_box <- beta_res_all %>% 
  mutate(Status = factor(Status, levels = c("PESMar","Recente","Antigo"))) %>%
  # mutate(Status = factor(Status, levels = c("PESMar",
  #                                           "Antigo Perto", 
  #                                           "Antigo Distante", 
  #                                           "Recente Perto", 
  #                                           "Recente Distante"))) %>%
  pivot_longer(cols = c("SIM","SOR","SNE"),names_to = "index",values_to = "Values") %>% 
  mutate(index = factor(index, levels = c("SOR","SIM","SNE"))) %>% 
  ggplot(aes(y=Values,
             x=Status))+
  geom_boxplot(aes(fill=Status),
               col="#111111")+
  geom_jitter(aes(col=Status),
               # col="#111111",
              alpha=0.5,
              height = 0,
              width = 0.4,
              size=1) +
 geom_signif(comparisons = list(
     c("PESMar","Antigo"),
     c("PESMar","Recente"),
     c("Antigo","Recente")
     # ,
     # c("PESMar","Antigo Perto"),
     # c("PESMar","Antigo Distante"),
     # c("PESMar","Recente Perto"),
     # c("PESMar","Recente Distante")
     ),
              map_signif_level=TRUE,
              col="#bfbfbf",
              y_position = c(0.3,0.4,0.5,0.6,0.7),
              # test = "wilcox.test",
              ) +
  theme_bw() +
  scale_colour_manual(values = cores,
                      breaks = names(cores)) +
  scale_fill_manual(values = cores,
                    breaks = names(cores)) +
  facet_grid(cols = vars(index),
             scales="free",
             space = "free")+
  # labs(title = paste0(estado," - ",EnvMat)) +
  ylab(label = "Beta diversidade taxonômica par a par") +
  xlab(label = "Status de conservação") +
  theme(axis.text.x = element_text(size=12,angle = 45, hjust = 1))
  




beta_box


ggsave(file = paste0(results_path,"/",
                     "3grupos-",
                     "beta_part_box-ID80-",analysis_rad,"-",Sys.Date(),".pdf",collapse = ""),
     plot = beta_box,
     device = "pdf",
     width = 30,units = "cm",
     height = 20,
     dpi = 300)


# diagrama de venn ----
install.packages("venneuler")     # Install & load venneuler package
library("venneuler")

plot(venneuler(c("A" = 10,          # Draw pairwise venn diagram
                 "B" = 25,
                 "A&B" = 4)))




install.packages("venn")
library("venn")


set.seed(12345)

x <- as.data.frame(matrix(sample(0:1, 150, replace = TRUE), ncol = 5))

venn(x, ilabels = "counts")


plot(venneuler( c(
  
  "Unidade de Conservação"                 = 100,
  "Com intervenção"                        = 15,
  "Sem intervenção"                        = 31,
  "Unidade de Conservação&Com intervenção" = 5,
  "Unidade de Conservação&Sem intervenção" = 9,
  "Com intervenção&Sem intervenção"        = 10
  ), shape = "ellipse"))


# https://eulerr.co/


#09B900,#9AEC00,#964C1A







install.packages("VennDiagram")

library(VennDiagram)


venn.diagram(list(B = 1:1800, A = 1571:2020),fill = c("red", "green"),
  alpha = c(0.5, 0.5), cex = 2,cat.fontface = 4,lty =2, fontfamily =3, 
   filename = "trial2.emf");



```

## Espécies indicadoras

```{r eval=FALSE, echo=TRUE}




# indicator species ----
######Indicator species####
install.packages('indicspecies')
library('indicspecies')

indval <-  FINAL_tbl_IDs %>%
  rename_at(vars(starts_with("ID_")),            
            .funs = ~str_replace_all(.,pattern = " ",
                                     replacement = "_")) %>% 
  select(starts_with("ID_")) %>% 
  multipatt(cluster = FINAL_tbl_IDs$agrupador,
                   control = how(nperm=999))

summary(indval)



# 
# res_indval_SP_agua 
# # <- capture.output(summary(indval) )
# res_indval_SP_solo 
# # <- capture.output(summary(indval) )
# res_indval_MG_agua 
# # <- capture.output(summary(indval) )
# res_indval_MG_solo
# # <- capture.output(summary(indval) )
# res_indval_RJ_agua 
# # <- capture.output(summary(indval) )
# res_indval_RJ_solo 
# # <- capture.output(summary(indval) )
# 





# extract values from indval summary ----
res_indval <- tibble(linha = capture.output(summary(indval) )) %>% 
  mutate(ordem = rownames(.)) %>% 
  mutate(linha = str_replace_all(string = linha,pattern = "\\s+",replacement = " ")) %>% 
  filter(str_detect(string = linha,pattern = "^ID|^ Group")) %>% 
  
  mutate(linha = str_replace_all(string = linha,pattern = "^ Group",replacement = "- - - Group - ")) %>% 
  separate(col = linha,sep = " ",into = c("ID","stat","pval","signif","d","e","Grupo","g","h"))
   

# fill groups from results ----
for (linha in 1:nrow(res_indval)) {
 if (is.na(res_indval$Grupo[linha])) {
  
   res_indval$Grupo[linha] <- (unique(res_indval$Grupo[1:linha]) %>% na.exclude() %>%  rev())[1]
   
 }else{}
  
  
}





res_indval_TODOS_agua <- res_indval
res_indval_TODOS_solo <- res_indval
res_indval_SP_agua <- res_indval
res_indval_SP_solo <- res_indval
res_indval_MG_agua <- res_indval
res_indval_MG_solo <- res_indval
res_indval_RJ_agua <- res_indval
res_indval_RJ_solo <- res_indval














tibble(linha = %>% 
  stringi::stri_split_lines())



indval$str %>% pheatmap::pheatmap()
indval$str
indval$cluster










```

# Betapart

```{r eval=FALSE, echo=TRUE}
# juntei no NMDS



# p-value

p.value.beta.SIM<-length(which(beta.meta_SI$sampled.values$beta.SIM<
beta.meta_SI$sampled.values$beta.SIM))/100


p.value.beta.SIM<-length(which(beta.meta_SI$sampled.values$beta.SIM < 
                                 beta.meta_CI$sampled.values$beta.SIM))/100


p.value.beta.SIM<-length(which(beta.meta_SI$sampled.values$beta.SIM < 
                                 beta.meta_UC$sampled.values$beta.SIM))/100






boxplot((beta.ceram.s$sampled.values$beta.SIM), (beta.ceram.n$sampled.values$beta.SIM ),
        (beta.ceram.s$sampled.values$beta.SOR), (beta.ceram.n$sampled.values$beta.SOR ),
        (beta.ceram.s$sampled.values$beta.SNE), (beta.ceram.n$sampled.values$beta.SNE ), 
        ylim=c(0,1), names =c("Ceram.s SIM","Ceram.n SIM","Ceram.s SOR","Ceram.n SOR", "Ceram.s SNE","Ceram.n SNE" ))





FINAL_tbl_COI_deposit$`Phylum (NCBI)` %>% table()
FINAL_tbl_COI_deposit$`Class (NCBI)` %>% table() %>% sort()
FINAL_tbl_COI_deposit$Status %>% table()
FINAL_tbl_COI_deposit$`Clean relative abd. on Sampling Unit by marker` %>% hist()

```

# betadisper

```{r eval=FALSE, echo=TRUE}


# betadisper ----
#            https://www.youtube.com/watch?v=oiChpzCLfdw

vegan::adonis2(t(FINAL_ID_table) ~ Estado + Status, data = metadata_tbl, by = NULL)
vegan::adonis2(t(FINAL_ID_table) ~  Status , data = metadata_tbl)
vegan::adonis2(t(FINAL_ID_table) ~ Estado * Status, data = metadata_tbl)


colnames(FINAL_ID_table)
rownames(t(FINAL_ID_table))


rownames(FINAL_tbl_IDs) <- FINAL_tbl_IDs$`Unique ID`



dists <- vegdist(FINAL_tbl_IDs[,9:1773],method = "bray")
dists <- vegdist(t(FINAL_tbl_IDs[,9:1773]),method = "bray")
dists <- vegdist(t(FINAL_ID_table),method = "bray")
dists <- vegdist(t(FINAL_ID_table),method = "jaccard")

perm <- betadisper(d = dists,
                   group = interaction(metadata_tbl$Estado,metadata_tbl$Status,metadata_tbl$`Environment (material)`))

plot(perm)
 
phyloseq::samples.p   metric='braycurtis')






FINAL_tbl_IDs %>% 
  nest_by(Estado) %>% 
  summarise()



















head(FINAL_ID_table)
head(blast_tax_table)



mergers_seqtab.nochim %>% class()
samdf %>% class()
mergers_taxa %>% class()





# phyloseq::otu_table(mergers_seqtab.nochim, taxa_are_rows = FALSE),
#                                  phyloseq::sample_data(samdf),
#                                  phyloseq::tax_table(mergers_taxa$tax)


phyloseq::otu_table()
phyloseq::sample_data()
phyloseq::tax_table(blast_tax_table)
phyloseq::phy_tree() 






mergers_taxa$tax



all_ps@otu_table %>% View()
all_ps@tax_table %>% View()




smp_abd_ID %>% colnames() %>% paste0(collapse = '",\n"') %>% cat()


#create new tax table from BLASTn identifications
blast_tax_table <- curated_smp_abd_ID %>% select(c("Curated ID",
                        "Genus (NCBI)",
                        "Subfamily (NCBI)",
                        "Family (NCBI)",
                        "Suborder (NCBI)",
                        "Order (NCBI)",
                        "Subclass (NCBI)",
                        "Class (NCBI)",
                        "Phylum (NCBI)",
                        "Subphylum (NCBI)",
                        "Kingdom (NCBI)",
                        "ASV (Sequence)")) %>% 
  unique() %>% 
  # filter(!`Kingdom (NCBI)` %in% c(NA,"NA")) %>% 
  # filter(`Kingdom (NCBI)` %in% c("Metazoa")) %>% 
  as.data.frame() %>% 
  `rownames<-`(.$`ASV (Sequence)`) %>% 
  select(-c("ASV (Sequence)")) %>% 
  as.matrix()
  

colnames(blast_tax_table) <- colnames(blast_tax_table) %>% str_replace(" ","_") %>% str_remove_all(pattern = "\\(|\\)")
colnames(blast_tax_table) <- colnames(blast_tax_table) %>% str_remove_all(pattern = " \\(BLASTn\\)")



all_ps@tax_table <- blast_tax_table #N'ao funciona

mergers_seqtab.nochim_filt <- mergers_seqtab.nochim[(mergers_seqtab.nochim %>% rowSums()) != 0,] 


mergers_seqtab.nochim_filt <- mergers_seqtab.nochim_filt[,colnames(mergers_seqtab.nochim_filt) %in% unique(curated_smp_abd_ID$`ASV (Sequence)`)]




seqtab_FINAL <- mergers_seqtab.nochim_filt %>% as_tibble(rownames = "Sample") %>% 
  mutate("SAMPLE" = str_remove_all(Sample,pattern = "EM118_|A|B")) %>% 
  filter(str_detect(Sample,pattern = "EM118" )) %>% 
  relocate("SAMPLE") %>% 
  dplyr::group_by(SAMPLE) %>% 
  summarise(across(.cols = !contains("S"),
                   .fns = sum,.names = "{col}")) %>% 
  column_to_rownames("SAMPLE") %>% 
  # select(-c("SAMPLE")) %>% 
  as.matrix()
  


rownames(seqtab_FINAL) <- seqtab_FINAL

mergers_seqtab.nochim_filt %>% dim()





samdf %>% colnames()


samdf_FINAL <- samdf %>% 
  as_tibble() %>% 
  filter(Type %in% c("Sample")) %>% 
  # select(c("File_name","Metadata 1","Metadata 2")) %>% 
  select(c(
    # "File_name",
    "Metadata 1"
    # ,"Metadata 2"
    )) %>% 
  rename("Metadata_1" = "Metadata 1"
         # ,         "Metadata_2" = "Metadata 2"
         ) %>%
  unique() %>% 
    as.data.frame()
# %>% 
#   column_to_rownames("Metadata_1") 
rownames(samdf_FINAL) <- samdf_FINAL$Metadata_1


mergers_seqtab.nochim %>% str


otu_table(mergers_seqtab.nochim, taxa_are_rows = FALSE) %>% View()
sample_data(samdf[!samdf$File_name %in% samples_out,1:6]) %>% View()
tax_table(blast_tax_table) %>% View()


all_ps_FINAL <- phyloseq::phyloseq(otu_table(seqtab_FINAL, taxa_are_rows = FALSE),
                                   sample_data(samdf_FINAL),
                                   tax_table(blast_tax_table))


blast_tax_table %>% View()


which(is.na(otu_table(mergers_seqtab.nochim, taxa_are_rows = FALSE)), arr.ind = TRUE)

all_ps_blast
plot_heatmap(all_ps_blast,na.value = "#ffffff")

rowSums(otu_table(mergers_seqtab.nochim, taxa_are_rows = FALSE))

all_ps_blast %>% phyloseq::plot_bar(fill = "Order")










```

# Exportando informções complementares

```{r eval=FALSE, echo=TRUE}


curated_smp_abd_ID$Project %>% unique()
curated_smp_abd_ID %>% 
  dplyr::filter(str_detect(string = Project, pattern = "EM165_DanielLimeira_Nxtseq")) %>% 
   dplyr::arrange(Unique_File_name) %>%
  # mutate("Unique_File_name" = factor(Unique_File_name, levels = sample_levels)) %>%
  # dplyr::filter(Type %in% c("Sample")) %>% 
  # dplyr::filter(`Clean relative abd. on sample` >= 0.0005) %>%
  # dplyr::filter(`Primer expected length` %in% c("in range")) %>%
  # dplyr::filter(`BLASTn pseudo-score` >= 80) %>%
  # dplyr::filter(`Kingdom (NCBI)` %in% c("Metazoa")) %>%
  filter(`Class (NCBI)` %in% c("Actinopteri")) %>%
  # filter((`Contamination status` %in% c("True detection") & Type %in% c("Sample") ) |Type %in% c("PCR control") ) %>%
  # filter((`Contamination status` %in% c("True detection") )) %>%
                    # filter((!str_detect( string = `Final ID (BLASTn)`,pattern = c("environmental") ))) %>%
  # dplyr::group_by(`Final ID (BLASTn)`,`Sample name`,`Read origin`) %>%
  dplyr::group_by(Unique_File_name,`Read origin`) %>%
  dplyr::mutate("Sample total abd"  = sum(`ASV absolute abundance`)) %>% 
  dplyr::ungroup() %>% 
  dplyr::group_by(`Curated ID`,Unique_File_name,`Read origin`) %>%
  # dplyr::group_by(`Final ID (BLASTn)`,Sample) %>%
  # dplyr::group_by(`Genus (NCBI)`,Sample) %>%
  # dplyr::group_by(Identification,Unique_File_name,`Read origin`) %>%
  # dplyr::group_by(`Final ID (DADA2)`,Unique_File_name,`Read origin`,`ASV (Sequence)`) %>%
  # dplyr::group_by(`Final ID (BLASTn)`,sample_Sample,`Read origin`,`ASV (Sequence)`) %>%
  # dplyr::group_by(`Final ID (BLASTn)`,Unique_File_name,`Read origin`,`ASV (Sequence)`) %>%
  # mutate("Relative abundance on sample sum (%)" = round(sum(`Relative abundance on sample`),digits = 3),
  dplyr::mutate("Relative abundance on sample (%)" = round(sum(`ASV absolute abundance`)/`Sample total abd`*100,digits = 3),
                "Absolute ID abd" = sum(`ASV absolute abundance`),
                "Num ASVs per ID" = length(unique(`ASV header`)),
                "ASVs in ID" = paste0(unique(`ASV header`),collapse = ";") ) %>% 
  dplyr::ungroup() %>% 
  dplyr::group_by(`Final ID (BLASTn)`,`Read origin`,Type) %>%
  # dplyr::group_by(`Genus (NCBI)`) %>% 
  dplyr::mutate("Min BLASTn pseudo-score" = round(min(`BLASTn pseudo-score`),digits = 2)
         ) %>%
  dplyr::ungroup() %>% 
  dplyr::select(c("Unique_File_name", 
                  "Primer",
                  "Curated ID", 
                  "Relative abundance on sample (%)",
                  "Absolute ID abd",
                  "Sample total abd",
                  "Min BLASTn pseudo-score",
                  "Num ASVs per ID",
                  "ASVs in ID",
                  "Family (NCBI)", "Order (NCBI)", "Class (NCBI)","Type")) %>%  
  unique() %>% 
  View()


```

## arvores por grupo

```{r,echo=TRUE, eval=FALSE}
#generate fasta from ASVs and align per primer ----


primers_n_samples$`Raw data path`[primers_n_samples$`Raw data path` == "/data/data_raw/ecomol/2024/EM165_DanielLimeira_Nxtseq/raw"] <- "/home/danielc/pontagrossa/raw"

#all ----
# giving our seq headers more manageable names (ASV_1, ASV_2...)

all_asv_seqs_cur <- smp_abd_ID_Final %>% 
  filter(`Read origin` %in% c("merged")) %>% 
  filter(`Primer expected length` %in% c("in range")) %>% 
  select(c(`ASV (Sequence)`,
         `ASV Size (pb)`,
         `ASV header`,
         OTU,`Final ID (BLASTn)`,`Final ID (DADA2)`,Primer, Sample)) %>% 
  dplyr::group_by(`ASV (Sequence)`) %>% 
  mutate("Found in" =  unique(Sample) %>% str_remove_all(pattern = "EM118_") %>% paste0(collapse = "-")) %>% 
  ungroup() %>% 
  select(-c("Sample")) %>% 
  unique()




all_asv_seqs_cur <- all_asv_seqs_cur %>% 
  mutate("Full header" = paste0(`ASV header`,"-OTU_",OTU,"-",Primer,"-","Bn_",`Final ID (BLASTn)`,"-DD2_",`Final ID (DADA2)`,"-in_",`Found in`)) 


#write fasta file with ASVs and Taxonomy
all_asv_seqs_cur <- c(rbind(all_asv_seqs_cur$`Full header`, all_asv_seqs_cur$`ASV (Sequence)`))

write(all_asv_seqs_cur, paste0(results_path,"/",analysis_rad,"-ASVs_metazoa_for_trees.fasta"))



all_asv_seqs_cur <- 
Biostrings::readDNAStringSet(filepath = paste0(results_path,"/",analysis_rad,"-ASVs_metazoa_for_trees.fasta")) %>%
  DECIPHER::RemoveGaps()



LGC_12Sdb_seqs <- 
Biostrings::readDNAStringSet(filepath = "~/prjcts/fish_eDNA/DB/mai22/DB/LGC12Sdb_251seqs-mai22-pretty_names_noGaps.fasta") %>%
  DECIPHER::RemoveGaps()


ASVs_N_DB <- c(all_asv_seqs_cur, LGC_12Sdb_seqs)


ASVs_N_DB_algn <- DECIPHER::AlignSeqs(myXStringSet = ASVs_N_DB, 
                                      refinements = 100,
                                      iterations = 100,
                                      verbose = TRUE)

DECIPHER::BrowseSeqs(ASVs_N_DB_algn)


library(DECIPHER)
ASVs_N_DB_algn_sub <- Biostrings::subseq(x = ASVs_N_DB_algn,
                                       start = 18 ,end = 247)




ASVs_N_DB_algn_sub <- ASVs_N_DB_algn_sub %>%
  DECIPHER::RemoveGaps() %>% 
  DECIPHER::AlignSeqs(refinements = 100,
                                      iterations = 100,
                                      verbose = TRUE)
#write alignments ----



ASVs_N_DB_algn_sub





ASVs_N_DB_algn_sub_dist <- DECIPHER::DistanceMatrix(myXStringSet = ASVs_N_DB_algn_sub,
                                            includeTerminalGaps = TRUE,
                                            correction = "Jukes-Cantor",
                                            processors = 60,type = "dist",
                                            verbose = TRUE)

ASVs_N_DB_algn_sub_dist %>% as.matrix() %>% 
pheatmap::pheatmap()



View(ASVs_N_DB_algn_sub_dist)
str(ASVs_N_DB_algn_sub_dist)


ASVs_N_DB_tree <- ape::njs(ASVs_N_DB_algn_sub_dist)


ASVs_N_DB_tree$tip.label

ape::write.tree(phy = ASVs_N_DB_tree,digits = 5,file =
                  paste0(results_path,"/","WWF_7-MiBird-Arvore_ASVs_12Sdb.nwk"))








#plot trees
library(ggtree)

# leafs_color_tbl <- tibble(seq = names(all_ASVs_12SDB_algn)) %>% 
#   mutate(category = if_else(str_detect(string = .$seq,pattern = "ASV_"),"ASV","DB"))



ASVs_N_DB_tree_nwck <- ggtree::read.tree(file = paste0(results_path,"/","WWF_7-MiBird-Arvore_ASVs_12Sdb.nwk"))





ASVs_N_DB_tree_nwck$tip.label





```

## Surubim

```{r,echo=TRUE, eval=FALSE}

curated_smp_abd_ID$Project %>%  unique()
curated_smp_abd_ID$`Curated ID` %>%  unique() %>% sort()


curated_smp_abd_ID %>% 
  dplyr::filter(!Project %in% c("eDNA_Surubim")) %>% 
  
  dplyr::filter(`Curated ID` %in% c("Steindachneridion doceanum")) %>% 
  
  filter(`Clean relative abd. on sample` >= 0.005) %>%
  # filter(!`ASV header` %in% c(">ASV_2682-175bp")) %>%
  dplyr::group_by(Sample) %>% 
  dplyr::mutate("Total" =  round(sum(`Clean relative abd. on sample`),digits = 3)) %>% 
  # ggplot(aes(x = interaction(`Metadata 1`,`Metadata 2`),
  ggplot(aes(y = Sample,
             x = `Clean relative abd. on sample`,
             fill = `ASV header`)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = Total)) +
  facet_grid(rows = vars(`Metadata 1`),drop = T,space  = "free",scales = "free")

```

## Corrigindo nome do projeto em todas tabelas

```{r,echo=TRUE, eval=FALSE}

# Function to check if an object is a data frame, tibble, or table and has a 'project' column
is_df_with_project <- function(obj_name) {
  obj <- get(obj_name)
  inherits(obj, c("data.frame", "tbl_df", "tbl")) && "Project" %in% colnames(obj)
}

# Get all objects in the environment
object_names <- ls()

# Filter objects that satisfy the conditions
df_with_project <- object_names[sapply(object_names, is_df_with_project)]

# List the objects that meet the criteria
df_with_project %>% paste0(collapse = '$Project == "Sq_dez25"\n') %>% cat()




all_asv_seqs_tax$Project[all_asv_seqs_tax$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
all_asv_seqs_tax_prj$Project[all_asv_seqs_tax_prj$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
all_IDs_NMDS_df$Project[all_IDs_NMDS_df$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
all_IDs_NMDS_tbl$Project[all_IDs_NMDS_tbl$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
all_ps_tbl$Project[all_ps_tbl$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
all_ps_tbl_blast$Project[all_ps_tbl_blast$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
all_ps_tbl_blast_controls$Project[all_ps_tbl_blast_controls$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
all_ps_tbl_blast_controls_clean$Project[all_ps_tbl_blast_controls_clean$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
all_samdf$Project[all_samdf$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
all_track$Project[all_track$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
concat_ps_tbl$Project[concat_ps_tbl$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
curated_smp_abd_ID$Project[curated_smp_abd_ID$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
curated_smp_abd_ID_processed$Project[curated_smp_abd_ID_processed$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
cut_files_per_primer$Project[cut_files_per_primer$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
FINAL_TBL$Project[FINAL_TBL$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
FINAL_tbl_IDs$Project[FINAL_tbl_IDs$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
mergers_ps_tbl$Project[mergers_ps_tbl$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
paired_files_per_primer$Project[paired_files_per_primer$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
primers_in_Nreads$Project[primers_in_Nreads$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
primers_in_Nreads_long$Project[primers_in_Nreads_long$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
primers_n_samples$Project[primers_n_samples$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
primers_n_samples_update$Project[primers_n_samples_update$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
samdf$Project[samdf$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
sample_idx_tbl$Project[sample_idx_tbl$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
sample_idx_tbl_wide$Project[sample_idx_tbl_wide$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
smp_abd_ID$Project[smp_abd_ID$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
smp_abd_ID_eco$Project[smp_abd_ID_eco$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
smp_abd_ID_Final$Project[smp_abd_ID_Final$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"
track_tbl$Project[track_tbl$Project == "Sq_dez25"] <- "eDNA_estuarios_UNESP"



```

#References

-   Callahan BJ, McMurdie PJ, Rosen MJ, Han AW, Johnson AJ, Holmes SP. *DADA2: High-resolution sample inference from Illumina amplicon data.* Nat Methods. 2016 Jul;13(7):581-3. doi: 10.1038/nmeth.3869. Epub 2016 May 23. PMID: 27214047; PMCID: PMC4927377.

-   Martin M. **Cutadapt removes adapter sequences from high-throughput sequencing reads.** EMBnet.journal. 2011;17(1):10–12. doi: 10.14806/ej.17.1.200. -

-   McMurdie PJ, Holmes S. *phyloseq: an R package for reproducible interactive analysis and graphics of microbiome census data.* PLoS One. 2013 Apr 22;8(4):e61217. doi: 10.1371/journal.pone.0061217. PMID: 23630581; PMCID: PMC3632530.

-   R Core Team (2020). **R: A language and environment for statistical computing.** R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.

-   Wang Q, Garrity GM, Tiedje JM, Cole JR. *Naive Bayesian classifier for rapid assignment of rRNA sequences into the new bacterial taxonomy.* Appl Environ Microbiol. 2007 Aug;73(16):5261-7. doi: 10.1128/AEM.00062-07. Epub 2007 Jun 22. PMID: 17586664; PMCID: PMC1950982.

\pagebreak

**This is a partial report, intended to show the current state of analyses. Many procedures and conclusions might change as the pipeline evolves. If you notice errors/mistakes/typos, or have any suggestions, we would be glad to know. *heronoh\@gmail.com***
